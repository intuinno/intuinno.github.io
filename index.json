[{"authors":["Deokgun Park"],"categories":null,"content":" We read a lot of papers. I thought it would be beneficial if I document how I organize the summary. Sometimes, I am in a hurry and read a lot of papers before summarizing them. This results sometimes in anxiety and even worse what you learned will be easily lost. By following standarized procedure for reading papers, I hope I can overcome this.\nMy procedure 2.0 (Updated 2/1/2011)  After you read the paper, move it to one drive. If you have hand-written annotations in the printed paper, replicate it on the file. Add the print to the binder.\n Add new entry on the paper references database in HLAI wiki. HLAI wiki is built using notion service. If there is interesting images, add them to the wiki page. Add comments in the wiki page. A few place holders will be following.  Summary What is this paper about? Good What are good points? Bad What are my criticism? Implication How I can use this work? What will be different from my approach? Future Readings Include some more references  (Optional) If the paper is highly relevant and you might write about it in other documents (papers, grants), or there is a comment worth sharing with the rest of the world, write a blog post in the homepage. Here is an example post.\n  2/1/2021 Update Previously, I used mind mapping to see overview of the paper. But as the number of papers grow, it was difficult to see it in the mindmaps (mindmeister, mindmup). Thus I switched to notion for the management. Also writing summary posts takes too much time while I still believe it is helpful. Thus I created a default pass for normal papers and an optional pass for highly important papers. Below is my original procedure for the record.\nMy procedure (Original)  After you read the paper, move it to google drive. If you have annotation with pen and highlighting marker, replicate it on the file. Add the reference to the reference mindmap. I embedded the mindmap in the post. If there is an interesting pictures, save photos to the google drive Paper figures folders and attach it into the mindmap.  You might change the filename of the captured image such that you can upload it to homepage. Copy those figures to homepage/static/img folder.\n  Start summarizing the paper in the mindmap. A few place holders will be following.  Summary What is this paper about? Good What are good points? Bad What are my criticism? Implication How I can use this work? What will be different from my approach? Future Readings Include some more references  After summarizing them, add those summary in the homepage review post. Here is an example post. Finally, if the paper is worth sharing, add the paper to HDILab journal with the link to the summary post such that it can be shared.  Below is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n","date":1612159200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612229580,"objectID":"85719d75ce349c60f4d175274164fd91","permalink":"http://crystal.uta.edu/~park/post/howto-read-paper/","publishdate":"2021-02-01T00:00:00-06:00","relpermalink":"/post/howto-read-paper/","section":"post","summary":"We read a lot of papers. This is my standarized procedure for reading a paper such that the insight from it can be kept and spread.  ","tags":["student advice"],"title":"What to do after reading a paper","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" This is the paper review of the following paper.\n Lemme, Andre, Ren√© Felix Reinhart, and Jochen Jakob Steil. \u0026ldquo;Online learning and generalization of parts-based image representations by non-negative sparse autoencoders.\u0026rdquo; Neural Networks 33 (2012): 194-203.\n This paper presents a variation of autoencoder (AE) models. It is estimated that the human visual cortex uses basis functions to transform an input image to sparse representation1.\nAutoencoders seem to be good models for the process because they can produce embedding representation with different dimensions from the original signal. Training of the model is also easy because we don\u0026rsquo;t need labels for the inputs but use the difference from the original input and the recovered input from embedding as an error function.\nThere are many variations for the autoencoders, including variational autoencoder (VAE) and sparse AE. VAE is for the interpretability. Conceptually, the high-dimensional space of the embedding can have an arbitrarily complex pattern. There can be many undefined spaces. For example, let\u0026rsquo;s say there are four dimensions for embedding and it happens to represent a cat with [0.5 0.5 0.5 0.5 0.8] and a dog with [0.5 0.5 0.5 0.5 0.2]. But there can be no meaning between 0.2 and 0.8 for the last dimension. It becomes especially problematic when you want to generate some data by randomly sampling from embedding space. It will be embarrassing if there are no meaningful data to most of the embedding space. VAE solves this problem by adding the constraint that the embedding values should follow a gaussian normal distribution. Technically, you add additional loss term for KL divergence between the distribution of embedding values and gaussian distribution. You can see an online demo of generating an image from Doom by changing latent dimensions here.\nAnother meaningful variation is that making the embedding sparse. Here we want only a small portion of embeddings to be nonzero while standard AE and VAE generate dense representation. Why do we want sparse representation? Sparsity has many benefits.\n It is easier to interpret. You can think of each nonzero value as the feature present in the data. For interpretability, non-negativity helps, too. What will be the meaning of the negative yellow? Or negative car? My favorite representation is a sparse binary representation, which maximizes the interpretability. It is more biologically plausible. At any given point, about two percents of the neural cells are active. Of course, AI does not need to use the same mechanism as the rockets, helicopters, or jet airplanes do not use the flipping mechanism to fly as birds do.\n According to Olshausen and Field (2004), it can minimize the chance for destructive cross talk.\n According to Ranzato, Boureau, and LeCun (2008), it improves the linear separability.\n  L1 loss called lasso loss is commonly used to build a sparse model. Andrew Ng used the KL divergence between a binominal distribution and the activation frequency of embedding values. It has one additional parameter that allows us to set the activation probability. Therefore, we can set the activation probability of embedding at two percent that is about the same as how frequently the biological neural cells activate.\nThis paper presents a non-negative sparse autoencoder (NNSAE). Compared to other AE variants, NNSAE has the following benefits for my heterarchical prediction memory (HPM).\n Non-negative Sparse Online Sparsity adds a built-in regulation to prevent overfitting Local  Non-negative matrix factorization (NMF) has been used to get non-negative embedding. However, this method relies on iterative fitting and does not work well with streaming inputs. NNSAE uses a larger update rate for negative weights than positive weights. It penalizes the negative weights and forces the weights to be positive. The logistic activation function has been used to make the output values between zero and one. In NNSAE, the logistic activation function is shifted such that only a certain percentage of the cells are activated. The below figure explains this concept visually.\n This figure explains how NNSAE generates a sparse code by shifting sigmoid function by parameter a and b. As can be seen in right figure, the shifted sigmoid generates a sparse code given gaussian input.   The sparsity constraint of the model enforces the regularization. In the synthetic toy dataset, where the ground-truth basis dimension is 18, we can see that the additional hidden dimensions are not used, as we can see when we use embedding dimensions larger than 18.\n This sysnthetic dataset has 18 basis. As we can see in (d) and (e), when there are more hidden units, the model only uses 18 basis and does not use the remainder.   Similarly, for MNIST and CBCL face dataset, we can see that the number of used neurons does not explode beyond as the standard AE and sparsity is met.\n In (a) and (b), we can see that the number of used neurons for hidden unit saturates, even though the number of hidden units increase. In \u0026copy;, we can see the standard AE uses all the basis, while the NNSAE uses only subset of basis and the remainder is near zero as seen in (d).   As the algorithm is online, we can change the dataset in the middle of the training and expect the model to adapt to the new dataset, as can be seen below.\n The algorithm is online, therefore when we switch the dataset, it adapts to new dataset.   Use of NNSAE for HPM I conjecture that each module predicts what will come as an input for the next time step. It is similar to AE that we can train the model minimizing the difference between the current input and recovered output. However, it becomes difficult to predict far in the future. I want to overcome this limitation by having a hierarchy of layers predicting the next time step. Each layer predicts the next time step and aggregates the four-time steps. This aggregated input is then reduced to the dimension of single input using NNSAE. The upper layer feeds back this information to the lower layer. Therefore lower layers have two inputs. One is the actual input, and the other is context.\n The diagram for HPM model   As a concrete example in the language modeling application, let\u0026rsquo;s say that you have a stream of characters. You might have three layers working on different time scales. The lowest layer L1 gets the characters encoded as sparse binary codes. In my experiment, I used 512 as the embedding size and only 10 bits, which is about two percents are on, and the rest is off. L1 tries to predict the next character by using a multilayer perceptron (MLP). But inherently, you cannot predict the next character given only the current character. For example, \u0026ldquo;a\u0026rdquo; or \u0026ldquo;h\u0026rdquo; can follow \u0026ldquo;c\u0026rdquo; as \u0026ldquo;cat\u0026rdquo; or \u0026ldquo;choice\u0026rdquo;. Context from the upper layer helps here. For L1, context from L2 contains information about the last four characters. Therefore L1 can predict the next characters better. Now, L1 sends a bottom-up feedforward signal by compressing embedding for four characters into 512 bits with ten on bits. This function is called \u0026ldquo;pooling,\u0026rdquo; and I used NNSAE for implementing the pooler.\nThe below figure shows my language model\u0026rsquo;s performance trained over a short text file and a large text file.\n The performance of NNSAE for the character level language modeling. We used three layers. Each layer has a predictor and a pooler. Pooler uses NNSAE.   While the performance of the pooler or NNSAE is satisfactory, the predictor performance is not. Below are some of my future strategy to make the predictor faster and better.\n Deep Sparse Rectifier Neural Networks by Xavier Glorot, Antoine Bordes, Yoshua Bengio. Sparse deep belief net model for visual area V2 by Honglak Lee, Chaitanya, Ekanadham, Andrew Ng Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons by Jochen Triesch Echo State Networks L1 Loss  Below is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n Olshausen, Bruno A., and David J. Field. \u0026ldquo;Sparse coding with an overcomplete basis set: A strategy employed by V1?.\u0026rdquo; Vision research 37.23 (1997): 3311-3325. ^   ","date":1596603600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612229580,"objectID":"d27f25945137f3019f6371732c05f21e","permalink":"http://crystal.uta.edu/~park/post/nnsae/","publishdate":"2020-08-05T00:00:00-05:00","relpermalink":"/post/nnsae/","section":"post","summary":"This paper presents an online autoencoder that produces non-negative sparse embedding.  ","tags":["agi","research","model","paper review"],"title":"Paper Summary: Online learning and generalization of parts-based image representations by non-negative sparse autoencoders","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" This is the paper review of the following paper.\n Legg, Shane, and Marcus Hutter. \u0026ldquo;Universal intelligence: A definition of machine intelligence.\u0026rdquo; Minds and machines 17.4 (2007): 391-444.\n While I was working on new paper on the language acquisition test, I needed a definition of intelligence. I had my own simple informal definition as an ability to behave in a beneficial way according to the sensory input. Though I am happy with my definition, academia is all about not reinventing the wheel and giving a proper credit to original authors.\nAt first I was worried because intelligence is an abstract concept and there have been a lot of ideas in the history of AI and psychology. R. J. Sternberg said that\n Viewed narrowly, there seems to be almost as many definitions of intelligence as there were experts asked to define it.\n Some pose practical stance that the definition is not important as long as we can recognize it when we see. Chris Eliasmith suggested that cognition is to researchers what pornography was to justice Potter Stewart in his book1.\nPotter Stewart said\n I shall not today attempt further to define pornography and perhaps I could never succeed in intelligibly doing so. But I know it when I see it.\n We could replace cognition with intelligence without loss of generality.\nTherefore when I found the paper by Shane Legg and Marcus Hutter, it was quite pleasant relief. Authors surveyed many definitions from the literature. Actually there is a companion paper2 which shows the collection of the definitions of intelligence. In that paper, they collected 71 definitions from the dictionary, psychologist, and AI researchers.\nBased on this survey, they propose an informal definition of intelligence as following.\n Intelligence measures an agent\u0026rsquo;s ability to achieve goals in a wide range of environments.\n What is nice about this definition is that this definition is universal meaning that it can be applied to humans, animals, and computer systems. Historically, intelligence is the term to describe human intelligence especially in the context of human intelligence test. Therefore many definitions and tests are anthropocentric. Many definitions also try to list the specific elements of the intelligence. It is like for definition of speed, listing the elements of vehicle such as engine, tire, and suspension and so on. One such example is following:\n \u0026ldquo;Intelligence is a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. \u0026ldquo; 3\n Here the ability to reason, plan, solve problems, think abstracly, etc. are all examples of the components for intelligence. Especially learning is a major component, where many people think essential for intelligence. But authors insist that learning is just one possible strategy to achieve goals in a wide range of environments even though it is an important and widely adopted in human and animals. And I agree with this view. For example, a worm can respond to various sensory input to achieve goals. But the individual agent does not learn but the species as a whole optimizes the neural circuitry with genetic evolution.\nAnother common pattern is shifting the problem to other abstract terms such as thinkging, creativity, consiousness or imagination. The follwoing examples shows this pattern:\n The ability to carry on abstract thinking. (L. M. Terman)\nThe capacity for knowledge, and knowledge possessed. (V.A.C. Henmon)\n The authors also try to derive a formal mathematical definition from the informal definition. Authors builds on the reinforcement learning (RL) framework of environment, agent, reward, observation, and action. The following figure shows a typical setup in the RL.\n Environment provides the observation and reward and the agents processes it to select appropriate actions   Given an environment $\\mu$ and agent $\\pi$, the expected future value is the sum of discounted rewards into the infinite future where $r_i$ is the reward in cycle i of a given hstory, $\\gamma$ is the discount rate, and $\\Gamma$ is the normalizing constant $\\Gamma := \\sum_{i=1}^{\\infty}\\gamma^i$.\n$$V^{\\pi}_{\\mu}(\\gamma):=\\frac{1}{\\Gamma}\\mathbf E\\left(\\sum_{i=1}^{\\infty}\\gamma^ir_i\\right) $$\nThis is the expected total reward for one environment. How we can represent diverse environment? More challenging question is how we can quantify an easy environment and a complex environment. Also how should we assign an weight to the performance (expected reward) for easy and difficult environment?\nThe main idea authors suggest is that the complexity of environments can be expressed with Kolmogorov complexity of the binary string that describes the environment.\n$$ K(x) := {min}_p \\{ l(p): U(p) = x \\} $$\nYou can think of the binary string p as the program to simulate the environment for the reference universal Turing machine U. Kolmogorov complexity is then the minimum length of the program that runs in Turing machine U. Generally if the length of program is short, the program is simple. And in this case, the fact that we have to find the minimum length makes the computation intractable for non-trivial case. You can think Kolomgorov complexity is similar with minimum description length (MDL) for program.\nWhen there are many environments, what is the probability distribution for the environment? One idea is that the probability of the existence of environment $p_{\\mu}$ might be inversely proportional to the exponential of the length or $p_{\\mu} \\propto 2^{-K(\\mu)}$. You might imagine randomly appending 0 or 1 to binary string to build a program. Therefore we can express intelligence as the expected performance of agent $\\pi$ with respect to the probability of environment $ 2^{-K(\\mu)}$ over the space of all environments E.\n$$ \\Gamma(\\pi) := \\sum_{\\mu \\in E}2^{-K(\\mu)}V^{\\pi}_{\\mu}$$\nAuthors define this as the universal intelligence of the agent $\\pi$. Authors then compare the intelligence of following agents.\n A random agent A very specialized agent A general but simple agent A simple agent with more history A simple forward looking agent A very intelligent agent A super intelligent agent A Human  It is quite nice to see that a very specialized agent gets lower intelligence score than a general but simple agent. Later the authors surveys the tests for the intelligence because the definition and the test are closely related in many cases. The list of tests are also useful for my research.\n Turing test and derivatives: Common criticism is that Turing test is not necessary to establish intelligence. Because the required knowledge level is too high, it cannot offer much guidance to the AI research. Also it depends on the human judges who are not reliable and reproducible for repeated tests. Compression tests: Compression can also represent the intelligence. An example would be summarizing papers, describing movies and so on. Linguistic Complexity: HAL project propose to \u0026ldquo;measure a system\u0026rsquo;s level of conversational ability by using techniques developed to measure the linguistic ability of children such as vocabulary size, length of utterances, response types, syntactic complexity and so on. Multiple Cognitive Abilities: Toddler turing test tries to build a young child in a similar set up to Turing test. A2I2 project tries to test performance of a small mammal. I would need to check this tests. Competitive Games: The goal is to build an AI that can do well on multiple games. This approach is popular nowadays.\n Collection of Psychometric Tests: This aims to pass the intelligence test for human such as Wechsler adult intelligence scale. C-Test: It is similar concept to universal intelligence. But the test environment is limited to sequence prediction and sequence abduction tasks. Using Levin complexity, we can measure the complexity of the each problems. Smith\u0026rsquo;s Test: An algorithm generates a series of problems for an agent. When the answer is wrong, the agent might try another answer to the same problem.  And authors suggest useful properties for tests of machine intelligence and score each tests according to the properties. Below is the summary.\n Comparison of various tests for machine intelligence.   Please note that Kolomogorov complexity is intractable for non-trivial case, therefore universal intelligence is a definition not test.\nIf we apply this metric to the Language acquisition test, I think the following can be claimed.\n Valid: debatable because it only measures language acquisition but we claim it is the core of human-level intelligence Informative: debatable for we provide many scores written as vectors. Wide Range: No General: No. because we target for human-level intelligence. Dynamic: Yes because the agent learn and adapt over time Unbiased: No because SEDRo is biased to human in western culture. Fundamental: Yes Formal: No because it is difficult to judge whether an agent has acquired language or not. Objective: No because we have to rely on the human judges. Fully Defined: No. The environment and the objective is not fully defined. Universal: No. It is anthropocentric. Practical: Yes because we are using simulator. Test vs Def: Test.  Finally in the paper, the authors response to common criticisms. Among those, I liked how they respond to \u0026ldquo;Blockhead\u0026rdquo; argument and \u0026ldquo;Chinese room\u0026rdquo; argument. To introduce those arguments to the readers, \u0026ldquo;Blockhead\u0026rdquo; argument is that a machine seems to be intelligent to pass the Turing test, but it it is in fact no more than just a big look-up table of questions and answers. This machine with simple look-up table does not seems to be intelligent, isn\u0026rsquo;t it? The \u0026ldquo;Chinese room\u0026rdquo; argument is similar. The agent in the room responds to the questions in chinese. But the agent cannot understand chinese character. But it has a big book of Chinese phrasebooks with questions and matching answers. Therefore when the agent is given the question in the chinese letter, the agent will simply search the book for the same phrase and write answer and send it back. Even though the agent pass the Turing test, does the agent understand chinese?\nThe authors claim that as long as the agent shows high $\\Gamma$ value, the internal working does not matter.\n \u0026hellip; it is not even clear to us how to define understandings if its presence has no measurable effects. \u0026hellip; if understanding does have a measurable impact on an agent\u0026rsquo;s performance in some well defined situations, then it is of interest to us. In which case, because $\\Gamma$ measures performance in all well defined situations, it follows that $\\Gamma$ is in part a measure of how much understanding an agent has.\n Personally I think these arguments are harmful influence of philosophers to engineering discipline. I agree with authors. So far, I have talked about the contents of the paper and what I liked in the paper. Now let\u0026rsquo;s talk about my criticism.\nMy criticism While I agree with their informal definition, my main criticism lies in their formal definition. I think it has a faulty assumption that rewards are equivalent to the goals. Reward system is just one of a trick to achieve goals.\nIntelligence is the concept that originated from biological agent. Therefore goals are natural to explain in perspective of biological agent. Generally we can say that the goal is to spread gene. Intelligence is one of strategy to achieve this goal. What are other strategies? Virus or bacteria have the strategy for lowering the cost of replication by hijacking to other system. Plant or phytoplankton choose the strategy of being self sufficient in addition to the lowering the cost of replication. Intelligence is more expensive strategy than these. Intelligence is selecting the behavior that will increase the chance of spreading gene according to the sensory input. This requires sensory system and central nerve system (CNS) or brain to process sensory information and control the actuators accordingly.\n Non-Intelligent vs Intelligent biological agents. Please note intelligence requires the sensory system and neural information processing system   However, at first there are different levels in intelligence strategy. Agents such as earthworms have simple brains. It has hardcoded the mapping from sensory system to the corresponding actions using simple look-up table. This lookup table is updated with evolution. Therefore while there was no learning in individual agent, the species as a whole improved this hardcoded function. A good example will be an earthworm. Charles Darwin studied earthworms for over 30 years in his house and his book The formation of vegetable mould, throuth the action of worms sold more copies than the origin of species4. Earthworms have light receptors and vibration sensors. They move according to the light condition or the vibration caused by the moles. While this is drastic improvement over the random spreading of the phytoplankton, the problem with this approach is that adaptation is very slow because the update to the neural circuit happens through evolution.\nThe next level in the intelligence arms race is individual-level learning. Relying on evolution is too slow. If an individual agent can learn new rules such as a new type of food, it can surely increase the probability of successful gene spreading. However, to enable learning at the individual level, two functional modules are required.\nThe first is a memory to store newly developed rules. I conjecture the neocortex mainly serves this memory function. The second module is a reward system to judge the merit of the state. We stated that the goal of a biological agent is to spread genes. However, the correct assessment is not possible at the individual agent level. For example, an agent laid many eggs in a hostile environment that no descendant will survive. Still, the agent cannot know this because it succumbed before this happened. Therefore we need a function to indicate whether the current stimulus or state is good or bad. A reward system fills this gap by providing a proxy signal to approximate the probability of achieving goals. If an agent eats food, the stomach and blood glucose level information enter the reward center, and it generated a positive reward signal meaning this will be perhaps good for achieving goals. The signal indicates the new rule is good and needs to be stored in the memory. Later at a similar state, the newly added rule will be executed, which is the process of learning.\nHowever, this implies that the environment does not provide a reward. Instead, it is an agent that produces a reward signal, which is the estimate of the current state by the agent about how valuable it is to achieve the ultimate goals. A dollar bill can be rewarding for some cultures but might not generate any reward to the tribal human who has never seen any money before. As for another example, when we eat three burgers for lunch, the reward for first and third burger will be different, even though it is the same object for the sake of the environment.\nTherefore, the diagram Figure 1 should be updated as following.\n Revised relationship of the agent and environment. Environment provides an observation. Some observation is used for the reward system in the agent. The resulting reward signal and the sensory information is fed into the control system.   Many different factors affect the value of the current state, such as physical fatigue, appetite, sex, or safety. A tired agent may crave both rest and sex at the same time. It looks like estimating the final value of the current state considering various factors itself is the challenging problem, and nature is again using evolution to experiment with the optimal reward function.\nAdmittedly, authors are aware of this issue. Below are quotes from the discussions.\n Strictly speaking, reward is an interpretation of the state of the environment. In this case, the environment is the universe, and clearly the universe does not have any notion of reward for particular agents. In humans this interpretation is internal, for example, that is experienced when you touch something hot. In which case, maybe it should really be a part of the agent rather than the environment? \u0026hellip; A more accurate framework would consist of an agent, an environment and a separate goal system that interpreted the state of the environment and rewarded the agent appropriately.\n Finally, I conjecture that human-level intelligence is not achievable with the maximizing the reward approach. I am planning to explain this in my new paper. The key idea is that while learning with reward is better than using evolution to improve your brain, it is still limited because the biological agent must experience the stimulus to learn it first hand. However, if you think about the hostile nature, learning with direct experience is a dangerous strategy, and what you can learn is limited. For example, a rabbit cannot try random action in front of the lion. It will be too late, and the rabbit\u0026rsquo;s experience cannot be transferred to other rabbits. Human-level intelligence tries to overcome this limitation by learning from others\u0026rsquo; experiences with language. Language learning is related to the reward. As a summary, below is my hypothetical level of intelligence diagram.\n The three level of intelligence.   Below is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n How to Build a Brain: A Neural architecture for biological cognition. ^ Legg, Shane, and Marcus Hutter. \u0026ldquo;A collection of definitions of intelligence.\u0026rdquo; Frontiers in Artificial Intelligence and applications 157 (2007): 17. link ^ Gottfredson, L. S. (1997). Mainstream science on intelligence: An editorial with 52 signatories, history, and bibliography. Intelligence, 24(1), 13-23 ^ Making sense of earthworm senses from Earthwormwatch.org. link ^   ","date":1596603600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597105234,"objectID":"dae63c5eb4b290ef8fc58bbbf14fc3b5","permalink":"http://crystal.uta.edu/~park/post/universal-intelligence/","publishdate":"2020-08-05T00:00:00-05:00","relpermalink":"/post/universal-intelligence/","section":"post","summary":"This paper defines intelligence as an agent's ability to achieve goals in a wide range of environments. And authors present elegant mathematical formulation based on the concept of rewards and Kolmogorov complexity. ","tags":["agi","research","model","environment","paper review"],"title":"Paper Summary: Universal Intelligence: A Definition of Machine Intelligence","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" This is the review of the following video.\n   AI Horizons Colloquium, Beyond IID: Meta-Learning Disentangled Causal Variables and How the World Works by Yoshua Bengio, September 17, 2019, Cambridge\n IBM has less reputation in the new renessance of AI research compared to its younger competitors such as Google and Facebook. To make the competition meaningful, IBM invested a lot of money with MIT, another big brand name that does not have a strong hold in AI. Don\u0026rsquo;t get me wrong. MIT and IBM had a lot of work in the old AI day\u0026rsquo;s. But their contribution has diminished over the repeated AI winters and when the new AI renessance came with deep learning, they had a slow start. Let\u0026rsquo;s see how this goes. This lecture is from AI Horizons Colloquium by IBM MIT AI research lab.\nYoshua Bengio is like a beacon that calls talented researchers around the world and feels like having 400-500 graduate students that his new work appears in the archive every week according to Geoffrey Hinton. What is remarkable about him is that even though he was one of the people who brough the deep learning, he acknowledges its limitation and tries to overcome. There are many fragmented community who studies Artificial General Intelligence (AGI). It is easy for them to begin with the limitation of current deep learning. What is ironical is that there are very high chance that Yoshua Bengio\u0026rsquo;s group will achieve the AGI, too. It is because of two things. First, his group is well supported and has lots of resources in terms of the talent. Second, his group has a strong background in the mathematics which might be essential for the development of the universal algorithm. Compared to his group, other AGI researchers such as Jeff Hawkins or Ben Goertzel looks like an independent inventor competiting with a Fortune 500 company.\nHis lecture focuses on the roadmaps to the AGI even though he never mentions it. His lecture contained many lessons for models and environments that our group is pursuing.\nEnvironments side We don\u0026rsquo;t have a good simulator of the real world especially involving humans.\nAnd it is crucial that environment changes continuosly because the changes in the distribution give us what is the underlying causal structure.\n Nature does not shuffle environments, we shouldn\u0026rsquo;t. L. Bottou ICML keynote\n Those problems are what our group tries to solve.\nModel side (DIM) His group is about models, so there are much more works going on that side.\nDeep InfoMax (DIM) This is interesting twist on the intrinsic rewards formulation. Simple intrinsic reward fomulation begins with predicting next state. However, using maximum likelihood estimator (MLE) does not work well. Rather by maximizing the mutual information from current state and next state can be an alternative fomulation.\n Hjelm, R. Devon, et al. \u0026ldquo;Learning deep representations by mutual information estimation and maximization.\u0026rdquo; arXiv preprint arXiv:1808.06670 (2018). Anand, Ankesh, et al. \u0026ldquo;Unsupervised state representation learning in atari.\u0026rdquo; Advances in Neural Information Processing Systems. 2019.  Attention as the feedback According to my opinion, the feedback from top-down is one of the most fundamental missing parts in the current fomulation of artificial neural net. But maybe the attention can be thought as the feedback signal where higher layer attends a subset of lower layer.\n Bengio, Yoshua. \u0026ldquo;The consciousness prior.\u0026rdquo; arXiv preprint arXiv:1709.08568 (2017).  IID and Disentangling Causal variables We need higher level independence such as objects from perception. However, constructing higher level representation is challenging.\nOne aspect of finding higher level representation is that they are independently controllable from other things. So actions to the world can guide the representation finding.\nAnother aspect of causal structure is if we map the independence well, we can update only the subset of network but if we mixed the independence, small change in the distribution leads to the update of the whole network because they are entangled.\n Bengio, Yoshua, et al. \u0026ldquo;A meta-transfer objective for learning to disentangle causal mechanisms.\u0026rdquo; arXiv preprint arXiv:1901.10912 (2019).  Even though there are no mathematical formula in the lecture, you will need a solid background on many mathematical concepts such as mutual information, generative adversarial network, probabilistic graphical model.\nBelow is my mindmap for the related papers to artificial general intelligence.\nYour browser is not able to display frames. Please visit AGI on MindMeister.AGI by Deokgun Park\n","date":1590123600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590181621,"objectID":"f5c7308b0a664fff187c912f477e8a9b","permalink":"http://crystal.uta.edu/~park/post/yoshua-bengio/","publishdate":"2020-05-22T00:00:00-05:00","relpermalink":"/post/yoshua-bengio/","section":"post","summary":"This lecture summarizies the current challenge of Deep Learning and a few approaches by Yoshua Bengio.","tags":["agi","research","model","review","environment"],"title":"Lecture Summary: AI-Horizons Colloquium by Yoshua Bengio","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" This is the paper review of the following paper.\n DeCamp, Philip, George Shaw, Rony Kubat, and Deb Roy. \u0026ldquo;An immersive system for browsing and visualizing surveillance video.\u0026rdquo; In Proceedings of the 18th ACM international conference on Multimedia, pp. 371-380. 2010.\n Summary I found this paper while searching for the case where there were longitudinal video recording of the infants. There were two previous works. One is the HomeView project by Chen Yu and Linda Smith. In HomeView project, they installed a action cam in the hat of the infants and recorded 6 hours per day for years for multiple families. The other is the Human Speechome Project by the Deb Roy. Human Speechome project is a project by MIT professor Deb Roy that he installed multiple cameras and mics around his house and recorded 9,000 hours of video of his son from the birth to 3 years. You can see the image sample in the Figure 1.\n They built 3D cad model of house by hand. And installed a wide angle fisheye camera per room. And reconstruct it as 3D immersive video.   This paper is how we can generate 3D immersive video from the fisheye camera recording. There is also a Ted talk by Deb Roy which has 3M views. The presentation skill is very good. It is a role model for presentation of HCI work. I recommend watching it. He wanted to use this data for the how human develops an intelligence and use this lesson for the training of his robot Tracy. You can read more about in this Wired article. Unfortunately, he is not there yet. He used the data for following purpose.\n He found how the visual experience and the first words are correlated.\n And he also used this technique to analyze the video of large mall for analytics.  Read here for more extensive list of the findings link\nGood points For me, this work is inspiring because it is an example that recording of full house is possible. Main challenge will be recruiting participants. Anyway, someone did it before.\nSecond, it led me to more recent work by reading papers citing this work.\n Browsing Group First-Person Videos with 3D visualization link Virtual-Real Fusion with Dynamic Scene from videos link  Third, a calibration interface might be useful to merge multiple coordinates from multiple depth camera.\n We can use manual calibration to increase the accuracy when merging point clouds from multiple camera   Bad points First it maps to only 3D building not character or furniture. We can understand this because he used one fish eye camera per room. This saves the number of camera. It was about 15 years ago. So we can understand it. The 3d immersive video using single camera is impressive.\nSecond, the data is not public. It is the same problem with the HomeView project. This data might be helpful for the AI research as Deb Roy explains in the Wired article. But the privacy issue makes it impossible to share this data as the public asset.\nI should be clear that bad points leads to the opportunity. Building upon his great work, we will add following small improvement.\nImplication First, we will use multiple LIDAR camera per rooms to remove occlusion and create a complete 3D model.\nSecond, we will try to make a public dataset.\nFinally, I am surveying 3D volumetric video a lot. We might write a survey paper about reconstructing 3D video from video recording to summarize our search.\nFurther Reading  HomeView Project link Human Speechome Project Ted talk link Wired article about human speechome project link Browsing Group First-Person Videos with 3D visualization link Virtual-Real Fusion with Dynamic Scene from videos link  Below is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n","date":1582869600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582937145,"objectID":"b9ccecc94af678d4035aed08a5e6c5f1","permalink":"http://crystal.uta.edu/~park/post/housefly/","publishdate":"2020-02-28T00:00:00-06:00","relpermalink":"/post/housefly/","section":"post","summary":"This paper presents HouseFly, which is an immersive video analytics platform where 3 years of videos from multiple camera can be shown as immersive video. ","tags":["agi","research","environment","paper review","3D animation"],"title":"Paper Summary: An Immersive System for Browsing and Visualizing Surveillance Video","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"This is the paper review of the following paper.\n Rinkus, Gerard J. \u0026ldquo;A cortical sparse distributed coding model linking mini-and macrocolumn-scale functionality.\u0026rdquo; Frontiers in neuroanatomy 4 (2010): 17.\n I found this paper while searching for the sparse coding implementation. His work claimed 91% performance on MNIST and 67% on Weizmann event dataset. While this result is weaker than the state of the art result (around 99%), the following aspects were interesting.\nFirst, Sparsey model uses sparse distributed representation (SDR) rather than dense representation. Second, Sparsey model does not use any of optimization including gradient back propagation. It can do one-shot learning meaning that only one example is required for learning. Actually, the weights between neurons are binary and they are set by single occurence in Hebbian manner. These two attributes are what I were considering required for my model. Only comparable model is HTM by Numenta. However, HTM does not have any performance evaluation result with popular dataset except a few synthetic toy dataset.\nThe main algorithm transforms binary inputs into sparse distributed representation.\n The sparsey algorithm produces sparse distributed representation (SDR) from the binary inputs. If the input patterns are very similar to previous patterns, the resulting SDR code will be almost same to previous codes while novel patterns will result in novel code.   The key insight is that the algorithm uses the familarity or novelty measure to control randomness of the resulting code. As a result, a well-known code or familar codes result in same representation as the previous case while the novel code results in the different code. The author calls it similar inputs map to similar codes (SISC).\nThere were many neuroscience references which will be useful for my future research. For example, cells in the minicolumn possesses simiar receptive field characteristic or tuning. This fact is also utilized in the HTM and cloned HMM. The cells in the column shares the same inputs.\nAlso SDR is used in the cells as can be shown in below figure.  The Calcium images of L2/3 of rat visual cortex reveals sparse distributed representation (SDR). Images from Ohki et al (2005).  \nOne big question for me is that if we define SISC as the binary bit overlap, the incoming input already possess the SISC property. While the algorithm creates more sparse version of the binary input, how the sparse representation can be utilized is a big question.\nIs the simplication the core process the cortical columns are doing? In my opinion, the prediction is the main task. After several hierarchy, the mnist digits might be separated to constant representation, but it does not tells about how the motion should be generated.\nAs a conclusion, this paper provides a good rationale behind the use of SDR verus dense or local code. But the model is not good for my purpose. I will look at the logistic regression with Lasso regularization as the next candidate.\nBelow is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n","date":1580709600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581357441,"objectID":"ed1ebf6b27b2b4da923f1cf417d17999","permalink":"http://crystal.uta.edu/~park/post/sparsey/","publishdate":"2020-02-03T00:00:00-06:00","relpermalink":"/post/sparsey/","section":"post","summary":"This paper presents Sparsey model which uses sparse distributed coding or representation (SDR) to build a hierarchical classifier. The main idea is using familarity to control the randomness of representation. But the simplication poses limited applicability. ","tags":["agi","research","model","paper review"],"title":"Paper Summary: A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"This is the paper review of the following paper.\n Goertzel, Ben, and Vladimir Bugaj. \u0026ldquo;AGI preschool: a framework for evaluating early-stage human-like AGIs.\u0026rdquo; In Proceedings of the 2nd Conference on Artificiel General Intelligence (2009). Atlantis Press, 2009.\n How we can evaluate the artificial general intelligence(AGI) is an open challenge in the community as suggested in this paper. We can start with the imitation test sometimes called Turing test. However, it is too difficult. We are struggling to find the basic principle of learning but the Turing test requires an adult level of knowledge. We can use all the knowledge in the world to trick the bot. Also because the agent in the Turing test is imitating the humans, there are many tricks that can fool humans into believing. For example, Eliza imitates an psychotherapist who keeps asking a question, and the recent winner from Loebner Prize mimics a russian teenager who learns English to fool the judges.\nOther tests such as College Student test is adopted to block these loopholes. However, one major limitation of this approach is that they don\u0026rsquo;t deal about how these agents acquire these skills.\nBen Goertzel and Stephan Vladimir Bugaj suggests an alternative framework for AGI testing resembling preschool. It has similar curriculum for human including linguistic, social, logical-mathematical, nonverval communication, spatial-visual, object manipulation, social skills.\nIt is an advanced framework compared to other scenarios that it includes how they can acquire those skills. But in my opinion, it is still too challenging. We need to focus more earlier period, especially from inception to 24 months.\nTo solve the challenge of social learning they propose to use VR technology where a human participant controls avatar. And they suggest to use the physics engine to simulate realistic object manipulation.\nAfter they pass the AGI preschool, the roadmap to more capable AGI is apparent. That they can build AGI grade school, secondary school, and so on.\nMy main criticism is that they are taking verbal and non-verbal communication as given. For example, to test AGI they suggest following tests.\n Write a set of instructions; speak on a subject analyse how a machine works review a musical work create a mime to explain something coach or counsel another  Actually, language acquisition is the main challenge that needs to be tackled even before AGI preschool.\nBelow is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n","date":1580709600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580790557,"objectID":"e30010d7ef9048eaf30e64fe3f3f7824","permalink":"http://crystal.uta.edu/~park/post/preschool/","publishdate":"2020-02-03T00:00:00-06:00","relpermalink":"/post/preschool/","section":"post","summary":"The main idea is using an environment that resembles a preschool. I think it is an improvement over other tests such as Turing test, College Student test, or 8th grader test. But it still does not answer how the agent acquire communication skill using human language. ","tags":["agi","research","environment","paper review"],"title":"Paper Summary: AGI Preschool: A Framework for Evaluating Early-Stage Human-like AGIs","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"This is the paper review of the following paper.\n Adams, Sam, Itmar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J. Storrs Hall et al. \u0026ldquo;Mapping the landscape of human-level artificial general intelligence.\u0026rdquo; AI magazine 33, no. 1 (2012): 25-42.\n The field of AGI is chaotic. For 70 years, there were many ups and downs. Still, we don\u0026rsquo;t have a consensus about how we can assess the human-level artificial general intelligence. This paper is an effort of many experts in the AGI field to derive a method to assess the AGI.\nThey start from Piaget and Vigotsky\u0026rsquo;s theory about developmental psychology. Piaget\u0026rsquo;s model starts with sensori-motor stage where an infant learns to coordinate perceptual and motor skills such as reaching, grasping, crawling, and walking. Vygotsky\u0026rsquo;s theory emphasize the role of others and social learning.\nWith this in mind, they present previous scenarios for assessing AGI. They are\n General Video-game learning Preschool learning Reading comprehension story or scene comprehension school learning (highschool or college) Wozniak Test   Scenario Milestones on the AGI Landascape   This paper is helpful for my research because it states the assessment scenario is an important challgenge in the AGI community.\n One challenge is to find tasks and environments where all of these characteristic are active, and thus all of the requireements must be confronted. A second challenge is that the existence of an architecture that achieves a subset of these requirements does not guarantee that such an architecture can be extended to achieve other requirements while maintaining satisfaction of the original set of requirements.\n Also it lists the requirements for the such scenarios that I can apply to my planned environment.\n Required Characteristics for AGI Environments, Tasks, and Agents.   I criticize that they are all focusing on too challenging scenarios without plan to achieve it. The assessing scenarios should focus on the earlier stage when the agents begins to acquire language while developing sensor-motor skills. In this sense, general video-game learning and preschool learning are relevant. However, general video-game learning lacks how the skills from each game will be accumulated and transferred to other games. Preschool learning is similar to our planned environments, but the main difference is that pre-school learning assumes that the agent has already acquired the communication capability as can be shown in the tasks highligted.\n A few example tasks for Preschool Environments. I highlighted the tasks where communication with human language is required.   However, we don\u0026rsquo;t know how we can teach such communication skill to achieve artificial agents yet.\nBelow is my mindmap for the related papers to artificial general intelligence. Your browser is not able to display frames. Please visit References on MindMeister.References by Deokgun Park\n","date":1580364000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580744828,"objectID":"3186236cf5316f0dcad004272f839041","permalink":"http://crystal.uta.edu/~park/post/mapping-the-landscape-of-human-level-agi.md/","publishdate":"2020-01-30T00:00:00-06:00","relpermalink":"/post/mapping-the-landscape-of-human-level-agi.md/","section":"post","summary":"This paper shows an overview of AGI capabilities from developmental psychology, mathematical, physiological, and information processing perspectives. Also it discusses how to evaluate AGI using environments, tasks, and scenarios.","tags":["agi","research","environment","paper review"],"title":"Paper Summary: Mapping the Landscape of Human-Level Artificial General Intelligence","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Human level intelligence test I propose a language acquisition as the test for the human-level intelligence. If we raise baby animals like a human baby, they will not learn human language. They are capability limited. If a human baby is raised in the jungle without any human interaction, they cannot acquire human language. They are environment limited. We can say that the language acquisition is the function of the capability and the environment. Therefore, if any agent can learn language given the proper environment, we can say that the agent has the capability for human level intelligence.\nLanguage acquisition environment For the proper environment, we need other humans to teach language. There are many social mechanisms that enable this. Caregivers use motherese or infant-directed speech (IDS). The baby attends where the caregiver attends (joint attention), and the baby imitates what they see. To provide artificial agent this environment, there are two approaches. The first is using physical robots and asking the real humans to be caregivers. Given the current state of the art, this can be cost-inhibitive and not reproducible. The second is using simulated environment, but programming the caregivers to teach diverse and reasonable responses to the random behaviors of the learning baby agent is a scientific challenge. I plan to overcome this by limiting the scenarios and contexts for the environment and approximating mother behavior. As a concrete example, let‚Äôs say that we invite 100 pairs of the mother and child to play on the play at with a few toys. We capture their motions using motion capture system and build the behavior library. For example, if 20 babies touched duck toy during the experiment, we can record 20 responses of the mothers. In the simulator, when learning agent touches the duck toy, the mother character will play one random behavior out of 20 possible reactions.\nModel development Using this environment, we will develop a model that can learn by observing and interacting with other human-like pre-programmed agent. There are two parts for the model.\nFirst, we need a common cortical algorithm that is a universal machine given a vector as an input that can predict next state vector. Hierarchy plays an important role here to overcome the trade-off between long-term predicton and training data.\nSome candidates for the possible algorithms are below\n Clonned HMM by Vicarious HTM by Numenta Hierarchical Prediction Network (HPNet) by Qiu et al.  Note the vector representation changes from Sparse binary (HTM) to dense continuous (HPNet). Personally I prefer sparse binary but it can be functionally equivalent as in the electric motor and combustion engine in the vehicle. We also need to batch multiple modules in a heterarchical way as the society of minds. A good example is the contour-surface factorization in the RCN paper. We will need many more modules to handle sensory motor, auditory and so on. The executive functions on the prefrontal cortex can be built on the same principle while working on higher layer vectors that was generated as final output vectors in other modules.\nSecond we need a supporting innate mechanisms to help these universal modules learn from the world. I believe the reward signal plays an important role here. We can learn lots of lower layers from the principle of predictive coding or intrinsic rewards where the action from the agent generates the next sensory inputs by training modules to predict next states. However, there are too many exploratory space in the world that an agent cannot learn from trial and error. The key in observational learning is studying innate mechanisms that can guide the learning agent to observe other humans and learn from them. For example, there are social rewards which can signal the learning agent that this is important sequence and needs to be memorized with increased focus. Newly inborn at least attends other humans speaking motherese more than other static objects or humans. There should be some kind of BIOS that can fill the contents of the blank state in the universal modules with meaningful content.\nRoad map Once we have a model that can do observational learning in the simulated environment, we can port this model to the embodied robots and use real humans to teach the language. I believe that the model that can learn the vocabulary of two years can be easily extended to the reading level because it learned the concepts grounded in the sensori-motor sequence.\n","date":1575612000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578508059,"objectID":"11361d252193bbcfe578d8eb103329a9","permalink":"http://crystal.uta.edu/~park/post/observational-learning/","publishdate":"2019-12-06T00:00:00-06:00","relpermalink":"/post/observational-learning/","section":"post","summary":"Below I summarize my plan for building artificial general intelligence (AGI). I start with the test for AGI, and then goes into environments and models for it.  ","tags":["agi","research"],"title":"Observational Learning: How I would build AGI","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Olfactory learning Nowadays you hear artificial intelligence or machine learning frequently.\nWhat is the difference between intelligence and learning?\nGeneral words such as intelligence and learning are difficult to define. Rather than trying to define, comparing the meanings can be helpful to understand both concepts.\nIntelligence is the rules to active actuators according to the sensory input to improve one\u0026rsquo;s wellbeing. Learning is acquiring new rules after birth. In this sense, intelligence does not need learning.\n There can be intelligence without learning and intelligence with learning.   Bees that show intelligent behavior does not rely on learning. All their smart rules are encoded in the genes. Similarly my calculator is intelligent. But I don\u0026rsquo;t think they are learning.\n This calculator is advertised as intelligent calculator, but it does not have the ability to learn new trick.   While trying to build an AI, humans tried first to infuse rules by hand. But soon they found there are two fundamental problems. First, there are too many rules. Not only the number, many rules was contradictory each other. Second problem was the symbol-grounding problem.\nAfter some failure, we arrived at the consensus that to build human-level intelligence, machines needs to learn itself. Interestingly, this idea of learning machine appears in the Alan Turing\u0026rsquo;s seminal paper, Computing machinery and intelligence (1950).\n Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child\u0026rsquo;s? If this were then subjected to an appropriate course of education one would obtain the adult brain. Presumably the child brain is something like a notebook as one buys it from the stationer\u0026rsquo;s. Rather little mechanism, and lots of blank sheets. (Mechanism and writing are from our point of view almost synonymous.) Our hope is that there is so little mechanism in the child brain that something like it can be easily programmed. The amount of work in the education we can assume, as a first approximation, to be much the same as for the human child.\n One way to think about the AI and AGI is where the general part comes. General part comes from the ability to learn new skills. Therefore learning is a required condition of the AGI, too.\n   What is the sufficient condition for the AGI?     I think a language acquisition or learning is a sufficent condition. Can an agent learn language by trial and error? You can read more about this    Learning is very expensive.\nMost animals cannot afford it.\nIf you make a mistake, you die. And there is no way to transfer your knowledge to descendants using genes. Your exploration to the world cannot benefit the survival of your genes. How dare animals begin learning?\nThink of cars. Modern luxury cars have lots of complex modules such as adaptive cruise, ABS, regenerative braking, hybrid motor, all wheel drive, GPS navigation, 8 way sound system, memory seat, AC and heater and so on. If anyone try to build a car one hundred years ago, will he consider all the complex modules of the modern cars? Probably not. He will only focus on how to rotate wheel without human manual muscle. That\u0026rsquo;s why the first cars had barely Minimum parts to implement a function. They had a motor and battery connected to wheels. Or they had an steam engine.\n The first car accident   So if we look at modern human brain, there are lots of fancy complex modules interconnected.\n Components required for reaching and grasping. There are many modules for controling hand gesture. Image from Schema theory by Michael A. Arbib (1998)   Then if we want to reverse-engineer learning, trying to copy from the human brain is trying to learn how to build a first car from the modern luxury cars. Let\u0026rsquo;s properly assume you don\u0026rsquo;t know what CPU and memory are because you are from one hundred years ago. The modern cars have 50-100 CPUs. Can we make sense what\u0026rsquo;s going on here?\nAll of previous arguments are to claim that we need to look at the minimum parts to implement a function to build a learning machine.\nOlfactory system is a candidate for such a system. We belive it is the minimum parts because it is oldest. How do we know it is oldest? Because it goes back to the lizard.\nMany readers might got the idea when I mention that lizard. They can skip the next part. But for the rest who do not have a clue, let me introduce crash course on the brain evolution.\nWhen we look at the brain there are many parts just too many parts. But if we simplify mercilessly, there are three major parts, hindbrain, limbic system, and neocortex.\nHindbrain takes care of basic tasks that should be automatic. No learning should occur here. We should not learn how to breathe or maintain body temperature. It should be built in. Otherwise our chance of survival will be too thin. This came first in the evolution and it is deep inside. The last part, neocortex is where the human level intelligence is happening. It begins with the blank state and fills as we learn. This came last in the evolution and located in the surface or outside.\n The Triune Brain clusters brain into three major parts as hindbrain, limbic system, and neocortex.   Limbic system is what is in the middle. It came second and located in the middle between hindbrain and neocortex. This simplication is called the triune brain. Previously limbic system is claimed to be old mammalian brain and it is believed to handle emotions. However, it is discovered in the common ancestors of reptiles and mammals.\n The Limbic system is composed of olfactory sensor, hippocampus, and amygdala   It is composed of olfactory sensor, hippocampus, and amygdala. Olfactory sensor is simple chemical sensors. The neurons in the olfactory sensors fire according to the chemical input. Amygdala is taking control of emotions. You can simplify emotions as a change of body reactions to the same stimulus depending on the chemical concentration in the animal.\nAmygdala controls the release of the chemicals. In this sense, it is an actuator.\nTo make situation ruthlessly simple, let\u0026rsquo;s say there are only two reactions, to approach or to avoid. (Of course there are others such as mating or fighting.) Let me clarify the same stimulus part to avoid confusion. Of course when we see food, we approach and when we see a tiger, we avoid. But let\u0026rsquo;s see you see an unidentified object, something you never seen or know. If your blood has more approach chemical, you will approach it. While if your blood has more avoid, vice versa. This thing, unidentified object, is important concept in the learning. Your gene may hard code the food and the predator. You don\u0026rsquo;t need learning to handle that case. But it is when you have a new stimulus that requires learning. Which is a learned reponse and different response for the same stimulus.\nAs a concrete example, when a mouse hears a certain bell and gets the food, he associates approach with the bell sound. But if a poor mouse next cage gets the electrical shock to the same bell sound, he will associate the sound with avoid reaction.\nSo we have a sensor and an actuator. What else we need to build a learning system? Learning system by definition has to have a mechanism to store input and connect or associate appropriate actions. Hippocampus is the one who is taking care of the associative memory.\nAs a summary, the minimum parts to implement learning is a sensor, an actuator, and a memory. Let\u0026rsquo;s call it a minimalistic learning module.\nDo you have an experience that when you smell something, it reminds me of your home or childhood memory? It is because the olfacory sensors and hippocampus are very directly connected compared to complex routing in other modules in the brain. We guess that it was the first sensor that connected to learning module because the olfactory sensors are directly connected to the hippocampus while other systems are connected through thalamus. Thalamus is the information hub. There are many sensors coming in and coming out.\nOne interesting question to ask is why olfactory sensor was connected to this first learning machine.\nThe need to learn new food source might be an motivation. But why animals rely on the odor rather than the visual shape or sound? My guess is that chemical ordor has far lower dimension than other sensory input such as vision and auditory signals. To generalize over the visual system, we need far more processing and storage power. For example, a visual signal can be composed of 640 by 480 pixel value while odor signal can be characterized by 10 numerical values.\n","date":1568869200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568909889,"objectID":"3514a9170cdb12691afb327df23446d8","permalink":"http://crystal.uta.edu/~park/post/olfactory-learning/","publishdate":"2019-09-19T00:00:00-05:00","relpermalink":"/post/olfactory-learning/","section":"post","summary":"Intelligence is the rules to actuate actuators according to sensory input to improve one's well-being. Learning is acquiring new rules after birth. Learning requires sensors, actuators, and memory. Olfactory learning is the first learning that can give insight to the minimum parts for learning. ","tags":["agi","research"],"title":"Olfactory learning","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"Below is adopted from forward in my Ph.D disseration.\n A man\u0026rsquo;s character is his fate. - Heraclitus\n It all began with the naƒ±ve and lazy man‚Äôs dream. I wanted interesting information to come to me even though I didn‚Äôt know if such information existed, and I didn‚Äôt search for it. I am lazy but addicted to information. I am also a Maximizer. According to the book The Paradox of Choice: Why More Is Less by Barry Schwartz, a Maximizer is the kind of person who scans all the available cereals in the supermarket and tries to select the best one. Frankly speaking, I envy the Satisficers because they will choose whatever option meets the requirements and forget about the rest.\nThat‚Äôs how I initially became interested in recommender systems, which are a class of algorithms that recommend something to my taste, as Amazon and other web-based services that are trying hard to extract more money from us. Also, from my previous experiences with wearable technology, I knew that the ability to extract valuable information from data will be the key component in the so-called big data value chain. Without the ability to turn data into insights, big data is just investment and cost. Analytics will be what generates revenue and profit.\nHowever, the journey never goes as expected and you never know where you will end up when you are setting out. Such was my Ph.D. I started with recommender systems, but the recommendations they make are not satisfactory due to limitations in the quality of these algorithms. It may be rather contentious to suggest that recommender systems algorithms are limited. Indeed, the world is changing and you never know if the next big scientific breakthrough will improve them to be more effective. But as anecdotal evidence to support my claim, Netflix never ended up using the state-of-art algorithms from the famous 1 million dollar competition. The algorithm showed top-performance, but the performance gain was not meaningful to justify the algorithm implementation cost.\nThat‚Äôs when I started to look for alternatives. Did I already tell you that I am a Maximizer? Therefore I concluded that we need to amplify the cognitive ability of the user to tackle the challenges of big data value creation. That was the focus of my Ph.D., presented here, with five design studies. The ideal ending will be that I am satisfied with my methodology and live happily ever after. But after six years of study, I see some fundamental limitations in the visual analytics (VA) approach as well. Those limitations are 1) VA systems are application/domain specific, 2) dependence on back-end algorithms that usually rely on the bag-of-words model, and 3) the requirement of user intervention (this can be both desirable and undesirable. But I am rather lazy.)\nSo here I am packing light again to find more fundamental ways to achieve my dream. Recent advances in neural networking look promising, and, being inspired by those advances, I want to build upon them to start a new journey into this untapped area. I am excited, afraid, humble, and foolish on this new journey.\nIf you want to know more detail, you can read my research statement.\n","date":1568782800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568828055,"objectID":"2440c50f07d8728a6a3146a13ec5b142","permalink":"http://crystal.uta.edu/~park/post/intellectual-journey/","publishdate":"2019-09-18T00:00:00-05:00","relpermalink":"/post/intellectual-journey/","section":"post","summary":"I was lazy and news-addict that I wanted news story that suits my interest flows towards me. I started with recommender system but soon found that it cannot deal with the delicacy of human language. I studied visual analytics to combine human intelligence with machine learning for the text analysis. But still found it unsatisfactory. Now I am studying grounded language which lead to artificial general intelligence research.   ","tags":["agi","Visual Analytics","research"],"title":"My intellectual journey","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"My job is thinking and talking.\nI do reading and writting.\nI like learning and teaching.\n","date":1568264400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568308104,"objectID":"6886a023107d193afaeaa99b1831a4c4","permalink":"http://crystal.uta.edu/~park/post/a-scholar/","publishdate":"2019-09-12T00:00:00-05:00","relpermalink":"/post/a-scholar/","section":"post","summary":"A poem about my job","tags":["poem"],"title":"A scholar","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"Listening to an old professor\nwho devoted his whole life\nlooking for the holy grail\ncouldn\u0026rsquo;t find it\nhanding over scattered clues\nto young, ignorant yet ambitious students\nlike once he was\nin the hope that allowed more time\nhe could finally see how minds work\nknowing that his time is over.\n","date":1568264400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568828055,"objectID":"4f2063cd924b89a9edb7c098bdb471d0","permalink":"http://crystal.uta.edu/~park/post/society-of-mind/","publishdate":"2019-09-12T00:00:00-05:00","relpermalink":"/post/society-of-mind/","section":"post","summary":"A poem about the society of mind (book) by Marvin Minsky","tags":["poem"],"title":"The Society of Mind","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":"I get many emails from master students who are interested in reserach.\n I would like to get research experience in my lab. May I join your lab as a master student?\n Below you can find my advice. TLDR, if you plan to pursue PhD after your master, it might be a good idea to experience research in my lab. If you plan to industry career, it might not.\nYou can contact me and discuss your interest. However, if you want to get a job after graduation, doing research with me might not be helpful. You might get a better chance for the job by preparing the coding interview. The research takes time to produce a meaningful outcome. And the research is a full-time job. For example, it is common that it takes more than two years before a phd student can produce a paper or meaningful software. However, this can be too late for the master students who need something to show to potential employer during first semester and third semester. Doing research is more beneficial for those who consider phd program after graduation.\nStill there are many masters student working in my lab. I encourage you to contact them.\n","date":1565067600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565105936,"objectID":"6e6fe2f39189ef68295dd2273703753e","permalink":"http://crystal.uta.edu/~park/post/master-research/","publishdate":"2019-08-06T00:00:00-05:00","relpermalink":"/post/master-research/","section":"post","summary":"If you plan to pursue PhD after your master, it might be a good idea to experience research in my lab. If you plan to industry career, it might not. ","tags":["student advice"],"title":"Advice for the master students who want to do reserach in my lab","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Recently, I got an email from a smart undergraduate student who was interested in research. I think his situation might be a common case so here I added my reply in the hope that this can be helpful to other students. Below is the modified email message.\n I have been talking with few graduate recruiters and found out that graduate schools don‚Äôt offer scholarship unless I am doing PhD or thesis (which I had no idea what that meant). All I wanted to do was to get a masters degree to gain enough knowledge on AI and deep learning and work for companies like DeepMind or Neuralink to bring AGI and ASI to real life. And now I am overwhelmed and lost with what I‚Äôm supposed to do. My options are to loan my way through graduate school (but I can‚Äôt do that since I am already on a huge debt for my undergraduate school), or get a PhD (this will take me forever and I will never be able to pay my loans back with the stipend), or find a job (until I am able to pay by loans and fund my graduate school but I really want to be on AI). I recently figured out that my major (computer engineering) wasn‚Äôt right for me. I decided to switch to computer science but I needed to take more classes so I am switching to software engineering to graduate on time with right the classes. My mind‚Äôs all over the place and I have no idea where to seek help from. I‚Äôm only halfway through the book even though I love it. I have been dying to learn Reinforcement Learning but I haven‚Äôt got time even to start searching about the resources.\nThank you so much, Dr. Park! I hope you have a wonderful rest of the day.\n Below you can find my advice. TLDR, it is okay to get a job if you are on a debt. If you think you are interested in the research, try to study on your own for a year or two. If you are still interested, you can consider a PhD.\nMy answer to the student Hi, Tomas (Name changed for privacy)\nI understand your position.\nBelow is my advice. The choice is yours. There is no right or wrong choice. The choice is based on who you are and in return shapes who you will be.\n to loan my way through graduate school (but I can‚Äôt do that since I am already on a huge debt for my undergraduate school),\n The graduate school here must be master‚Äôs degree, right. I don‚Äôt recommend it, either. You cannot get enough knowledge on AI topic and you don‚Äôt have enough time to create a knowledge that will make you attractable hire for companies like Deep Mind.\n or get a PhD (this will take me forever and I will never be able to pay my loans back with the stipend),\n It does not take you forever. It is actually somewhat short to do what I describe above. It will pay you back reasonably well if you are successful. But the decision cannot be made solely on financial reward because this financial reward is probabilistic. Better motivation would be the pursuit of knowledge or curiosity. And the reward is auxiliary. For example, you usually do not pursue professional baseball career because most of baseball related careers are not well-paid. Only winner takes it all.(I hope the chance is higher in the CS.) But many still pursue it because they enjoy baseball anyway.\n or find a job (until I am able to pay by loans and fund my graduate school but I really want to be on AI).\n This is an actually good option. Get a job. Get decent salary and pay your loans. The trick is that you can study AI on your own with online learning education resource nowadays. This can be sometimes better than what the Master‚Äôs degree can offer. When you study enough and you have a non-trivial question, it will be a good time to pursue PhD. Of course, consult with professors about your question.\nAttending academic conference is a good investment. Studying alone is actually harder than you might think. You will be busy for the job (actually everyone is busy, right? Even my 9th grade daughter is busy because she has to watch three hours of youtube videos in addition to all the school work and violin and archery practice) and you may find the AI study is not so fun. The good news is that if you don‚Äôt like it, you don‚Äôt have to do it. It means that you are probably not good fit for the PhD. Don‚Äôt worry. You have a job already and you can focus on the software engineering career which can be also very rewarding. According to my opinion, I think about 5% of the people with good school grades are actually good fit for the PhD. The main reason is that we get good grades by learning what others have found. But PhD is about finding new knowledge which is very different from learning what others have found.\nAs a summary, I think you have a potential. If you really want to study AI and deep learning now, you can get a PhD now. If you are not sure, it is okay to get a SWE job. If you find that you keep studying on AI and DL for one or two years on your own, you might consider getting a PhD.\nRegards\nDeokgun\n","date":1565067600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568308104,"objectID":"d836ea05e94048f86891c48151975cb2","permalink":"http://crystal.uta.edu/~park/post/graduate-school/","publishdate":"2019-08-06T00:00:00-05:00","relpermalink":"/post/graduate-school/","section":"post","summary":"If you are not sure, getting a SW job is okay. If you study AI by yourself for one or two years, you might consider applying for PhD program.","tags":["student advice","career"],"title":"Advice for the undergraduate students who consider the graduate school","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Recently, I got an email from a student from HDILab. I think his situation might be a common case so here I added my reply in the hope that this can be helpful to other students. Below is the modified email message from the student.\n Hello Dr.Park,\nI am trying to implement carracing. I am using a virtualenv python3.5.4. I am trying to run extract.bash using $sudo bash extract.bash. However, it returns\n‚Äù File ‚Äúextract.py‚Äù, line 8, in  import gym ImportError: No module named gym‚Äù when extract.bash is trying to run extract.py.\nThe problem is I installed gym and box2d-py too, and yet it shows the import error.\n$ which pip /home/aishwarya/WorldModelsExperiments/carracing/venv/bin/pip\n$ which python\n/home/aishwarya/WorldModelsExperiments/carracing/venv/bin/python\nI‚Äôve also tried the solutions given in here and in here\nCan you please help me out with this issue.\n Below you can find my advice. TLDR, if you have a technical problem. Solve it on your own while producing shareable outcome. If you have a research idea, your advisor can help you evaluate whether it is intractable, already done, or trivial.\nMy answer to the student Hi, Tomas (Name changed for privacy)\nI don\u0026rsquo;t know about this. You should check Google or ask other person\u0026rsquo;s in the lab. I think Jane and John might know.\nDon\u0026rsquo;t worry. Debugging this kind issue is common. I myself always deal with this issue. One of the reason, I cannot help is that the reason can be diverse. It is case by case. Therefore it is more important to know how to deal with these kind of issues than the actual specific solution. There will be hardly anyone who can solve your technical problem with a clear answer. If you have one you are lucky. But still if you ask to much questions to him, you are actually costing a precious resource to the group which is a bad news for you. Below are some general advices.\n Use slack general channel. If you send email to one person, the chance is low that your busy and ignorant professor can help you. If you use slack to post your issue to the entire group, some competent students might help you.\n Make environment simple. 90 Percent of these issues are package version collision. Virtual env helps but not perfect. In old days I used to format frequently. That\u0026rsquo;s why I use one disk for system and one disk for home directory. Nowadays learning how to use docker will pay you back well in the long run.\n Try to learn generalizable lesson and share it. Most of time, you just fix and forget. You might try stack overflow or Google solution until you fix it. The problem with this approach is that the time you spent on solving this issue does not produce any credit for your work. While I also sometimes do that, the correct way to handle an issue is that first understand the reason of the issue and create a technical note or blogs that explains the issue and the solution. Many people in the lab can benefit your contribution and your technical blog will help building your professional reputation. You need to be accustomed to solve these kinds of issues. It is like growing your muscles.\n  How to use your advisor If your advisor cannot help you solve your technical issues, where can I use him? One area is when you have a research question. As a graduate student, you will always think the research question or the topic for the next paper. There can be two major pitfalls for setting the research topic. An academic work is about finding a knowledge that none has found before. There can be two reasons why nobody has done it before.\nFirst, it can be too difficult to do or trivial but not meaningful. When we think a new idea, I can bet there will be more than 10 people who have thought the same thing. Still the finding the solution might be too difficult. Time machine, teleportation, or thinking machines are those areas. Those are technologies that people wish but it is very hard to make a progress in those area. Or more commonly, your topic is slightly general and there can be many approaches to it. However, the topic might be well-known in the community and almost all low hanging fruits are taken already and what remains might be too challenging.\nSecond, your problem might be too narrow or trivial or already solved before. Your advisor is like a guide to the Mt. Everest or a chaperone to the party. He has an experience and background knowledge about the research community.\nTherefore getting a cross check of your idea can be a good use of your advisor.\n","date":1565067600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582823446,"objectID":"dbd9435e0f3601e2c69d958eac3fb883","permalink":"http://crystal.uta.edu/~park/post/how-to-use-your-advisor/","publishdate":"2019-08-06T00:00:00-05:00","relpermalink":"/post/how-to-use-your-advisor/","section":"post","summary":"If you have a technical problem. Solve it on your own while producing shareable outcome. If you have a research idea, your advisor can help you evaluate whether it is intractable, already done, or trivial. ","tags":["student advice"],"title":"How to use your advisor","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Below is HDILab culture. A culture is a principle about how we do everyday things. I hope that our culture shape our group in a productive way.\nWe learn by teaching. Every week we will have a paper reading seminar where one student will teach a paper to other lab members. A pizza and a diet coke will be provided. You will have a chance to announce what you are working on nowadays in a friendly environment 30 minutes before the seminar. Currently the seminar starts on Wednesday 12:30pm.\n After you have done lab seminar, add the slides and all materials into the Google drive here. The goal here is to make it easier for a new lab member to follow what we have done so far. Also write one paragraph abstract for the seminar to summarize what you teach. Add your call sign so that we can know who did the seminar. Students should answer the questions from colleagues.  Team play There are focused hours in the lab where students are supposed to be at the same space and time. The main idea is to have an informal chat, update, questions and answers. The focused hours are currently held Mon, Tue, Wed 10am-2pm at ERB 205. Don‚Äôt be late. If you think you will be late, report it to the slack.\nSharable output Students are required to maintain a lab journal and project journal Lab journal is for the general purpose work and project journal is for the project related progress. For example,\n I set up the new server or hardware for the-\u0026gt; hdilab journal I organized the inventory -\u0026gt; hdilab journal\n I replicated the world model -\u0026gt; daivid journal I read a paper -\u0026gt; a blog article for paper summary (This is an example )  Every work should be recorded and reproducible. Basically journal is for yourself. But write it well when others have to find something you did. When you accumulate enough work and progress, make them shareable and transferable chunk into three places:\n journal how-to technical note When you create a new technical note leave a author call sign such as #deokgun so that I can find who wrote what. If you need to update it, add a call sign and date after the original author.\nExample Created: #deokgun 01/08/2019 Updated: #sanjay 01/09/2019  Personal homepage blog article\n Github readme.md\n  One common mistake for the new member is writing a technical note about a topic that is already covered in previous technical note from other members. This is problematic in the two sense. First, it means that you did not search or read other\u0026rsquo;s technical note. A value of the technical note is how many times it is read by others. If no one reads others\u0026rsquo; technical note, the value of our journal will be nothing. Second, you are creating an additional burden for the future readers looking for a solution for the topic. In that sense, you are creating a noise if you are creating a redundant article. So what we should do when we found that the topic that we would like to wrtie is available. Check the original post and if you have an additional content, just update the original post. If you are sure that you can write a better one by rewriting, replace the original post. The original post should be archived to the old technical note and referenced by the new article.\nWe share the open source code and how-to manual as a final output. We use GitHub as the main archive As a rule of thumb, I expect 50% of everyone‚Äôs time will be spent writing what you have done.\nHow to write a journal  Make the outline neat If you click the View-\u0026gt; Show Document Outline button, it will show you the document outline. Make sure your writing follows the header rule. There is a shortcut key for selecting the paragraph level.\ncmd + alt + 1 makes the top level heading cmd + alt + 2 makes the second level heading cmd + alt + 0 makes the content paragraph, which is not shown in outline.  The Things to do next part is important. Your professor reads it often. Keep it tidy. When something is done, remove. Update it everyday. When you are given new goal, write it there. Make the thing you are working on now, the first item. Order them in the priority.\n  Communication is half of your job. Your impact will be the multiplication of research and communication of the result. Try to report the progress whenever there is a progress Don\u0026rsquo;t wait until your boss ask your progress. Tell him what you are working on now. If you meet a barrier or decide to change direction, report it. When I ask you to do something, I usually expect to hear the progress report in a one or two days.\nBeing true to ourselves You cannot deceive yourself. Being true to yourself is, in my opinion, a very good long-term strategy. For example, if you don‚Äôt know during the seminar, acknowledge that you don‚Äôt know and ask questions until you understand. Don‚Äôt be embarrassed or give up by social pressure. Academy is a few places where being true to yourself is tolerated.\nOther good question to ask yourself is whether you are enjoying the research. Actually according to my experience, research is not for everyone. Probably about 5 persons out of 100 suit the academic life. Because of this, it is perfectly okay if you feel that the graduate study is not what you want to do. I recommend to get a SW engineering job in that case, which actually pays you better and provides better work-life balance. You might feel like a failure to quit the research at first, but if you are true to yourself, you may find it as one of the best decisions of your life later.\nSimilarly I will release you out of the lab if I think that you are not a good fit for the lab as early as possible. How I make that decision? First, I have to acknowledge that it is very difficult decision for me, too. It is not only emotionally difficult but intellectually difficult. Because nobody knows the future, one day the student I fired may get a Nobel prize.\nI have to follow the lab culture which is my principle. For me, there are three characteristics for the academic career.\n First is curiosity. The desire to know or find the truth is our strongest motivation and rewards.\n Second is the self-starting. This one is related to curiosity. Because you want to know something, you start researching about it. This is usually observed when the student comes to me and ask an advice for something. It is the opposite of waiting for the order from me.\n Third is the persistence. The journey is long and the rewards are sparse. If you are not persistent, chances are you give up. Persistence is measured by the shareable output. According to my experience, quantity is more important than the quality for measuring persistence. It means if you are producing lots of so-so blog article or technical note and low quality draft of academic papers, you have the persistence. Think about growing academic muscle by writing everyday.\n  ","date":1565067600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580745241,"objectID":"3f80f58bdfbdbbcdacb6f39ae8597a48","permalink":"http://crystal.uta.edu/~park/post/hdilab-culture/","publishdate":"2019-08-06T00:00:00-05:00","relpermalink":"/post/hdilab-culture/","section":"post","summary":"In HDILab, we learn by teaching. Do not study or work but create a sharable output.  Be true to yourself.  ","tags":["student advice"],"title":"The HDILab culture","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Life evolves. The speed of evolution depends on the mechanism of the evolution. The first evolution was based on the random mutation of genes. It is basically trial and error. But the diversity of the life forms it generated is awesome. I would call it hard evolution. We, humans, are one of the successful life forms with mosquitoes and cockroaches.\nHuman adopted a new strategy. It was building a more flexible general purpose brain to adapt to the environment. Other life forms also have the brain. But its function was more rigid or hard encoded. You can think how the pocket calculator compares with the smartphone. Both have a similar electronic components namely CPU, memory and I/O devices.\nUsing the general brain, we can do many things that was not possible. But the essential function is learning. In hard evolution, the special variation that worked well leaves the genes. However, in soft evolution, we can learn from others. It basically allows exponential trial and errors. Nobody can experience all the diverse experience in the world given limited time and energy. Still we can learn from others first using verbal language. This allowed us to transfer knowledge from nearby people. The written language allowed it to go beyond the limitation of the space and time of the verbal language. Now what is beautiful about the soft evolution is that the time it takes to evolve has reduced dramatically. The soft evolution happens in the brain circuitry during the life time of the agent while in the hard evolution, the life time of the agent was a single unit of progress.\nBecause of this general flexible brain, we are born with a rather blank state compared to other animals such as cats and dogs. (Of course there are still many innate circuitry which I will talk later about.) And it takes relatively long time to have a reasonably working program. Interestingly as the amount of the information to function well in the society increases the time it takes to be independent is also increasing. Now it is common in the first world that it takes about 20 to 30 years before one can be independent from their parents.\nI said the brain is born as a basically blank state. But still there are innate mechanism to help learn from the parents. Think of the truly blank state agent. We got a continuous stream of image and sound. How we can make sense of the these images? For example, parents talking to the baby might look like a skin colored chunk with a few holes that are constantly moving. One hole continuously changes shape and make a sound (hint: mouth). How can we learn this chunk of image is a mom and the sound is the language which is different from random noise from the street? Epistemology is an old branch of philosophy devoted to this problem.\nI think the innate mechanism is essential for the new born baby to make sense of the world. Let me give you an example. Andrew Meltzoff and Keith Moore found that a baby who was about 7 hours since the birth can still mimic the tongue movements. It is quite surprising when we think about all the skills to do this. First, the baby has to recognize the human face. Then he has to map the human face he never seen to his face that he never seen himself. Finally the baby has to control the tongue to imitate the expression.\n New born baby can imitate the random facial expression. This capabilities an innate mechanism to help learn from others. We should learn from relevant objects such as people and care givers and not from irrelevant objects such as cars or doors. Image from Science 1977   I believe this imitation capability is essential to learn from others. Given blank state, we should not fill this blank with random noise but relevant contents. What will be the relevant contents for the new born baby. Most likely it will be from the parents and caregivers. The imitation mechanism has already filtered irrelevant objects in the world and focused on the human facial expression and followed its motion. This limits the vast space of the exploration to meaningful trajectory that was suggested by human.\nLessons for the AGI In the famous DQN paper, there are experiments for the Atari games. Among many games that showed superhuman performance by the artificial agent, there was one game that showed very poor performance called Montezuma\u0026rsquo;s revenge.\n  This blog explains why the Montezuma\u0026rsquo;s revenge game is particularly challenging. In a summary, there are too many things that have to be done sequentially such as getting the key, avoid the monster, and go back to the door. The random behavior by the agent cannot explore the vast exploration space in a limited time. In 100 Million iterations, the agent can access only the second stage. This shows the limitation of the random trial and error. I said other animals cannot learn. But I was wrong. They can learn. For example, dogs can learn new trick. They learn by trial and error. They associate behaviors with positive rewards or treats. But things you can learn from this approach is limited.\nI think there are three components for the artificial general intelligence. The first is a model. For example, in my HPM theory, the agent predicts the next sensory input with the help from the hierarchy to do the higher-order prediction (chunking). The second is an environment. It provides a source of information. The problem is there are vast space for exploration. Finally there will be many smart tricks such as imitation or social mechanism to focus on the human interaction during language acquisition to reduce this search space effectively by social learning. Our lab tries to build an environment that can provide a testbed for such social mechanism and study the models.\nFinally, what will be the next step for the evolution? It will be how we can overcome the limitation of the biological brain cell. The brain cell is relatively slow and degradable. The number of cells are limited by how large our head can be to enable the birth and feed required energy to run big brain. If we can use our electronic components as a device, it will achieve a step-up in the evolution speed. But more importantly, I think the true power of the next evolution is when the artificial intelligence agent upgrades its own structure. This upgrades will be beyond the human\u0026rsquo;s ability to follow which is called technical singularity. Some would call it computational evolution.\n The evolution of the intelligence   ","date":1564981200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576258492,"objectID":"9e80d9eba7c40220c7be82fbc83fd54e","permalink":"http://crystal.uta.edu/~park/post/soft-evolution/","publishdate":"2019-08-05T00:00:00-05:00","relpermalink":"/post/soft-evolution/","section":"post","summary":"The first evolution mechanism was based on the DNA. The second evolution mechanism was based on the brain. The third  evolution mechanism will be based on algorithms","tags":["agi","research"],"title":"Evolution: Hard, Soft, and Computational?","type":"post"},{"authors":["Deokgun Park"],"categories":null,"content":" Contents  Introduce the role of the rewards in reinforcement learning  Use the example of dog training Explain the dopamine Explain the  Introduce an extrinsic rewards  Classic rewards Used in reinforcement learning examples  Atari Alpha Go World model paper   Introduce an intrinsic rewards\n Explain the limitation of the extrinsic rewards  Montezuma\u0026rsquo;s revenge  Explain the mechanism of the intrinsic rewards  How the curious or explorative behavior relates to the intrinsic rewards How to formulate the intrinsic rewards mathematically?  Model-free vs model-based reinforcement learning Intrinsic rewards examples  Introduce paper by Stanford World Discovery Model paper   Introduce the limitation of the intrinsic rewards\n The search space is too vast for a single agent learn by exploration\n Example: Radnom permutation of alphabet to generate a meaningful sequenc. Example: Musical note\n  Explain the higher order Markov chains\n   Introduce the social rewards\n Introduce the imprint Introduce how the baby learns  Learn by imitation Joint attention Gated learning  Theory based mathematically driven algorithm vs quick dirty rule based system  Future research direction\n Models that take into account the innate mechanisms Environments that can test the models with social rewards   Reward plays a key role in the reinforcement learning.\nIn this post, I will explain three types of the rewards that can shape the intelligent behavior.\n Extrinsic rewards: A reward triggered by the external entity. Intrinsic rewards: A reward that can be generated by the agent himself. Social rewards: A rewards that can be generated by the social activities  Extrinsic rewards Extrinsic rewards means the positive or negative reward triggered by the external entity. A concrete example is the Previously rewards meant mostly extrinsic rewards.\nIntrinsic rewards Social rewards A search space to generate a meaningful space is very vast and only very few are meaningful. But we can learn from others the meaningful sequence which reduces the search space\nThis can be expressed with music note.\nShould we use reward mechanism or reflex mechanism?\nImprint is an example of reflex mechanism. Because we have the freedom to follow or not, I think reward mechanism makes more sense.\nReferences  Jones, Susan S. (2012-12-10). \u0026ldquo;Human Toddlers\u0026rsquo; Attempts to Match Two Simple Behaviors Provide No Evidence for an Inherited, Dedicated Imitation Mechanism\u0026rdquo;. PLOS ONE. 7 (12): e51326. Bibcode:2012PLoSO\u0026hellip;751326J. doi:10.1371/journal.pone.0051326. ISSN 1932-6203. PMC 3519587. PMID 23251500 Jones, Susan S. (2009-08-27). \u0026ldquo;The development of imitation in infancy\u0026rdquo;. Philosophical Transactions of the Royal Society B: Biological Sciences. 364 (1528): 2325‚Äì2335. doi:10.1098/rstb.2009.0045. ISSN 0962-8436. PMC 2865075. PMID 19620104. Rowland, D.C., Yanovich, Y. and Kentros, C.G. (2011). A stable hippocampal representation of a space requires its direct experience. Proceedings of the National Academy of Sciences. 108(35). 14654-14658. -\u0026gt; An evidence for Gated language CONSPEC and CONLERN: a two-process theory of infant face recognition. J Morton, MH Johnson - Psychological review, 1991 - psycnet.apa.org Evidence from newborns leads to the conclusion that infants are born with some information about the structure of faces. This structural information, termed CONSPEC, guides the preference for facelike patterns found in newborn infants. CONSPEC is contrasted with a\n Newborns\u0026rsquo; preferential tracking of face-like stimuli and its subsequent decline MH Johnson, S Dziurawiec, H Ellis, J Morton - Cognition, 1991 - Elsevier Abstract Goren, Sarty, and Wu (1975) claimed that newborn infants will follow a slowly moving schematic face stimulus with their head and eyes further than they will folow scrambled faces or blank stimuli. Despite the far-reaching theoretical importance of this ‚Ä¶ How the brain processes social information: searching for the social brain TR Insel, RD Fernald - Annu. Rev. Neurosci., 2004 - annualreviews.org ‚ñ™ Abstract Because information about gender, kin, and social status are essential for reproduction and survival, it seems likely that specialized neural mechanisms have evolved to process social information. This review describes recent studies of four aspects of social Eye contact detection in humans from birth T Farroni, G Csibra, F Simion‚Ä¶ - Proceedings of the ‚Ä¶, 2002 - National Acad Sciences Making eye contact is the most powerful mode of establishing a communicative link between humans. During their first year of life, infants learn rapidly that the looking behaviors of others conveys significant information. Two experiments were carried out to demonstrate ‚Ä¶  ","date":1564981200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568217054,"objectID":"31334378b8fe8152420ce9ac4e6886cf","permalink":"http://crystal.uta.edu/~park/post/rewards/","publishdate":"2019-08-05T00:00:00-05:00","relpermalink":"/post/rewards/","section":"post","summary":"Extrinsic rewards is for the animal or bug level of intelligence. Intrinsic rewards or curiosity enables efficient navigation in the vast exploration space. Social rewards enable imitation or gated learning which reduces the exploration space.  ","tags":["agi","research"],"title":"Rewards for AGI","type":"post"},{"authors":["Deokgun Park","Steven M. Drucker","Roland Fernandez","Niklas Elmqvist"],"categories":null,"content":"  Sequence of layout operations to generate a unit column chart for survivors of the Titanic by passenger class.   ","date":1538016791,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538237872,"objectID":"f2aba7552741a49797bb1b7afbffe7d3","permalink":"http://crystal.uta.edu/~park/publication/atom/","publishdate":"2018-09-26T21:53:11-05:00","relpermalink":"/publication/atom/","section":"publication","summary":"Unit visualizations are a family of visualizations where every data item is represented by a unique visual mark - a visual unit - during visual encoding. For certain datasets and tasks, unit visualizations can provide more information, better match the user's mental model, and enable novel interactions compared to traditional aggregated visualizations. Current visualization grammars cannot fully describe the unit visualization family. In this paper, we characterize the design space of unit visualizations to derive a grammar that can express them. The resulting grammar is called ATOM, and is based on passing data through a series of layout operations that divide the output of previous operations recursively until the size and position of every data point can be determined. We evaluate the expressive power of the grammar by both using it to describe existing unit visualizations, as well as to suggest new unit visualizations.","tags":["Information Visualization"],"title":"Atom: A Grammar for Unit Visualizations","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536469200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538188338,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"http://crystal.uta.edu/~park/tutorial/example/","publishdate":"2018-09-09T00:00:00-05:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Deokgun Park","Seungyeon Kim","Jurim Lee","Jaegul Choo","Nicholas Diakopoulos","Niklas Elmqvist"],"categories":null,"content":"  The CommentIQ UI showing toggleable visualizations such as scatterplot, map, and timeline (left) that enable overview and filtering of comments, as well as an adjustable ranking based on various weighted quality criteria (right).ConceptVector supports interactive construction of lexicon-based concepts. Here the user creates a new unipolar concept (1) by adding initial keywords related to tidal flooding (2). The system recommends related words along with their semantic groupings (3), also shown in a scatterplot (4), revealing word- and cluster-level relationships. Irrelevant words can be specified to improve recommendation quality (5). Concepts (9) can then be used to rank document corpora (10). Document scores can be visualized in a scatterplot based on concepts such as tidal flooding and money (7). Users can further refine concepts based on results (8).   ","date":1517195878,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538237872,"objectID":"b66bafc1a63aa7d16637aa7c7c4931de","permalink":"http://crystal.uta.edu/~park/publication/conceptvector/","publishdate":"2018-01-28T22:17:58-05:00","relpermalink":"/publication/conceptvector/","section":"publication","summary":"Central to many text analysis methods is the notion of a concept: a set of semantically related keywords characterizing a specific object, phenomenon, or theme. Advances in word embedding allow building a concept from a small set of seed terms. However, naive application of such techniques may result in false positive errors because of the polysemy of natural language. To mitigate this problem, we present a visual analytics system called ConceptVector that guides a user in building such concepts and then using them to analyze documents. Document-analysis case studies with real-world datasets demonstrate the fine-grained analysis provided by ConceptVector. To support the elaborate modeling of concepts, we introduce a bipolar concept model and support for specifying irrelevant words. We validate the interactive lexicon building interface by a user study and expert reviews. Quantitative evaluation shows that the bipolar lexicon generated with our methods is comparable to human-generated ones.","tags":["Text Analysis","Visual Analytics","Open-ended Tasks"],"title":"ConceptVector: Text Visual Analytics via Interactive Lexicon Building Using Word Embedding","type":"publication"},{"authors":["Deokgun Park"],"categories":null,"content":"","date":1483250400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548263775,"objectID":"b114db2e37f3222e6421fb54941f18d1","permalink":"http://crystal.uta.edu/~park/talk/naver/","publishdate":"2017-01-01T00:00:00-06:00","relpermalink":"/talk/naver/","section":"talk","summary":"A comment section, such as for an online news article, video, or social media post, is commonly a place to share personal opinions. However, when there are too many comments, it is challenging to gain new insights and estimate the distribution of the public opinions simply by reading them. Selecting and promoting high-quality comments can mitigate those problems, but the required resources for choosing them manually are too high for common practice. In this talk, I will introduce my research on visual analytics for comment analysis. The ability to see an overview of the comments and to create custom rankings supports moderators, editors, and commenters themselves. I also propose a method to aid semantic analysis where users can build custom dictionaries for unique concepts and use them to analyze comments. In the future, assessing public opinions will play an important role in protecting the digital democracy against organized attempts to manipulate public opinions.","tags":[],"title":"Visual Analytics for Comment Analysis (in Korean)","type":"talk"},{"authors":["Deokgun Park","Simranjit Sachar","Nicholas Diakopoulos","Niklas Elmqvist"],"categories":null,"content":"  The CommentIQ UI showing toggleable visualizations such as scatterplot, map, and timeline (left) that enable overview and filtering of comments, as well as an adjustable ranking based on various weighted quality criteria (right).   ","date":1474950413,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538237872,"objectID":"f7a8d1ac5322c7c1c36cc05d2b9bf386","permalink":"http://crystal.uta.edu/~park/publication/commentiq/","publishdate":"2016-09-26T23:26:53-05:00","relpermalink":"/publication/commentiq/","section":"publication","summary":"Online comments submitted by readers of news articles can provide valuable feedback and critique, personal views and perspectives, and opportunities for discussion. The varying quality of these comments necessitates that publishers remove the low quality ones, but there is also a growing awareness that by identifying and highlighting high quality contributions this can promote the general quality of the community. In this paper we take a user-centered design approach towards developing a system, CommentIQ, which supports comment moderators in interactively identifying high quality comments using a combination of comment analytic scores as well as visualizations and flexible UI components. We evaluated this system with professional comment moderators working at local and national news outlets and provide insights into the utility and appropriateness of features for journalistic tasks, as well as how the system may enable or transform journalistic practices around online comments.","tags":["Text Analysis","Visual Analytics","Open-ended Tasks"],"title":"Supporting comment moderators in identifying high quality online news comments","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461733200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538188338,"objectID":"80be3c9fcc86014efab0cec0f14957f6","permalink":"http://crystal.uta.edu/~park/project/deep-learning/","publishdate":"2016-04-27T00:00:00-05:00","relpermalink":"/project/deep-learning/","section":"project","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit.","tags":["Deep Learning"],"title":"Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":1461733200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538188338,"objectID":"553a94c5dfd3b8b099d8a12b2d248093","permalink":"http://crystal.uta.edu/~park/project/example-external-project/","publishdate":"2016-04-27T00:00:00-05:00","relpermalink":"/project/example-external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["Deokgun Park"],"categories":null,"content":" Hello,\nMy name is Deokgun Park and I lead Human Data Interaction Lab (HDILab) in the Department of Computer Science \u0026amp; Engineering at the University of Texas at Arlington. In this article, I will explain the problems we are solving at HDILab. In Human Data Interaction Lab, we are studying artificial general intelligence (AGI).\nMany students already have an idea about artificial intelligence (AI). But artificial general intelligence or AGI might be a new term. So let\u0026rsquo;s start with what AGI is.\nClarifying AI and AGI Since Marvin Minsky and other researchers gathered at Dartmouth College in Hanover in 1956, the goal of AI was to build a machine that can do many tasks like humans. But after experiencing a few AI winters, the academic focus shifted to building models to perform a single application because it was more tractable. This approach has been frequently called machine learning (ML). It is said that one of the reason ML has been coined was to avoid mentioning AI in the proposal during the AI winters. It was successful, and we achieved many advances in specific applications such as image classification, machine translation, self-driving car, or playing Go game. And the term AI became hot again.\nBut we still lack an idea about how we can build a general-purpose AI which appears in Hollywood movies or general public associates with. Because most of the current AI research is application-specific, we need another term for the original general purpose agent. It has been rephrased many times, including\n strong AI true AI human-like AI movie-like AI lifelong learning continual learning meta learning or learning to learn artificial general intelligence (AGI)  We will use AGI to refer this original AI because it tells the fundamental difference between the current mainstream AI research, which is application-specific.\n AI vs AGI. AI started as a general purpose model, but later changed its meaning to mostly application specific models. We will use artificial general intelligence (AGI) to mean the original general purpose model.   How to test AGI Before we discuss how we can build AGI, let\u0026rsquo;s start with how we can test if we built AGI. Because according to Peter Drucker or Lord Kelvin,\n If you can\u0026rsquo;t measure it, you can\u0026rsquo;t improve it.\n Alan Turing suggested a test to verify AGI. According to the Turing test, also known as Imitation Game, a human participant asks an agent hidden behind the wall to perform many tasks. If the human cannot discern whether the agent is truly a human or an artificial agent, then the artificial agent is assumed to achieve a human-level intelligence.\n In the movie Ex Machina, you can see how Turing test is conducted.   While theoretically valid, it poses several problems in its practical application. First, it is too difficult for the current status of research. The human tester can use all the knowledge about the world to test the agent, yet it would be very costly and impossible to teach all the knowledge about the world to the artificial agent, while researchers struggle to discover how we can mimic human-like learning. It is like asking a 1st grader to take SAT test.\nSecond, the test does not provide any idea about where the model can learn those knowledges required to take test. It is like testing students without giving them any textbooks or lectures.\nThird, even for the same model and the same evaluator, the feedback will be different from today to tomorrow. The test is subjective and not reproducible.\nFinally, it is prohibitively expensive to hire people to conduct a test. Humans may participate in annual Turing test competition, but during the hyperparameter tuning or iterative model refinement, it is difficult to get access to human testers. For these reasons, it is not practically applicable in the current renaissance of the AI.\nWe propose an alternative test method for AGI. This method is based on the observation that even if we raise cats and dogs, treating them like human babies, they cannot learn to speak. The animals are capability-limited, and the human baby cannot learn to speak if it is separated from people speaking to it. It is environment-limited. Therefore we can think that the language acquisition is the function of the environment and the capability of the learning agent. In other words, if an agent can learn how to speak in a proper environment, we can say that it has the capability to do artificial general intelligence. We call it the Language Acquisition Test for AGI or Park\u0026rsquo;s test.\n In Park\u0026rsquo;s test, the agent is said to have a human-level intelligence if it can learn language given the proper environment   To pass a Park\u0026rsquo;s test, we needs a capable model and a proper environment. Let\u0026rsquo;s look at environment first.\nThe Environment for the Language Acquisition To conduct the Park\u0026rsquo;s AGI Test, an agent requires an interaction with the world to learn how to speak. One factor that enabled the recent advances in reinforcement learning was the use of the simulated environments such as Atari games or 3D first person shooting games such as VizDoom. Those environments can be used to build and test an agent that can optimize its behavior with little instructions while maximizing the reward signal as a goal to train an agent. However, environments and reward signals adopted in those studies are primitive and more suitable for the development of low-level intelligence which can be found in fish or bugs.\n               Atari Environment Car Racing Environment RoboSchool Environment    If we want to build an agent with human-level of intelligence, we need to use an environment that can provide a reasonable sensory input and feedback that can teach an agent how to speak. One naive way to provide such an environment is using real people to provide the required responses or trainings. However, using real people has similar limitations with the Turing test. We will have to explore many models in a trial and error before we can finally build an AGI. In addition to the prohibitive cost of using human participants, human experimenters will become quickly tired of providing the same feedback again and again or providing different feedback to the same situation which does not lead to reproducible research.\n   Advanced Discussion: What is language?     Some would claim that the poor baby abandoned in jungle will still develop a language to communicate with other animal. Similarly there is an emergent communication pattern among collaborative robots. While true, we are interested in human language in this project especially for human robot interaction. The rationale is that we want the robot to learn human language not vice versa.    There are a few prior researches in language acquisition. Devendra Singh Chaplot and other researchers in the Carnegie Melon University used VizDoom environment to demonstrate how agent can learn semantic concepts using reinforcement learning. In their experiments, agents get rewards when they go to objects according to the verbal direction such as \u0026ldquo;Go to short blue torch\u0026rdquo;. What is interesting is that during the training the agents experience verbal direction such as \u0026ldquo;Go to blue torch\u0026rdquo;, \u0026ldquo;Go to torch\u0026rdquo;, \u0026ldquo;Got to short red torch\u0026rdquo; and so on but never experience \u0026ldquo;short blue torch\u0026rdquo;. Even then during the test time, they can follow the direction to go to \u0026ldquo;short blue torch\u0026rdquo;. This implies that the agent can map the words such as \u0026ldquo;short\u0026rdquo;, \u0026ldquo;blue\u0026rdquo;, \u0026ldquo;torch\u0026rdquo; with the visual features in the objects. This is a step forward to solve the symbol grounding problem.\n Agents learns language using reinforcement learning. Image by Devendra Singh Chaplot et al   But the concepts that can be learned in this way is limited. There are limitations due to the environments. We don\u0026rsquo;t learn by fetching objects according to the parent directions. It will take too long to learn all concepts this way. We need a better environments that can teach the language\nWhen the transistor was first invented, people were excited to use it as an amplifier to build radio and radars. But the true power of the transistor was when it was arranged in a specific structure, it could build a logic gate. By arranging logic gates in a specific way, we could build a CPU, the true ultimate power of transistor.\nThe same goes with the connectionism. We know how one or two neural cell behaves exactly and we can simulate them. But most advancement came with the arrangement of this device in a specific ways, such as multi-layer perceptron (MLP), convolutional neural net (CNN), recurrent neural net (RNN), and generative adversarial network (GAN). In this sense, we are experimental computer scientist who seek the right structure mostly by trial and errors. Because of this nature, it is helpful to have an environment that can provide an easy, low-cost, and reproducible way to experiment.\nIn our lab, we would like to develop an environment for Park\u0026rsquo;s test. The key idea is that we will focus on the critical stage of the human development when humans learn how to speak as infants. This environment will contain a 3D replication of a room in the home with a few toys. There will be a mother character and a baby character. The mother character will be programmed manually using traditional game AI technology to take care of the baby and lead a conversation with the baby character which is often called a baby talk, child-directed speech (CDS), motherese or infant directed speech (IDS). IDS is a communication pattern, when a mother tries to teach language to an infant. The baby character will be the learning agent. The success of the test will be decided by whether the learning agents can acquire language and develop reasonable behavior comparable to the human developmental progress.\n Previous environments have led the advancements of the reinforcement learning. We propose a novel environment for the language learning.   Hierarchical Prediction Memory (HPM) HDILab also studies the model that can learn the language in the environment described above. Let\u0026rsquo;s start our discussion from the function and the mechanism.\nFunction and Mechanism The most difficult way to fly is to imitate the biological mechanism of flying such as in birds or flies. The biological mechanism is highly evolved due to the long history of adaptation. And many of the complex mechanism is due to the biological limitation which does not apply to us. What we need to figure out is what those mechanism are actually doing or function. The way human or horses run is pushing the ground backward. The way birds fly is pushing the air downward. This applies to the intelligence. The biological mechanism is very complex. It has been very optimized. It has to use biological lossy devices. So the mechanism is very complex. But we need to learn what is the function of the mechanism. It is in my opinion prediction of vector sequence. Hierarchy helps to overcome the temporal limit by chunking. The essence of intelligence is hierarchical prediction of vector sequence.\nWe conjecture that the essence of the intelligence is a hierarchical prediction.\nWhere the original connectivist has missed? The original connectivist thought the decision or pattern recognition as the core activity. However, this lead to the wrong formalization of the problem? In my opinion, prediction should be the core activity. Prediction includes the decision or pattern recognition, but the main difference is that it has the streaming input and streaming output.\n","date":1461128400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568217054,"objectID":"59de895a25b9e24e0fe72f00b1f2227a","permalink":"http://crystal.uta.edu/~park/post/research-in-hdilab/","publishdate":"2016-04-20T00:00:00-05:00","relpermalink":"/post/research-in-hdilab/","section":"post","summary":"Artificial General Intelligence (AGI) Research at Human Data Interaction Lab (HDILab)","tags":["agi","research","student advice"],"title":"AGI Research in HDILab","type":"post"},{"authors":["Deokgun Park","Jungu Choi","Niklas Elmqvist"],"categories":null,"content":"  The MovieVis tool. Two groups in the movie space have been selected to compare corresponding user distribution. Two movies selected in the upper-center region‚ÄîOne flew Over the Cuckoos Nest (1975) and Amadeus (1984)‚Äìand are shown in blue color. Another two movies selected in a lower-center region‚ÄîPhenomenon (1996) and Twister (1996)‚Äîare shown in orange. The highlighted users are those who liked all both pairs of movies (because the group mode is set to common). Based on the user space axes‚Äîgender for the horizontal and age for the vertical‚Äîwe can see that while the movie One Flew Over the Cuckoo‚Äôs Nest and Amadeus were favored by male reviewers of all ages, the Phenomenon and Twister were liked by relatively younger male audiences.    On the left, we compare two movies, Toy Story (1995), in blue, and Scream (1996), in orange, according to the age, location and similarity criteria for users. Some notable observations are while the former is liked all around the U.S. by any age groups the latter is mostly popular in the eastern part and within a younger generation. On the right, we compare two users, a 19-year-old male student, in blue, and a 51-year-old male educator, in orange according to the average, release date, and similarity criteria for movies. We observe that the older user tends to rate older films highly. In addition, his average review tends to conform to the average ratings patterns of all users while the younger user seems to deviate from it.   ","date":1459266011,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538237872,"objectID":"6dfd7923368efd00696a61be7c219db1","permalink":"http://crystal.uta.edu/~park/publication/parallelspace/","publishdate":"2016-03-29T10:40:11-05:00","relpermalink":"/publication/parallelspace/","section":"publication","summary":"We present ParallelSpaces, a novel method to explore bipartite datasets in both feature and data dimensions. This dyadic data is displayed as weighted bipartite graphs using scatterplots in two separated visual spaces, where each entity is positioned according to multi-dimensional properties of each entity or similarity in preferences. Selecting or navigating in one space is reflected in the other space, so that organic visual patterns can be formed to facilitate the characterization of underlying groupings. To aid visual pattern recognition we also overlay a contour plot based on kernel density estimation. We have implemented two instantiations of ParallelSpaces for (a) movie preferences, and (b) business reviews as Web-based visualizations. To validate the method, we performed a qualitative user study involving eleven participants using these Web-based tools to explore data and collect deep insights. ","tags":["Information Visualization","Visual Analytics"],"title":"Parallelspaces: Simultaneous Exploration of Feature and Data for Hypothesis Generation","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538188338,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"http://crystal.uta.edu/~park/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]