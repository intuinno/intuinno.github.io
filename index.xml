<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deokgun Park on Deokgun Park</title>
    <link>http://crystal.uta.edu/~park/</link>
    <description>Recent content in Deokgun Park on Deokgun Park</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Feb 2021 00:00:00 -0600</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>What to do after reading a paper</title>
      <link>http://crystal.uta.edu/~park/post/howto-read-paper/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/howto-read-paper/</guid>
      <description>

&lt;p&gt;We read a lot of papers. I thought it would be beneficial if I document how I organize the summary.
Sometimes, I am in a hurry and read a lot of papers before summarizing them.
This results sometimes in anxiety and even worse what you learned will be easily lost.
By following standarized procedure for reading papers, I hope I can overcome this.&lt;/p&gt;

&lt;h3 id=&#34;my-procedure-2-0-updated-2-1-2011&#34;&gt;My procedure 2.0 (Updated 2/1/2011)&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;After you read the paper, move it to one drive.&lt;/li&gt;
&lt;li&gt;If you have hand-written annotations in the printed paper, replicate it on the file.&lt;/li&gt;
&lt;li&gt;Add the print to the binder.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Add new entry on the &lt;a href=&#34;https://www.notion.so/intuinno/49bedcbdfd944e43b4b02c7798269edd?v=ceb7c38f8373441cbf4dce44183fe17c&#34; target=&#34;_blank&#34;&gt;paper references database in HLAI wiki&lt;/a&gt;. HLAI wiki is built using notion service.&lt;/li&gt;
&lt;li&gt;If there is interesting images, add them to the wiki page.&lt;/li&gt;
&lt;li&gt;Add comments in the wiki page. A few place holders will be following.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt; What is this paper about?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good&lt;/strong&gt; What are good points?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bad&lt;/strong&gt; What are my criticism?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implication&lt;/strong&gt; How I can use this work? What will be different from my approach?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Future Readings&lt;/strong&gt; Include some more references&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;(Optional) If the paper is highly relevant and you might write about it in other documents (papers, grants), or there is a comment worth sharing with the rest of the world, write a blog post in the homepage. Here is &lt;a href=&#34;http://crystal.uta.edu/~park/post/nnsae/&#34; target=&#34;_blank&#34;&gt;an example post&lt;/a&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;(Optional) If the paper is worth sharing with the lab members, organize a paper seminar to disseminate it.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;2/1/2021 Update&lt;/strong&gt;
Previously, I used mind mapping to see overview of the paper. But as the number of papers grow, it was difficult to see it in the mindmaps (&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;mindmeister&lt;/a&gt;, &lt;a href=&#34;https://atlas.mindmup.com/intuinno/artificial_general_intelligence/index.html&#34; target=&#34;_blank&#34;&gt;mindmup&lt;/a&gt;). Thus I switched to notion for the management. Also writing summary posts takes too much time while I still believe it is helpful. Thus I created a default pass for normal papers and an optional pass for highly important papers. Below is my original procedure for the record.&lt;/p&gt;

&lt;h3 id=&#34;my-procedure-original&#34;&gt;My procedure (Original)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;After you read the paper, move it to google drive.&lt;/li&gt;
&lt;li&gt;If you have annotation with pen and highlighting marker, replicate it on the file.&lt;/li&gt;
&lt;li&gt;Add the reference to &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;the reference mindmap&lt;/a&gt;. I embedded the mindmap in the post.&lt;/li&gt;
&lt;li&gt;If there is an interesting pictures, save photos to the google drive Paper figures folders and attach it into the mindmap.

&lt;ul&gt;
&lt;li&gt;You might change the filename of the captured image such that you can upload it to homepage.&lt;/li&gt;
&lt;li&gt;Copy those figures to homepage/static/img folder.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Start summarizing the paper in the mindmap. A few place holders will be following.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt; What is this paper about?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good&lt;/strong&gt; What are good points?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bad&lt;/strong&gt; What are my criticism?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implication&lt;/strong&gt; How I can use this work? What will be different from my approach?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Future Readings&lt;/strong&gt; Include some more references&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;After summarizing them, add those summary in the homepage review post. Here is &lt;a href=&#34;http://crystal.uta.edu/~park/post/mapping-the-landscape-of-human-level-agi.md/&#34; target=&#34;_blank&#34;&gt;an example post&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Finally, if the paper is worth sharing, add the paper to HDILab journal with the link to the summary post such that it can be shared.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Definition and a Test for Human-Level Artificial Intelligence</title>
      <link>http://crystal.uta.edu/~park/publication/definition_hlai/</link>
      <pubDate>Thu, 28 Jan 2021 22:17:58 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/definition_hlai/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./img/3levels.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Three levels of intelligence&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/language_theory.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Learning with language means that the symbolic description brings the same changes to the model comparable to direct experiences.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Modeling social interaction for baby in simulated environment for developmental robotics</title>
      <link>http://crystal.uta.edu/~park/publication/modeling/</link>
      <pubDate>Mon, 26 Oct 2020 21:53:11 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/modeling/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./img/sedro_babymind.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Screenshots from SEDRo environments. (a) Fetus environment. Almost dark space with no visual capability of the baby. (b) After birth house environment with a Mother character and some other toys. &amp;copy; Mother is feeding the baby. (d) Mother is showing a toy to the baby&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>An open-world simulated environment for developmental robotics</title>
      <link>http://crystal.uta.edu/~park/publication/laow2020/</link>
      <pubDate>Sat, 26 Sep 2020 21:53:11 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/laow2020/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./img/big_picture.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Ecosystem of SEDRo Environment&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summary: Online learning and generalization of parts-based image representations by non-negative sparse autoencoders</title>
      <link>http://crystal.uta.edu/~park/post/nnsae/</link>
      <pubDate>Wed, 05 Aug 2020 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/nnsae/</guid>
      <description>

&lt;p&gt;This is the paper review of &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0893608012001451?casa_token=WYDIO2ntGhQAAAAA:B29Tp8xM_QevE28SHvAOVdn8nXVPCaGSOdZ90BY4vAI-YXUv4gYbknpJt_-TLjiWB7ki2pHHe4M&#34; target=&#34;_blank&#34;&gt;the following paper&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Lemme, Andre, Ren√© Felix Reinhart, and Jochen Jakob Steil. &amp;ldquo;Online learning and generalization of parts-based image representations by non-negative sparse autoencoders.&amp;rdquo; Neural Networks 33 (2012): 194-203.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This paper presents a variation of autoencoder (AE) models. It is estimated that the human visual cortex uses basis functions to transform an input image to sparse representation&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;br /&gt;
Autoencoders seem to be good models for the process because they can produce embedding representation with different dimensions from the original signal. Training of the model is also easy because we don&amp;rsquo;t need labels for the inputs but use the difference from the original input and the recovered input from embedding as an error function.&lt;/p&gt;

&lt;p&gt;There are many variations for the autoencoders, including variational autoencoder (VAE) and sparse AE. VAE is for the interpretability. Conceptually, the high-dimensional space of the embedding can have an arbitrarily complex pattern. There can be many undefined spaces.   For example, let&amp;rsquo;s say there are four dimensions for embedding and it happens to represent a cat with [0.5 0.5 0.5 0.5 0.8] and a dog with [0.5 0.5 0.5 0.5 0.2]. But there can be no meaning between 0.2 and 0.8 for the last dimension. It becomes especially problematic when you want to generate some data by randomly sampling from embedding space. It will be embarrassing if there are no meaningful data to most of the embedding space. VAE solves this problem by adding the constraint that the embedding values should follow a gaussian normal distribution. Technically, you add additional loss term for KL divergence between the distribution of embedding values and gaussian distribution.  You can see an online demo of generating an image from Doom by changing latent dimensions &lt;a href=&#34;https://worldmodels.github.io/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another meaningful variation is that making the embedding sparse. Here we want only a small portion of embeddings to be nonzero while standard AE and VAE generate dense representation. Why do we want sparse representation? Sparsity has many benefits.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It is easier to interpret. You can think of each nonzero value as the feature present in the data. For interpretability, non-negativity helps, too. What will be the meaning of the negative yellow? Or negative car? My favorite representation is a sparse binary representation, which maximizes the interpretability.&lt;/li&gt;
&lt;li&gt;It is more biologically plausible. At any given point, about two percents of the neural cells are active. Of course, AI does not need to use the same mechanism as the rockets, helicopters, or jet airplanes do not use the flipping mechanism to fly as birds do.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;According to Olshausen and Field (2004), it can minimize the chance for destructive cross talk.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;According to Ranzato, Boureau, and LeCun (2008), it improves the linear separability.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L1 loss called lasso loss is commonly used to build a sparse model. Andrew Ng used the KL divergence between a binominal distribution and the activation frequency of embedding values.  It has one additional parameter that allows us to set the activation probability. Therefore, we can set the activation probability of embedding at two percent that is about the same as how frequently the biological neural cells activate.&lt;/p&gt;

&lt;p&gt;This paper presents a non-negative sparse autoencoder (NNSAE). Compared to other AE variants, NNSAE has the following benefits for my heterarchical prediction memory (HPM).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Non-negative&lt;/li&gt;
&lt;li&gt;Sparse&lt;/li&gt;
&lt;li&gt;Online&lt;/li&gt;
&lt;li&gt;Sparsity adds a built-in regulation to prevent overfitting&lt;/li&gt;
&lt;li&gt;Local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Non-negative matrix factorization (NMF) has been used to get non-negative embedding. However, this method relies on iterative fitting and does not work well with streaming inputs. NNSAE uses a larger update rate for negative weights than positive weights. It penalizes the negative weights and forces the weights to be positive.  The logistic activation function has been used to make the output values between zero and one. In NNSAE, the logistic activation function is shifted such that only a certain percentage of the cells are activated. The below figure explains this concept visually.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/NNSAE1.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;This figure explains how NNSAE generates a sparse code by shifting sigmoid function by parameter a and b. As can be seen in right figure, the shifted sigmoid generates a sparse code given gaussian input.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The sparsity constraint of the model enforces the regularization. In the synthetic toy dataset, where the ground-truth basis dimension is 18, we can see that the additional hidden dimensions are not used, as we can see when we use embedding dimensions larger than 18.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/NNSAE4.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;This sysnthetic dataset has 18 basis. As we can see in (d) and (e), when there are more hidden units, the model only uses 18 basis and does not use the remainder.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Similarly, for MNIST and CBCL face dataset, we can see that the number of used neurons does not explode beyond as the standard AE and sparsity is met.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/NNSAE5.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;In (a) and (b), we can see that the number of used neurons for hidden unit saturates, even though the number of hidden units increase. In &amp;copy;, we can see the standard AE uses all the basis, while the NNSAE uses only subset of basis and the remainder is near zero as seen in (d).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;As the algorithm is online, we can change the dataset in the middle of the training and expect the model to adapt to the new dataset, as can be seen below.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/NNSAE2.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The algorithm is online, therefore when we switch the dataset, it adapts to new dataset.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h2 id=&#34;use-of-nnsae-for-hpm&#34;&gt;Use of NNSAE for HPM&lt;/h2&gt;

&lt;p&gt;I conjecture that each module predicts what will come as an input for the next time step. It is similar to AE that we can train the model minimizing the difference between the current input and recovered output. However, it becomes difficult to predict far in the future. I want to overcome this limitation by having a hierarchy of layers predicting the next time step. Each layer predicts the next time step and aggregates the four-time steps. This aggregated input is then reduced to the dimension of single input using NNSAE. The upper layer feeds back this information to the lower layer. Therefore lower layers have two inputs. One is the actual input, and the other is context.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/HPM2.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The diagram for HPM model&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;As a concrete example in the language modeling application, let&amp;rsquo;s say that you have a stream of characters. You might have three layers working on different time scales. The lowest layer L1 gets the characters encoded as sparse binary codes. In my experiment, I used 512 as the embedding size and only 10 bits, which is about two percents are on, and the rest is off.  L1 tries to predict the next character by using a multilayer perceptron (MLP). But inherently, you cannot predict the next character given only the current character. For example, &amp;ldquo;a&amp;rdquo; or &amp;ldquo;h&amp;rdquo; can follow &amp;ldquo;c&amp;rdquo; as &amp;ldquo;cat&amp;rdquo; or &amp;ldquo;choice&amp;rdquo;. Context from the upper layer helps here. For L1, context from L2 contains information about the last four characters. Therefore L1 can predict the next characters better. Now, L1 sends a bottom-up feedforward signal by compressing embedding for four characters into 512 bits with ten on bits. This function is called &amp;ldquo;pooling,&amp;rdquo; and I used NNSAE for implementing the pooler.&lt;/p&gt;

&lt;p&gt;The below figure shows my language model&amp;rsquo;s performance trained over a short text file and a large text file.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/NNSAE6.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The performance of NNSAE for the character level language modeling. We used three layers. Each layer has a predictor and a pooler. Pooler uses NNSAE.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;While the performance of the pooler or NNSAE is satisfactory, the predictor performance is not. Below are some of my future strategy to make the predictor faster and better.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Deep Sparse Rectifier Neural Networks by Xavier Glorot, Antoine Bordes, Yoshua Bengio.&lt;/li&gt;
&lt;li&gt;Sparse deep belief net model for visual area V2 by Honglak Lee, Chaitanya, Ekanadham,  Andrew Ng&lt;/li&gt;
&lt;li&gt;Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons by Jochen Triesch&lt;/li&gt;
&lt;li&gt;Echo State Networks&lt;/li&gt;
&lt;li&gt;L1 Loss&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Olshausen, Bruno A., and David J. Field. &amp;ldquo;Sparse coding with an overcomplete basis set: A strategy employed by V1?.&amp;rdquo; Vision research 37.23 (1997): 3311-3325.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summary: Universal Intelligence: A Definition of Machine Intelligence</title>
      <link>http://crystal.uta.edu/~park/post/universal-intelligence/</link>
      <pubDate>Wed, 05 Aug 2020 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/universal-intelligence/</guid>
      <description>

&lt;p&gt;This is the paper review of &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/s11023-007-9079-x.pdf&#34; target=&#34;_blank&#34;&gt;the following paper&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Legg, Shane, and Marcus Hutter. &amp;ldquo;Universal intelligence: A definition of machine intelligence.&amp;rdquo; Minds and machines 17.4 (2007): 391-444.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While I was working on new paper on the language acquisition test, I needed a definition of intelligence. I had my own simple informal definition as an ability to behave in a beneficial way according to the sensory input. Though I am happy with my definition, academia is all about not reinventing the wheel and giving a proper credit to original authors.&lt;/p&gt;

&lt;p&gt;At first I was worried because intelligence is an abstract concept and there have been a lot of ideas in the history of AI and psychology. R. J. Sternberg said that&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Viewed narrowly, there seems to be almost as many definitions of intelligence as there were experts asked to define it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Some pose practical stance that the definition is not important as long as we can recognize it when we see. Chris Eliasmith suggested that &lt;strong&gt;cognition&lt;/strong&gt; is to researchers what &lt;strong&gt;pornography&lt;/strong&gt; was to justice Potter Stewart in his book&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;br /&gt;
Potter Stewart said&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I shall not today attempt further to define &lt;strong&gt;pornography&lt;/strong&gt; and perhaps I could never succeed in intelligibly doing so. But I know it when I see it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We could replace &lt;strong&gt;cognition&lt;/strong&gt; with &lt;strong&gt;intelligence&lt;/strong&gt; without loss of generality.&lt;/p&gt;

&lt;p&gt;Therefore when I found the paper by Shane Legg and Marcus Hutter, it was quite pleasant relief. Authors surveyed many definitions from the literature. Actually there is a companion paper&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; which shows the collection of the definitions of intelligence. In that paper, they collected 71 definitions from the dictionary, psychologist, and AI researchers.&lt;/p&gt;

&lt;p&gt;Based on this survey, they propose an informal definition of intelligence as following.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Intelligence&lt;/strong&gt; measures an agent&amp;rsquo;s ability to achieve goals in a wide range of environments.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What is nice about this definition is that this definition is &lt;strong&gt;universal&lt;/strong&gt; meaning that it can be applied to humans, animals, and computer systems. Historically, intelligence is the term to describe human intelligence especially in the context of human intelligence test. Therefore many definitions and tests are anthropocentric. Many definitions also try to list the specific elements of the intelligence. It is like for definition of speed, listing the elements of vehicle such as engine, tire, and suspension and so on.
One such example is following:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;Intelligence is a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. &amp;ldquo;&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here the ability to reason, plan, solve problems, think abstracly, etc. are all examples of the components for intelligence. Especially &lt;em&gt;learning&lt;/em&gt; is a major component, where many people think essential for intelligence. But authors insist that learning is just one possible strategy to achieve goals in a wide range of environments even though it is an important and widely adopted in human and animals. And I agree with this view. For example, a worm can respond to various sensory input to achieve goals. But the individual agent does not learn but the species as a whole optimizes the neural circuitry with genetic evolution.&lt;/p&gt;

&lt;p&gt;Another common pattern is shifting the problem to other abstract terms such as thinkging, creativity, consiousness or imagination. The follwoing examples shows this pattern:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The ability to carry on abstract thinking. (L. M. Terman)&lt;/p&gt;

&lt;p&gt;The capacity for knowledge, and knowledge possessed. (V.A.C. Henmon)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The authors also try to derive a formal mathematical definition from the informal definition. Authors builds on the reinforcement learning (RL) framework of environment, agent, reward, observation, and action.
The following figure shows a typical setup in the RL.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/agent-environment-reward.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Environment provides the observation and reward and the agents processes it to select appropriate actions&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Given an environment $\mu$ and agent $\pi$, the expected future value is the sum of discounted rewards into the infinite future where $r_i$ is the reward in cycle i of a given hstory, $\gamma$ is the discount rate, and $\Gamma$ is the normalizing constant $\Gamma := \sum_{i=1}^{\infty}\gamma^i$.&lt;/p&gt;

&lt;p&gt;$$V^{\pi}_{\mu}(\gamma):=\frac{1}{\Gamma}\mathbf E\left(\sum_{i=1}^{\infty}\gamma^ir_i\right) $$&lt;/p&gt;

&lt;p&gt;This is the expected total reward for one environment. How we can represent diverse environment? More challenging question is how we can quantify an easy environment and a complex environment. Also how should we assign an weight to the performance (expected reward) for easy and difficult environment?&lt;/p&gt;

&lt;p&gt;The main idea authors suggest is that the complexity of environments can be expressed with Kolmogorov complexity of the binary string that describes the environment.&lt;/p&gt;

&lt;p&gt;$$ K(x) := {min}_p \{ l(p): U(p) = x \} $$&lt;/p&gt;

&lt;p&gt;You can think of the binary string p as the program to simulate the environment for the reference universal Turing machine U. Kolmogorov complexity is then the minimum length of the program that runs in Turing machine U.  Generally if the length of program is short, the program is simple. And in this case, the fact that we have to find the minimum length makes the computation intractable for non-trivial case.  You can think Kolomgorov complexity is similar with minimum description length (MDL) for program.&lt;/p&gt;

&lt;p&gt;When there are many environments, what is the probability distribution for the environment? One idea is that the probability of the existence of environment $p_{\mu}$ might be inversely proportional to the exponential of the length or $p_{\mu} \propto 2^{-K(\mu)}$. You might imagine randomly appending 0 or 1 to binary string to build a program. Therefore we can express intelligence as the expected performance of agent $\pi$ with respect to the probability of environment $ 2^{-K(\mu)}$ over the space of all environments E.&lt;/p&gt;

&lt;p&gt;$$ \Gamma(\pi) := \sum_{\mu \in E}2^{-K(\mu)}V^{\pi}_{\mu}$$&lt;/p&gt;

&lt;p&gt;Authors define this as the &lt;em&gt;universal intelligence&lt;/em&gt; of the agent $\pi$.
Authors then compare the intelligence of following agents.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A random agent&lt;/li&gt;
&lt;li&gt;A very specialized agent&lt;/li&gt;
&lt;li&gt;A general but simple agent&lt;/li&gt;
&lt;li&gt;A simple agent with more history&lt;/li&gt;
&lt;li&gt;A simple forward looking agent&lt;/li&gt;
&lt;li&gt;A very intelligent agent&lt;/li&gt;
&lt;li&gt;A super intelligent agent&lt;/li&gt;
&lt;li&gt;A Human&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is quite nice to see that a very specialized agent gets lower intelligence score than a general but simple agent. Later the authors surveys the tests for the intelligence because the definition and the test are closely related in many cases. The list of tests are also useful for my research.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Turing test and derivatives: Common criticism is that Turing test is not &lt;em&gt;necessary&lt;/em&gt; to establish intelligence. Because the required knowledge level is too high, it cannot offer much guidance to the AI research. Also it depends on the human judges who are not reliable and reproducible for repeated tests.&lt;/li&gt;
&lt;li&gt;Compression tests: Compression can also represent the intelligence. An example would be summarizing papers, describing movies and so on.&lt;/li&gt;
&lt;li&gt;Linguistic Complexity: HAL project propose to &amp;ldquo;measure a system&amp;rsquo;s level of conversational ability by using techniques developed to measure the linguistic ability of children such as vocabulary size, length of utterances, response types, syntactic complexity and so on.&lt;/li&gt;
&lt;li&gt;Multiple Cognitive Abilities: Toddler turing test tries to build a young child in a similar set up to Turing test. A2I2 project tries to test performance of a small mammal. I would need to check this tests.&lt;/li&gt;
&lt;li&gt;Competitive Games: The goal is to build an AI that can do well on multiple games. This approach is popular nowadays.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Collection of Psychometric Tests: This aims to pass the intelligence test for human such as Wechsler adult intelligence scale.&lt;/li&gt;
&lt;li&gt;C-Test: It is similar concept to universal intelligence. But the test environment is limited to sequence prediction and sequence abduction tasks. Using Levin complexity, we can measure the complexity of the each problems.&lt;/li&gt;
&lt;li&gt;Smith&amp;rsquo;s Test: An algorithm generates a series of problems for an agent. When the answer is wrong, the agent might try another answer to the same problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And authors suggest useful properties for tests of machine intelligence and score each tests according to the properties. Below is the summary.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/tests-for-ai.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Comparison of various tests for machine intelligence.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Please note that Kolomogorov complexity is intractable for non-trivial case, therefore universal intelligence is a definition not test.&lt;/p&gt;

&lt;p&gt;If we apply this metric to the Language acquisition test, I think the following can be claimed.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Valid&lt;/strong&gt;: debatable because it only measures language acquisition but we claim it is the core of human-level intelligence&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Informative&lt;/strong&gt;: debatable for we provide many scores written as vectors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wide Range&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;General&lt;/strong&gt;: No. because we target for human-level intelligence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt;: Yes because the agent learn and adapt over time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unbiased&lt;/strong&gt;: No because SEDRo is biased to human in western culture.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fundamental&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Formal&lt;/strong&gt;: No because it is difficult to judge whether an agent has acquired language or not.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objective&lt;/strong&gt;: No because we have to rely on the human judges.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fully Defined&lt;/strong&gt;: No. The environment and the objective is not fully defined.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Universal&lt;/strong&gt;: No. It is anthropocentric.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Practical&lt;/strong&gt;: Yes because we are using simulator.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test vs Def&lt;/strong&gt;: Test.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally in the paper, the authors response to common criticisms. Among those, I liked how they respond to &amp;ldquo;Blockhead&amp;rdquo; argument and &amp;ldquo;Chinese room&amp;rdquo; argument. To introduce those arguments to the readers, &amp;ldquo;Blockhead&amp;rdquo; argument is that a machine seems to be intelligent to pass the Turing test, but it it is in fact no more than just a big look-up table of questions and answers. This machine with simple look-up table does not seems to be intelligent, isn&amp;rsquo;t it? The &amp;ldquo;Chinese room&amp;rdquo; argument is similar. The agent in the room responds to the questions in chinese. But the agent cannot understand chinese character. But it has a big book of Chinese phrasebooks with questions and matching answers. Therefore when the agent is given the question in the chinese letter, the agent will simply search the book for the same phrase and write answer and send it back. Even though the agent pass the Turing test, does the agent &lt;em&gt;understand&lt;/em&gt; chinese?&lt;/p&gt;

&lt;p&gt;The authors claim that as long as the agent shows high $\Gamma$ value, the internal working does not matter.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; it is not even clear to us how to define &lt;em&gt;understandings&lt;/em&gt; if its presence has no measurable effects. &amp;hellip; if &lt;em&gt;understanding&lt;/em&gt; does have a measurable impact on an agent&amp;rsquo;s performance in some well defined situations, then it is of interest to us. In which case, because $\Gamma$ measures performance in all well defined situations, it follows that $\Gamma$ is in part a measure of how much understanding an agent has.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Personally I think these arguments are harmful influence of philosophers to engineering discipline. I agree with authors. So far, I have talked about the contents of the paper and what I liked in the paper. Now let&amp;rsquo;s talk about my criticism.&lt;/p&gt;

&lt;h2 id=&#34;my-criticism&#34;&gt;My criticism&lt;/h2&gt;

&lt;p&gt;While I agree with their informal definition, my main criticism lies in their formal definition. I think it has a faulty assumption that rewards are equivalent to the goals. Reward system is just one of a trick to achieve goals.&lt;/p&gt;

&lt;p&gt;Intelligence is the concept that originated from biological agent. Therefore goals are natural to explain in perspective of biological agent. Generally we can say that the goal is to spread gene. Intelligence is one of strategy to achieve this goal. What are other strategies? Virus or bacteria have the strategy for lowering the cost of replication by hijacking to other system. Plant or phytoplankton choose the strategy of being self sufficient in addition to the lowering the cost of replication. Intelligence is more expensive strategy than these. Intelligence is selecting the behavior that will increase the chance of spreading gene according to the sensory input.  This requires sensory system and central nerve system (CNS) or brain to process sensory information and control the actuators accordingly.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/intelligence-sense-act-think.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Non-Intelligent vs Intelligent biological agents. Please note intelligence requires the sensory system and neural information processing system&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;However, at first there are different levels in intelligence strategy. Agents such as earthworms have simple brains. It has hardcoded the mapping from sensory system to the corresponding actions using simple look-up table. This lookup table is updated with evolution. Therefore while there was no learning in individual agent, the species as a whole improved this hardcoded function. A good example will be an earthworm. Charles Darwin studied earthworms for over 30 years in his house and his book &lt;em&gt;The formation of vegetable mould, throuth the action of worms&lt;/em&gt; sold more copies than &lt;em&gt;the origin of species&lt;/em&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. Earthworms have light receptors and vibration sensors. They move according to the light condition or the vibration caused by the moles.  While this is drastic improvement over the random spreading of the phytoplankton, the problem with this approach is that adaptation is very slow because the update to the neural circuit happens through evolution.&lt;/p&gt;

&lt;p&gt;The next level in the intelligence arms race is individual-level learning. Relying on evolution is too slow. If an individual agent can learn new rules such as a new type of food, it can surely increase the probability of successful gene spreading.  However, to enable learning at the individual level, two functional modules are required.&lt;/p&gt;

&lt;p&gt;The first is a memory to store newly developed rules. I conjecture the neocortex mainly serves this memory function. The second module is a reward system to judge the merit of the state. We stated that the goal of a biological agent is to spread genes. However, the correct assessment is not possible at the individual agent level. For example, an agent laid many eggs in a hostile environment that no descendant will survive. Still, the agent cannot know this because it succumbed before this happened. Therefore we need a function to indicate whether the current stimulus or state is good or bad. A reward system fills this gap by providing a proxy signal to approximate the probability of achieving goals. If an agent eats food, the stomach and blood glucose level information enter the reward center, and it generated a positive reward signal meaning this will be perhaps good for achieving goals. The signal indicates the new rule is good and needs to be stored in the memory. Later at a similar state, the newly added rule will be executed, which is the process of learning.&lt;/p&gt;

&lt;p&gt;However, this implies that the environment does not provide a reward. Instead, it is an agent that produces a reward signal, which is the estimate of the current state by the agent about how valuable it is to achieve the ultimate goals.
A dollar bill can be rewarding for some cultures but might not generate any reward to the tribal human who has never seen any money before. As for another example, when we eat three burgers for lunch, the reward for first and third burger will be different, even though it is the same object for the sake of the environment.&lt;/p&gt;

&lt;p&gt;Therefore, the diagram Figure 1 should be updated as following.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/revised-agent-environment.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Revised relationship of the agent and environment. Environment provides an observation. Some observation is used for the reward system in the agent. The resulting reward signal and the sensory information is fed into the control system.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Many different factors affect the value of the current state, such as physical fatigue, appetite, sex, or safety. A tired agent may crave both rest and sex at the same time. It looks like estimating the final value of the current state considering various factors itself is the challenging problem, and nature is again using evolution to experiment with the optimal reward function.&lt;/p&gt;

&lt;p&gt;Admittedly, authors are aware of this issue. Below are quotes from the discussions.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Strictly speaking, reward is an interpretation of the state of the environment. In this case, the environment is the universe, and clearly the universe does not have any notion of reward for particular agents. In humans this interpretation is internal, for example, that is experienced when you touch something hot. In which case, maybe it should really be a part of the agent rather than the environment? &amp;hellip;
A more accurate framework would consist of an agent, an environment and a separate goal system that interpreted the state of the environment and rewarded the agent appropriately.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, I conjecture that human-level intelligence is not achievable with the maximizing the reward approach. I am planning to explain this in my new paper. The key idea is that while learning with reward is better than using evolution to improve your brain, it is still limited because the biological agent must experience the stimulus to learn it first hand. However, if you think about the hostile nature, learning with direct experience is a dangerous strategy, and what you can learn is limited.  For example, a rabbit cannot try random action in front of the lion. It will be too late, and the rabbit&amp;rsquo;s experience cannot be transferred to other rabbits. Human-level intelligence tries to overcome this limitation by learning from others&amp;rsquo; experiences with language. Language learning is related to the reward.  As a summary, below is my hypothetical level of intelligence diagram.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/three-level-of-intelligence.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The three level of intelligence.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;&lt;em&gt;How to Build a Brain: A Neural architecture for biological cognition&lt;/em&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Legg, Shane, and Marcus Hutter. &amp;ldquo;A collection of definitions of intelligence.&amp;rdquo; Frontiers in Artificial Intelligence and applications 157 (2007): 17. &lt;a href=&#34;https://core.ac.uk/download/pdf/156626191.pdf&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Gottfredson, L. S. (1997). Mainstream science on intelligence: An editorial with 52 signatories, history, and bibliography. Intelligence, 24(1), 13-23
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Making sense of earthworm senses from Earthwormwatch.org. &lt;a href=&#34;https://www.earthwormwatch.org/blogs/making-sense-earthworm-senses&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lecture Summary: AI-Horizons Colloquium by Yoshua Bengio</title>
      <link>http://crystal.uta.edu/~park/post/yoshua-bengio/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/yoshua-bengio/</guid>
      <description>

&lt;p&gt;This is the review of &lt;a href=&#34;https://www.youtube.com/watch?v=s3AUUYUXsP8&#34; target=&#34;_blank&#34;&gt;the following video&lt;/a&gt;.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/s3AUUYUXsP8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;AI Horizons Colloquium, Beyond IID: Meta-Learning Disentangled Causal Variables and How the World Works by Yoshua Bengio, September 17, 2019, Cambridge&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;IBM has less reputation in the new renessance of AI research compared to its younger competitors such as Google and Facebook. To  make the competition meaningful, IBM invested a lot of money with MIT, another big brand name that does not have a strong hold in AI. Don&amp;rsquo;t get me wrong. MIT and IBM had a lot of work in the old AI day&amp;rsquo;s. But their contribution has diminished over the repeated AI winters and when the new AI renessance came with deep learning, they had a slow start. Let&amp;rsquo;s see how this goes.
This lecture is from AI Horizons Colloquium by IBM MIT AI research lab.&lt;/p&gt;

&lt;p&gt;Yoshua Bengio is &lt;strong&gt;like a beacon that calls talented researchers around the world&lt;/strong&gt; and &lt;strong&gt;feels like having 400-500 graduate students that his new work appears in the archive every week&lt;/strong&gt;  according to Geoffrey Hinton.
What is remarkable about him is that even though he was one of the people who brough the deep learning, he acknowledges its limitation and tries to overcome.
There are many fragmented community who studies Artificial General Intelligence (AGI).
It is easy for them to begin with the limitation of current deep learning.
What is ironical is that there are very high chance that Yoshua Bengio&amp;rsquo;s group will achieve the AGI, too.
It is because of two things. First, his group is well supported and has lots of resources in terms of the talent.
Second, his group has a strong background in the mathematics which might be essential for the development of the &lt;strong&gt;universal algorithm&lt;/strong&gt;.
Compared to his group, other AGI researchers such as Jeff Hawkins or Ben Goertzel looks like an independent inventor competiting with a Fortune 500 company.&lt;/p&gt;

&lt;p&gt;His lecture focuses on the roadmaps to the AGI even though he never mentions it.
His lecture contained many lessons for models and environments that our group is pursuing.&lt;/p&gt;

&lt;h3 id=&#34;environments-side&#34;&gt;Environments side&lt;/h3&gt;

&lt;p&gt;We don&amp;rsquo;t have a good simulator of the real world especially involving humans.&lt;/p&gt;

&lt;p&gt;And it is crucial that environment changes continuosly because the changes in the distribution give us what is the underlying causal structure.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Nature does not shuffle environments, we shouldn&amp;rsquo;t.
L. Bottou ICML keynote&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Those problems are what our group tries to solve.&lt;/p&gt;

&lt;h3 id=&#34;model-side-dim&#34;&gt;Model side (DIM)&lt;/h3&gt;

&lt;p&gt;His group is about models, so there are much more works going on that side.&lt;/p&gt;

&lt;h4 id=&#34;deep-infomax-dim&#34;&gt;Deep InfoMax (DIM)&lt;/h4&gt;

&lt;p&gt;This is interesting twist on the intrinsic rewards formulation. Simple intrinsic reward fomulation begins with predicting next state.
However, using maximum likelihood estimator (MLE) does not work well. Rather by maximizing the mutual information from current state and next state can be an alternative fomulation.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Hjelm, R. Devon, et al. &amp;ldquo;Learning deep representations by mutual information estimation and maximization.&amp;rdquo; arXiv preprint arXiv:1808.06670 (2018).&lt;/li&gt;
&lt;li&gt;Anand, Ankesh, et al. &amp;ldquo;Unsupervised state representation learning in atari.&amp;rdquo; Advances in Neural Information Processing Systems. 2019.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;attention-as-the-feedback&#34;&gt;Attention as the feedback&lt;/h4&gt;

&lt;p&gt;According to my opinion, the feedback from top-down is one of the most fundamental missing parts in the current fomulation of artificial neural net.
But maybe the attention can be thought as the feedback signal where higher layer attends  a subset of lower layer.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bengio, Yoshua. &amp;ldquo;The consciousness prior.&amp;rdquo; arXiv preprint arXiv:1709.08568 (2017).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;iid-and-disentangling-causal-variables&#34;&gt;IID and Disentangling Causal variables&lt;/h4&gt;

&lt;p&gt;We need higher level independence such as objects from perception. However, constructing higher level representation is challenging.&lt;/p&gt;

&lt;p&gt;One aspect of finding higher level representation is that they are independently controllable from other things. So actions to the world can guide the representation finding.&lt;/p&gt;

&lt;p&gt;Another aspect of causal structure is if we map the independence well, we can update only the subset of network but if we mixed the independence, small change in the distribution leads to the update of the whole network because they are entangled.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bengio, Yoshua, et al. &amp;ldquo;A meta-transfer objective for learning to disentangle causal mechanisms.&amp;rdquo; arXiv preprint arXiv:1901.10912 (2019).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even though there are no mathematical formula in the lecture, you will need a solid background on many mathematical concepts such as mutual information, generative adversarial network, probabilistic graphical model.&lt;/p&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.&lt;/p&gt;

&lt;p&gt;&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1411415072/agi?width=600&amp;height=400&amp;z=auto&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1411415072/agi&#34; target=&#34;_blank&#34;&gt;AGI&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1411415072/agi&#34; target=&#34;_blank&#34;&gt;AGI&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summary: An Immersive System for Browsing and Visualizing Surveillance Video</title>
      <link>http://crystal.uta.edu/~park/post/housefly/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/housefly/</guid>
      <description>

&lt;p&gt;This is the paper review of &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/1873951.1874002&#34; target=&#34;_blank&#34;&gt;the following paper&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;DeCamp, Philip, George Shaw, Rony Kubat, and Deb Roy. &amp;ldquo;An immersive system for browsing and visualizing surveillance video.&amp;rdquo; In Proceedings of the 18th ACM international conference on Multimedia, pp. 371-380. 2010.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;I found this paper while searching for the case where there were longitudinal video recording of the infants. There were two previous works. One is &lt;a href=&#34;https://cogdev.sitehost.iu.edu/homeview.html&#34; target=&#34;_blank&#34;&gt;the HomeView project&lt;/a&gt; by Chen Yu and Linda Smith.  In HomeView project, they installed a action cam in the hat of the infants and recorded 6 hours per day for years for multiple families. The other is the &lt;a href=&#34;https://www.media.mit.edu/cogmac/projects/hsp.html&#34; target=&#34;_blank&#34;&gt;Human Speechome Project&lt;/a&gt; by the Deb Roy. Human Speechome project is a project by MIT professor Deb Roy that he installed multiple cameras and mics around his house and recorded 9,000 hours of video of his son from the birth to 3 years. You can see the image sample in the Figure 1.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/housefly-system.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;They built 3D cad model of house by hand. And installed a wide angle fisheye camera per room. And reconstruct it as 3D immersive video.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;This paper is how we can generate 3D immersive video from the fisheye camera recording.
There is also a &lt;a href=&#34;https://www.ted.com/talks/deb_roy_the_birth_of_a_word?language=en&#34; target=&#34;_blank&#34;&gt;Ted talk by Deb Roy&lt;/a&gt; which has 3M views. The presentation skill is very good. It is a role model for presentation of HCI work. I recommend watching it.
He wanted to use this data for the how human develops an intelligence and use this lesson for the training of his robot Tracy. You can read more about in &lt;a href=&#34;https://www.wired.com/2007/04/truman/&#34; target=&#34;_blank&#34;&gt;this Wired article&lt;/a&gt;.
Unfortunately, he is not there yet.  He used the data for following purpose.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;He found how the visual experience and the first words are correlated.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;And he also used this technique to analyze the video of large mall for analytics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Read here for more extensive list of the findings &lt;a href=&#34;https://www.media.mit.edu/cogmac/projects/hsp.html&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;good-points&#34;&gt;Good points&lt;/h3&gt;

&lt;p&gt;For me, this work is inspiring because it is an example that recording of full house is possible.  Main challenge will be recruiting participants. Anyway, someone did it before.&lt;/p&gt;

&lt;p&gt;Second, it led me to more recent work by reading papers citing this work.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Browsing Group First-Person Videos with 3D visualization &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3279778.3279783&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Virtual-Real Fusion with Dynamic Scene from videos &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/7756128&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Third, a calibration interface might be useful to merge multiple coordinates from multiple depth camera.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/housefly-calibration.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;We can use manual calibration to increase the accuracy when merging point clouds from multiple camera&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;bad-points&#34;&gt;Bad points&lt;/h3&gt;

&lt;p&gt;First it maps to only 3D building not character or furniture. We can understand this because he used one fish eye camera per room. This saves the number of camera. It was about 15 years ago. So we can understand it. The 3d immersive video using single camera is impressive.&lt;/p&gt;

&lt;p&gt;Second, the data is not public. It is the same problem with the HomeView project. This data might be helpful for the AI research as Deb Roy explains in the Wired article. But the privacy issue makes it impossible to share this data as the public asset.&lt;/p&gt;

&lt;p&gt;I should be clear that bad points leads to the opportunity. Building upon his great work, we will add following small improvement.&lt;/p&gt;

&lt;h3 id=&#34;implication&#34;&gt;Implication&lt;/h3&gt;

&lt;p&gt;First, we will use multiple LIDAR camera per rooms to remove occlusion and create a complete 3D model.&lt;/p&gt;

&lt;p&gt;Second, we will try to make a public dataset.&lt;/p&gt;

&lt;p&gt;Finally, I am surveying 3D volumetric video a lot. We might write a survey paper about reconstructing 3D video from video recording to summarize our search.&lt;/p&gt;

&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;HomeView Project &lt;a href=&#34;(https://cogdev.sitehost.iu.edu/homeview.html)&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Human Speechome Project Ted talk &lt;a href=&#34;https://www.ted.com/talks/deb_roy_the_birth_of_a_word?language=en&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wired article about human speechome project &lt;a href=&#34;https://www.wired.com/2007/04/truman/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Browsing Group First-Person Videos with 3D visualization &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3279778.3279783&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Virtual-Real Fusion with Dynamic Scene from videos &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/7756128&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summary: A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality</title>
      <link>http://crystal.uta.edu/~park/post/sparsey/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/sparsey/</guid>
      <description>&lt;p&gt;This is the paper review of &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fnana.2010.00017/full&#34; target=&#34;_blank&#34;&gt;the following paper&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Rinkus, Gerard J. &amp;ldquo;A cortical sparse distributed coding model linking mini-and macrocolumn-scale functionality.&amp;rdquo; Frontiers in neuroanatomy 4 (2010): 17.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I found this paper while searching for the sparse coding implementation.
His work claimed 91% performance on MNIST and 67% on &lt;a href=&#34;http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html&#34; target=&#34;_blank&#34;&gt;Weizmann event dataset&lt;/a&gt;.
While this result is weaker than the state of the art result (around 99%), the following aspects were interesting.&lt;/p&gt;

&lt;p&gt;First, Sparsey model uses sparse distributed representation (SDR) rather than dense representation.
Second, Sparsey model does not use any of optimization including gradient back propagation. It can do one-shot learning meaning that only one example is required for learning.
Actually, the weights between neurons are binary and they are set by single occurence in Hebbian manner.
These two attributes are what I were considering required for my model.
Only comparable model is HTM by Numenta.
However, HTM does not have any performance evaluation result with popular dataset except a few synthetic toy dataset.&lt;/p&gt;

&lt;p&gt;The main algorithm transforms binary inputs into sparse distributed representation.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/sparsey.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The sparsey algorithm produces sparse distributed representation (SDR) from the binary inputs. If the input patterns are very similar to previous patterns, the resulting SDR code will be almost same to previous codes while novel patterns will result in novel code.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The key insight is that the algorithm uses the familarity or novelty measure to control randomness of the resulting code.
As a result, a well-known code or familar codes result in same representation as the previous case while the novel code results in the different code.
The author calls it similar inputs map to similar codes (&lt;strong&gt;SISC&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;There were many neuroscience references which will be useful for my future research.
For example, cells in the minicolumn possesses simiar receptive field characteristic or tuning.
This fact is also utilized in the HTM and cloned HMM.
The cells in the column shares the same inputs.&lt;/p&gt;

&lt;p&gt;Also SDR is used in the cells as can be shown in below figure.



&lt;figure&gt;

&lt;img src=&#34;./img/sdr.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The Calcium images of L2/3 of rat visual cortex reveals sparse distributed representation (SDR). Images from Ohki et al (2005).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;One big question for me is that if we define SISC as the binary bit overlap, the incoming input already possess the SISC property.
While the algorithm creates more sparse version of the binary input, how the sparse representation can be utilized is a big question.&lt;/p&gt;

&lt;p&gt;Is the simplication the core process the cortical columns are doing?
In my opinion, the prediction is the main task.
After several hierarchy, the mnist digits might be separated to constant representation, but it does not tells about how the motion should be generated.&lt;/p&gt;

&lt;p&gt;As a conclusion, this paper provides a good rationale behind the use of SDR verus dense or local code.
But the model is not good for my purpose. I will look at the logistic regression with Lasso regularization as the next candidate.&lt;/p&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summary: AGI Preschool: A Framework for Evaluating Early-Stage Human-like AGIs</title>
      <link>http://crystal.uta.edu/~park/post/preschool/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/preschool/</guid>
      <description>&lt;p&gt;This is the paper review of &lt;a href=&#34;https://www.atlantis-press.com/proceedings/agi09/1826&#34; target=&#34;_blank&#34;&gt;the following paper&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Goertzel, Ben, and Vladimir Bugaj. &amp;ldquo;AGI preschool: a framework for evaluating early-stage human-like AGIs.&amp;rdquo; In Proceedings of the 2nd Conference on Artificiel General Intelligence (2009). Atlantis Press, 2009.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;How we can evaluate the artificial general intelligence(AGI) is an open challenge in the community as suggested in &lt;a href=&#34;http://crystal.uta.edu/~park/post/mapping-the-landscape-of-human-level-agi.md/&#34; target=&#34;_blank&#34;&gt;this paper&lt;/a&gt;.
We can start with the imitation test sometimes called &lt;a href=&#34;https://www.jstor.org/stable/2251299?seq=1#metadata_info_tab_contents&#34; target=&#34;_blank&#34;&gt;Turing test&lt;/a&gt;.
However, it is too difficult.
We are struggling to find the basic principle of learning but the Turing test requires an adult level of knowledge.
We can use all the knowledge in the world to trick the bot.
Also because the agent in the Turing test is imitating the humans, there are many tricks that can fool humans into believing.
For example, &lt;a href=&#34;https://en.wikipedia.org/wiki/ELIZA&#34; target=&#34;_blank&#34;&gt;Eliza&lt;/a&gt; imitates an psychotherapist who keeps asking a question, and the recent winner from Loebner Prize mimics &lt;a href=&#34;https://www.theguardian.com/technology/2014/jun/08/super-computer-simulates-13-year-old-boy-passes-turing-test&#34; target=&#34;_blank&#34;&gt;a russian teenager who learns English to fool the judges&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Other tests such as College Student test is adopted to block these loopholes.
However, one major limitation of this approach is that they don&amp;rsquo;t deal about how these agents acquire these skills.&lt;/p&gt;

&lt;p&gt;Ben Goertzel and Stephan Vladimir Bugaj suggests an alternative framework for AGI testing resembling preschool.
It has similar curriculum for human including linguistic, social, logical-mathematical, nonverval communication, spatial-visual, object manipulation, social skills.&lt;/p&gt;

&lt;p&gt;It is an advanced framework compared to other scenarios that it includes how they can acquire those skills.
But in my opinion, it is still too challenging.
We need to focus more earlier period, especially from inception to 24 months.&lt;/p&gt;

&lt;p&gt;To solve the challenge of social learning they propose to use VR technology where a human participant controls avatar.
And they suggest to use the physics engine to simulate realistic object manipulation.&lt;/p&gt;

&lt;p&gt;After they pass the AGI preschool, the roadmap to more capable AGI is apparent.
That they can build AGI grade school, secondary school, and so on.&lt;/p&gt;

&lt;p&gt;My main criticism is that they are taking verbal and non-verbal communication as given.
For example, to test AGI they suggest following tests.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write a set of instructions; speak on a subject&lt;/li&gt;
&lt;li&gt;analyse how a machine works&lt;/li&gt;
&lt;li&gt;review a musical work&lt;/li&gt;
&lt;li&gt;create a mime to explain something&lt;/li&gt;
&lt;li&gt;coach or counsel another&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Actually, language acquisition is the main challenge that needs to be tackled even before AGI preschool.&lt;/p&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summary: Mapping the Landscape of Human-Level Artificial General Intelligence</title>
      <link>http://crystal.uta.edu/~park/post/mapping-the-landscape-of-human-level-agi.md/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/mapping-the-landscape-of-human-level-agi.md/</guid>
      <description>&lt;p&gt;This is the paper review of &lt;a href=&#34;https://www.aaai.org/ojs/index.php/aimagazine/article/view/2322&#34; target=&#34;_blank&#34;&gt;the following paper&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Adams, Sam, Itmar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J. Storrs Hall et al. &amp;ldquo;Mapping the landscape of human-level artificial general intelligence.&amp;rdquo; AI magazine 33, no. 1 (2012): 25-42.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The field of AGI is chaotic.
For 70 years, there were many ups and downs.
Still, we don&amp;rsquo;t have a consensus about how we can assess the human-level artificial general intelligence.
This paper is an effort of many experts in the AGI field to derive a method to assess the AGI.&lt;/p&gt;

&lt;p&gt;They start from Piaget and Vigotsky&amp;rsquo;s theory about developmental psychology.
Piaget&amp;rsquo;s model starts with sensori-motor stage where an infant learns to coordinate perceptual and motor skills such as reaching, grasping, crawling, and walking.
Vygotsky&amp;rsquo;s theory emphasize the role of others and social learning.&lt;/p&gt;

&lt;p&gt;With this in mind, they present previous scenarios for assessing AGI.
They are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;General Video-game learning&lt;/li&gt;
&lt;li&gt;Preschool learning&lt;/li&gt;
&lt;li&gt;Reading comprehension&lt;/li&gt;
&lt;li&gt;story or scene comprehension&lt;/li&gt;
&lt;li&gt;school learning (highschool or college)&lt;/li&gt;
&lt;li&gt;Wozniak Test&lt;/li&gt;
&lt;/ul&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/scenarios.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Scenario Milestones on the AGI Landascape&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;This paper is helpful for my research because it states the assessment scenario is an important challgenge in the AGI community.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;One challenge is to find tasks and environments where all of these characteristic are active, and thus all of the requireements must be confronted.
A second challenge is that the existence of an architecture that achieves a subset of these requirements does not guarantee that such an architecture can be extended to achieve other requirements while maintaining satisfaction of the original set of requirements.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Also it lists the requirements for the such scenarios that I can apply to my planned environment.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/env-requirements.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Required Characteristics for AGI Environments, Tasks, and Agents.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;I criticize that they are all focusing on too challenging scenarios without plan to achieve it.
The assessing scenarios should focus on the earlier stage when the agents begins to acquire language while developing sensor-motor skills.
In this sense, general video-game learning and preschool learning are relevant.
However, general video-game learning lacks how the skills from each game will be accumulated and transferred to other games.
Preschool learning is similar to our planned environments, but the main difference is that pre-school learning assumes that the agent has already acquired the communication capability as can be shown in the tasks highligted.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/tasks-preschool.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;A few example tasks for Preschool Environments. I highlighted the tasks where communication with human language is required.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;However, we don&amp;rsquo;t know how we can teach such communication skill to achieve artificial agents yet.&lt;/p&gt;

&lt;p&gt;Below is my mindmap for the related papers to artificial general intelligence.
&lt;iframe width=&#34;600&#34; height=&#34;400&#34; frameborder=&#34;0&#34; src=&#34;https://www.mindmeister.com/maps/public_map_shell/1405726945/references?width=600&amp;height=400&amp;z=auto&amp;live_update=1&amp;no_logo=1&#34; scrolling=&#34;no&#34; style=&#34;overflow: hidden; margin-bottom: 5px;&#34;&gt;Your browser is not able to display frames. Please visit &lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; on MindMeister.&lt;/iframe&gt;&lt;div class=&#34;mb-5&#34;&gt;&lt;a href=&#34;https://www.mindmeister.com/1405726945/references&#34; target=&#34;_blank&#34;&gt;References&lt;/a&gt; by &lt;a href=&#34;https://www.mindmeister.com/users/channel/42813067&#34; target=&#34;_blank&#34;&gt;Deokgun Park&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Observational Learning: How I would build AGI</title>
      <link>http://crystal.uta.edu/~park/post/observational-learning/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/observational-learning/</guid>
      <description>

&lt;h2 id=&#34;human-level-intelligence-test&#34;&gt;Human level intelligence test&lt;/h2&gt;

&lt;p&gt;I propose a language acquisition as the test for the human-level intelligence. If we raise baby animals like a human baby, they will not learn human language. They are capability limited. If a human baby is raised in the jungle without any human interaction, they cannot acquire human language. They are environment limited. We can say that the language acquisition is the function of the capability and the environment. Therefore, if any agent can learn language given the proper environment, we can say that the agent has the capability for human level intelligence.&lt;/p&gt;

&lt;h2 id=&#34;language-acquisition-environment&#34;&gt;Language acquisition environment&lt;/h2&gt;

&lt;p&gt;For the proper environment, we need other humans to teach language. There are many social mechanisms that enable this. Caregivers use motherese or infant-directed speech (IDS). The baby attends where the caregiver attends (joint attention), and the baby imitates what they see. To provide artificial agent this environment, there are two approaches. The first is using physical robots and asking the real humans to be caregivers. Given the current state of the art, this can be cost-inhibitive and not reproducible. The second is using simulated environment, but programming the caregivers to teach diverse and reasonable responses to the random behaviors of the learning baby agent is a scientific challenge. I plan to overcome this by limiting the scenarios and contexts for the environment and approximating mother behavior. As a concrete example, let‚Äôs say that we invite 100 pairs of the mother and child to play on the play at with a few toys. We capture their motions using motion capture system and build the behavior library. For example, if 20 babies touched duck toy during the experiment, we can record 20 responses of the mothers. In the simulator, when learning agent touches the duck toy, the mother character will play one random behavior out of 20 possible reactions.&lt;/p&gt;

&lt;h2 id=&#34;model-development&#34;&gt;Model development&lt;/h2&gt;

&lt;p&gt;Using this environment, we will develop a model that can learn by observing and interacting with other human-like pre-programmed agent. There are two parts for the model.&lt;/p&gt;

&lt;p&gt;First, we need a common cortical algorithm that is a universal machine given a vector as an input that can predict next state vector.
Hierarchy plays an important role here to overcome the trade-off between long-term predicton and training data.&lt;/p&gt;

&lt;p&gt;Some candidates for the possible algorithms are below&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1905.00507.pdf&#34; target=&#34;_blank&#34;&gt;Clonned HMM&lt;/a&gt; by Vicarious&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fncir.2016.00023/full&#34; target=&#34;_blank&#34;&gt;HTM&lt;/a&gt; by Numenta&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1901.09002&#34; target=&#34;_blank&#34;&gt;Hierarchical Prediction Network (HPNet)&lt;/a&gt; by Qiu et al.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note the vector representation changes from Sparse binary (HTM) to dense continuous (HPNet). Personally I prefer sparse binary but it can be functionally equivalent as in the electric motor and combustion engine in the vehicle. We also need to batch multiple modules in a heterarchical way as the society of minds. A good example is the contour-surface factorization in the RCN paper. We will need many more modules to handle sensory motor, auditory and so on. The executive functions on the prefrontal cortex can be built on the same principle while working on higher layer vectors that was generated as final output vectors in other modules.&lt;/p&gt;

&lt;p&gt;Second we need a supporting innate mechanisms to help these universal modules learn from the world. I believe the reward signal plays an important role here. We can learn lots of lower layers from the principle of predictive coding or intrinsic rewards where the action from the agent generates the next sensory inputs by training modules to predict next states. However, there are too many exploratory space in the world that an agent cannot learn from trial and error. The key in observational learning is studying innate mechanisms that can guide the learning agent to observe other humans and learn from them. For example, there are social rewards which can signal the learning agent that this is important sequence and needs to be memorized with increased focus. Newly inborn at least attends other humans speaking motherese more than other static objects or humans. There should be some kind of BIOS that can fill the contents of the blank state in the universal modules with meaningful content.&lt;/p&gt;

&lt;h2 id=&#34;road-map&#34;&gt;Road map&lt;/h2&gt;

&lt;p&gt;Once we have a model that can do observational learning in the simulated environment, we can port this model to the embodied robots and use real humans to teach the language. I believe that the model that can learn the vocabulary of two years can be easily extended to the reading level because it learned the concepts grounded in the sensori-motor sequence.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Olfactory learning</title>
      <link>http://crystal.uta.edu/~park/post/olfactory-learning/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/olfactory-learning/</guid>
      <description>

&lt;h1 id=&#34;olfactory-learning&#34;&gt;Olfactory learning&lt;/h1&gt;

&lt;p&gt;Nowadays you hear artificial &lt;strong&gt;intelligence&lt;/strong&gt; or machine &lt;strong&gt;learning&lt;/strong&gt; frequently.&lt;/p&gt;

&lt;p&gt;What is the difference between intelligence and learning?&lt;/p&gt;

&lt;p&gt;General words such as intelligence and learning are difficult to define. Rather than trying to define, comparing the meanings can be helpful to understand both concepts.&lt;/p&gt;

&lt;p&gt;Intelligence is the rules to active actuators according to the sensory input to improve one&amp;rsquo;s wellbeing. Learning is acquiring new rules after birth. In this sense, intelligence does not need learning.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/intelligence-vs-learning.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;There can be intelligence without learning and intelligence with learning.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Bees that show intelligent behavior does not rely on learning. All their smart rules are encoded in the genes.
Similarly my calculator is intelligent. But I don&amp;rsquo;t think they are learning.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;http://www.walyou.com/img/video-games-texas-instruments-math-calculator-1.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;This calculator is advertised as intelligent calculator, but it does not have the ability to learn new trick.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;While trying to build an AI, humans tried first to infuse rules by hand. But soon they found there are two fundamental problems. First, there are too many rules. Not only the number, many rules was contradictory each other. Second problem was the symbol-grounding problem.&lt;/p&gt;

&lt;p&gt;After some failure, we arrived at the consensus that to build human-level intelligence, machines needs to learn itself.
Interestingly, this idea of learning machine appears in the Alan Turing&amp;rsquo;s seminal paper, &lt;em&gt;Computing machinery and intelligence&lt;/em&gt; (1950).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child&amp;rsquo;s? If this were then subjected to an appropriate course of education one would obtain the adult brain. Presumably the child brain is something like a notebook as one buys it from the stationer&amp;rsquo;s. Rather little mechanism, and lots of blank sheets. (Mechanism and writing are from our point of view almost synonymous.) Our hope is that there is so little mechanism in the child brain that something like it can be easily programmed. The amount of work in the education we can assume, as a first approximation, to be much the same as for the human child.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One way to think about the AI and AGI is where the &lt;strong&gt;general&lt;/strong&gt; part comes. General part comes from the ability to learn new skills.
Therefore learning is a required condition of the AGI, too.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;What is the sufficient condition for the AGI?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;I think a language acquisition or &lt;strong&gt;learning&lt;/strong&gt; is a sufficent condition. Can an agent learn language by trial and error?   You can read &lt;a href=&#34;./post/research-in-hdilab/&#34; target=&#34;_blank&#34;&gt;more about this&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Learning is very expensive.&lt;/p&gt;

&lt;p&gt;Most animals cannot afford it.&lt;/p&gt;

&lt;p&gt;If you make a mistake, you die. And there is no way to transfer your knowledge to descendants using genes.  Your exploration to the world cannot  benefit the survival of your genes. How dare animals begin learning?&lt;/p&gt;

&lt;p&gt;Think of cars. Modern luxury cars have lots of complex modules such as adaptive cruise, ABS, regenerative braking, hybrid motor, all wheel drive, GPS navigation, 8 way sound system, memory seat, AC and heater and so on.  If anyone try to build a car one hundred years ago, will he consider all the complex modules of the modern cars? Probably not. He will only focus on how to rotate wheel without human manual muscle. That&amp;rsquo;s why the first cars had barely &lt;strong&gt;Minimum parts to implement a function&lt;/strong&gt;. They had a motor and battery connected to wheels. Or they had an steam engine.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/5/5b/Fardier_a_vapeur.gif&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The first car accident&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;So if we look at modern human brain, there are lots of fancy complex modules interconnected.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/2e25648359458f3658f3e55c88b5eeea1271c318/14-Figure1-1.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Components required for reaching and grasping. There are many modules for controling hand gesture.  Image from Schema theory by Michael A. Arbib (1998)&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Then if we want to reverse-engineer learning, trying to copy from the human brain is trying to learn how to build a first car from the modern luxury cars.  Let&amp;rsquo;s properly assume you don&amp;rsquo;t know what CPU and memory are because you are from one hundred years ago. The modern cars have 50-100 CPUs. Can we make sense what&amp;rsquo;s going on here?&lt;/p&gt;

&lt;p&gt;All of previous arguments are to claim that we need to look at the &lt;strong&gt;minimum parts to implement a function&lt;/strong&gt; to build a learning machine.&lt;/p&gt;

&lt;p&gt;Olfactory system is a candidate for such a system.
We belive it is the &lt;strong&gt;minimum parts&lt;/strong&gt; because it is oldest.
How do we know it is oldest?
Because it goes back to the lizard.&lt;/p&gt;

&lt;p&gt;Many readers might got the idea when I mention that lizard. They can skip the next part. But for the rest who do not have a clue, let me introduce crash course on the brain evolution.&lt;/p&gt;

&lt;p&gt;When we look at the brain there are many parts just too many parts. But if we simplify mercilessly, there are three major parts, hindbrain, limbic system, and neocortex.&lt;/p&gt;

&lt;p&gt;Hindbrain takes care of basic tasks that should be automatic. No learning should occur here. We should not learn how to breathe or maintain body temperature. It should be built in. Otherwise our chance of survival will be too thin.  This came first in the evolution and it is deep inside.
The last part, neocortex is where the human level intelligence is happening. It begins with the blank state and fills as we learn. This came last in the evolution and located in the surface or outside.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;http://images.mini-ielts.com/images/11/29/the-triune-brain.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The Triune Brain clusters brain into three major parts as hindbrain, limbic system, and neocortex.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Limbic system is what is in the middle. It came second and located in the middle between hindbrain and neocortex. This simplication is called the &lt;strong&gt;triune brain&lt;/strong&gt;. Previously limbic system is claimed to be &lt;strong&gt;old mammalian&lt;/strong&gt; brain and it is believed to handle emotions. However, it is discovered in the common ancestors of reptiles and mammals.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/d1/Blausen_0614_LimbicSystem.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The Limbic system is composed of olfactory sensor, hippocampus, and amygdala&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;It is composed of olfactory sensor, hippocampus, and amygdala.
Olfactory sensor is simple chemical sensors.
The neurons in the olfactory sensors fire according to the chemical input.
Amygdala is taking control of emotions.
You can simplify emotions as a change of body reactions to the same stimulus depending on the chemical concentration in the animal.&lt;br /&gt;
Amygdala controls the release of the chemicals.
In this sense, it is an &lt;strong&gt;actuator&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;To make situation ruthlessly simple, let&amp;rsquo;s say there are only two reactions, to approach or to avoid.
(Of course there are others such as mating or fighting.)
Let me clarify the same stimulus part to avoid confusion.
Of course when we see food, we approach and when we see a tiger, we avoid.
But let&amp;rsquo;s see you see an unidentified object, something you never seen or know.
If your blood has more &lt;strong&gt;approach&lt;/strong&gt; chemical, you will approach it.
While if your blood has more &lt;strong&gt;avoid&lt;/strong&gt;, vice versa.
This thing, unidentified object, is important concept in the learning.
Your gene may hard code the food and the predator.
You don&amp;rsquo;t need learning to handle that case.
But it is when you have a &lt;strong&gt;new stimulus&lt;/strong&gt; that requires learning.
Which is a learned reponse and different response for the same stimulus.&lt;/p&gt;

&lt;p&gt;As a concrete example, when a mouse hears a certain bell and gets the food, he associates approach with the bell sound.
But if a poor mouse next cage gets the electrical shock to the same bell sound, he will associate the sound with &lt;strong&gt;avoid&lt;/strong&gt; reaction.&lt;/p&gt;

&lt;p&gt;So we have a sensor and an actuator.
What else we need to build a learning system?
Learning system by definition has to have a mechanism to store input and connect or &lt;strong&gt;associate&lt;/strong&gt; appropriate actions.
Hippocampus is the one who is taking care of the associative memory.&lt;/p&gt;

&lt;p&gt;As a summary, the minimum parts to implement learning is a sensor, an actuator, and a memory.  Let&amp;rsquo;s call it a minimalistic learning module.&lt;/p&gt;

&lt;p&gt;Do you have an experience that when you smell something, it reminds me of your home or childhood memory?
It is because the olfacory sensors and hippocampus are very directly connected compared to complex routing in other modules in the brain.
We guess that it was the first sensor that connected to learning module because the olfactory sensors are directly connected to the hippocampus while other systems are connected through thalamus. Thalamus is the information hub. There are many sensors coming in and coming out.&lt;/p&gt;

&lt;p&gt;One interesting question to ask is why olfactory sensor was connected to this first learning machine.&lt;/p&gt;

&lt;p&gt;The need to learn new food source might be an motivation. But why animals rely on the odor rather than the visual shape or sound?
My guess is that chemical ordor has far lower dimension than other sensory input such as vision and auditory signals. To generalize over the visual system, we need far more processing and storage power. For example, a visual signal can be composed of 640 by 480 pixel value while odor signal can be characterized by 10 numerical values.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My intellectual journey</title>
      <link>http://crystal.uta.edu/~park/post/intellectual-journey/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/intellectual-journey/</guid>
      <description>&lt;p&gt;Below is adopted from forward in my Ph.D disseration.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A man&amp;rsquo;s character is his fate. &lt;br&gt;
&lt;em&gt;- Heraclitus&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It all began with the naƒ±ve and lazy man‚Äôs dream. I wanted interesting information to come to me even though I didn‚Äôt know if such information existed, and I didn‚Äôt search for it. I am lazy but addicted to information. I am also a Maximizer. According to the book The &lt;a href=&#34;https://www.amazon.com/Paradox-Choice-Why-More-Less/dp/149151423X&#34; target=&#34;_blank&#34;&gt;Paradox of Choice: Why More Is Less by Barry Schwartz&lt;/a&gt;, a &lt;strong&gt;Maximizer&lt;/strong&gt; is the kind of person who scans all the available cereals in the supermarket and tries to select the best one. Frankly speaking, I envy the &lt;strong&gt;Satisficers&lt;/strong&gt; because they will choose whatever option meets the requirements and forget about the rest.&lt;/p&gt;

&lt;p&gt;That‚Äôs how I initially became interested in recommender systems, which are a class of algorithms that recommend something to my taste, as Amazon and other web-based services that are trying hard to extract more money from us. Also, from my &lt;a href=&#34;https://intuinno.weebly.com/airbeat.html&#34; target=&#34;_blank&#34;&gt;previous experiences with wearable technology&lt;/a&gt;, I knew that the ability to extract valuable information from data will be the key component in the so-called big data value chain. Without the ability to turn data into insights, big data is just investment and cost. Analytics will be what generates revenue and profit.&lt;/p&gt;

&lt;p&gt;However, the journey never goes as expected and you never know where you will end up when you are setting out. Such was my Ph.D. I started with recommender systems, but the recommendations they make are not satisfactory due to limitations in the quality of these algorithms. It may be rather contentious to suggest that recommender systems algorithms are limited. Indeed, the world is changing and you never know if the next big scientific breakthrough will improve them to be more effective. But as anecdotal evidence to support my claim, Netflix never ended up using the state-of-art algorithms from the famous &lt;a href=&#34;https://www.wired.com/2012/04/netflix-prize-costs/&#34; target=&#34;_blank&#34;&gt;1 million dollar competition&lt;/a&gt;. The algorithm showed top-performance, but the performance gain was not meaningful to justify the algorithm implementation cost.&lt;/p&gt;

&lt;p&gt;That‚Äôs when I started to look for alternatives. Did I already tell you that I am a Maximizer? Therefore I concluded that we need to amplify the cognitive ability of the user to tackle the challenges of big data value creation. That was the focus of my Ph.D., presented here, with five design studies. The ideal ending will be that I am satisfied with my methodology and live happily ever after. But after six years of study, I see some fundamental limitations in the visual analytics (VA) approach as well. Those limitations are
1) VA systems are application/domain specific,
2) dependence on back-end algorithms that usually rely on the bag-of-words model, and
3) the requirement of user intervention (this can be both desirable and undesirable. But I am rather lazy.)&lt;/p&gt;

&lt;p&gt;So here I am packing light again to find more fundamental ways to achieve my dream. Recent advances in neural networking look promising, and, being inspired by those advances, I want to build upon them to start a new journey into this untapped area. I am excited, afraid, humble, and foolish on this new journey.&lt;/p&gt;

&lt;p&gt;If you want to know more detail, you can read &lt;a href=&#34;files/research-statement-agi.pdf&#34; target=&#34;_blank&#34;&gt;my research statement&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A scholar</title>
      <link>http://crystal.uta.edu/~park/post/a-scholar/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/a-scholar/</guid>
      <description>&lt;p&gt;My job is thinking and talking.&lt;/p&gt;

&lt;p&gt;I do reading and writting.&lt;/p&gt;

&lt;p&gt;I like learning and teaching.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
