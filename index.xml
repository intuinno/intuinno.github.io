<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deokgun Park on Deokgun Park</title>
    <link>http://crystal.uta.edu/~park/</link>
    <description>Recent content in Deokgun Park on Deokgun Park</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0500</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Advice for the master students who want to do reserach in my lab</title>
      <link>http://crystal.uta.edu/~park/post/master-research/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/master-research/</guid>
      <description>&lt;p&gt;I get many emails from master students who are interested in reserach.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I would like to get research experience in my lab. May I join your lab as a master student?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Below you can find my advice. TLDR, if you plan to pursue PhD after your master, it might be a good idea to experience research in my lab. If you plan to industry career, it might not.&lt;/p&gt;

&lt;p&gt;You can contact me and discuss your interest. However, if you want to get a job after graduation, doing research with me might not be helpful. You might get a better chance for the job by preparing the coding interview. The research takes time to produce a meaningful outcome. And the research is a full-time job. For example, it is common that it takes more than two years before a phd student can produce a paper or meaningful software. However, this can be too late for the master students who need something to show to potential employer during first semester and third semester. Doing research is more beneficial for those who consider phd program after graduation.&lt;/p&gt;

&lt;p&gt;Still there are many masters student working in my lab. I encourage you to contact them.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Advice for the undergraduate students who consider the graduate school</title>
      <link>http://crystal.uta.edu/~park/post/graduate-school/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/graduate-school/</guid>
      <description>

&lt;p&gt;Recently, I got an email from a smart undergraduate student who was interested in research. I think his situation might be a common case so here I added my reply in the hope that this can be helpful to other students. Below is the modified email message.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I have been talking with few graduate recruiters and found out that graduate schools don’t offer scholarship unless I am doing PhD or thesis (which I had no idea what that meant). All I wanted to do was to get a masters degree to gain enough knowledge on AI and deep learning and work for companies like DeepMind or Neuralink to bring AGI and ASI to real life. And now I am overwhelmed and lost with what I’m supposed to do. My options are to loan my way through graduate school (but I can’t do that since I am already on a huge debt for my undergraduate school), or get a PhD (this will take me forever and I will never be able to pay my loans back with the stipend), or find a job (until I am able to pay by loans and fund my graduate school but I really want to be on AI). I recently figured out that my major (computer engineering) wasn’t right for me. I decided to switch to computer science but I needed to take more classes so I am switching to software engineering to graduate on time with right the classes.  My mind’s all over the place and I have no idea where to seek help from.  I’m only halfway through the book even though I love it. I have been dying to learn Reinforcement Learning but I haven’t got time even to start searching about the resources.&lt;/p&gt;

&lt;p&gt;Thank you so much, Dr. Park! I hope you have a wonderful rest of the day.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Below you can find my advice. TLDR, it is okay to get a job if you are on a debt. If you think you are interested in the research, try to study on your own for a year or two. If you are still interested, you can consider a PhD.&lt;/p&gt;

&lt;h3 id=&#34;my-answer-to-the-student&#34;&gt;My answer to the student&lt;/h3&gt;

&lt;p&gt;Hi, Tomas (Name changed for privacy)&lt;/p&gt;

&lt;p&gt;I understand your position.&lt;/p&gt;

&lt;p&gt;Below is my advice.  The choice is yours. There is no right or wrong choice. The choice is based on who you are and in return shapes who you will be.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;to loan my way through graduate school (but I can’t do that since I am already on a huge debt for my undergraduate school),&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The graduate school here must be master’s degree, right. I don’t recommend it, either. You cannot get enough knowledge on AI topic and you don’t have enough time to create a knowledge that will make you attractable hire for companies like Deep Mind.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;or get a PhD (this will take me forever and I will never be able to pay my loans back with the stipend),&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It does not take you forever. It is actually somewhat short to do what I describe above. It will pay you back reasonably well if you are successful. But the decision cannot be made solely on financial reward because this financial reward is probabilistic. Better motivation would be the pursuit of knowledge or curiosity. And the reward is auxiliary. For example, you usually do not pursue professional baseball career because most of baseball related careers are not well-paid. Only winner takes it all.(I hope the chance is higher in the CS.) But many still pursue it because they enjoy baseball anyway.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;or find a job (until I am able to pay by loans and fund my graduate school but I really want to be on AI).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is an actually good option. Get a job. Get decent salary and pay your loans.
The trick is that you can study AI on your own with online learning education resource nowadays. This can be sometimes better than what the Master’s degree can offer.
When you study enough and you have a non-trivial question, it will be a good time to pursue PhD. Of course, consult with professors about your question.&lt;/p&gt;

&lt;p&gt;Attending academic conference is a good investment.
Studying alone is actually harder than you might think. You will be busy for the job (actually everyone is busy, right? Even my 9th grade daughter is busy because she has to watch three hours of youtube videos in addition to all the school work and violin and archery practice) and you may find the AI study is not so fun. The good news is that if you don’t like it, you don’t have to do it. It means that you are probably not good fit for the PhD. Don’t worry. You have a job already and you can focus on the software engineering career which can be also very rewarding. According to my opinion, I think about 5% of the people with good school grades are actually good fit for the PhD. The main reason is that we get good grades by learning what others have found. But PhD is about finding new knowledge which is very different from learning what others have found.&lt;/p&gt;

&lt;p&gt;As a summary, I think you have a potential. If you really want to study AI and deep learning now, you can get a PhD now. If you are not sure, it is okay to get a SWE job. If you find that you keep studying on AI and DL for one or two years on your own, you might consider getting a PhD.&lt;/p&gt;

&lt;p&gt;Regards&lt;/p&gt;

&lt;p&gt;Deokgun&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to use your advisor</title>
      <link>http://crystal.uta.edu/~park/post/how-to-use-your-advisor/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/how-to-use-your-advisor/</guid>
      <description>

&lt;p&gt;Recently, I got an email from a student from HDILab.  I think his situation might be a common case so here I added my reply in the hope that this can be helpful to other students. Below is the modified email message from the student.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hello Dr.Park,&lt;/p&gt;

&lt;p&gt;I am trying to implement carracing. I am using a virtualenv python3.5.4. I am trying to run extract.bash using $sudo bash extract.bash. However, it returns&lt;/p&gt;

&lt;p&gt;” File “extract.py”, line 8, in &lt;module&gt;
   import gym
ImportError: No module named gym” when extract.bash is trying to run extract.py.&lt;/p&gt;

&lt;p&gt;The problem is I installed gym and box2d-py too, and yet it shows the import error.&lt;/p&gt;

&lt;p&gt;$ which pip
/home/aishwarya/WorldModelsExperiments/carracing/venv/bin/pip&lt;/p&gt;

&lt;p&gt;$ which python&lt;br /&gt;
/home/aishwarya/WorldModelsExperiments/carracing/venv/bin/python&lt;/p&gt;

&lt;p&gt;I’ve also tried the solutions given in here and in here&lt;/p&gt;

&lt;p&gt;Can you please help me out with this issue.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Below you can find my advice. TLDR, if you have a technical problem. Solve it on your own while producing shareable outcome. If you have a research idea, your advisor can help you evaluate whether it is intractable, already done, or trivial.&lt;/p&gt;

&lt;h3 id=&#34;my-answer-to-the-student&#34;&gt;My answer to the student&lt;/h3&gt;

&lt;p&gt;Hi, Tomas (Name changed for privacy)&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know about this. You should check Google or ask other person&amp;rsquo;s in the lab. I think Jane and John might know.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t worry. Debugging this kind issue is common. I myself always deal with this issue. One of the reason, I cannot help is that the reason can be diverse. It is case by case. Therefore it is more important important to know how to deal with these kind of issues than the actual specific solution.  There will be hardly anyone who can solve your technical problem with a clear answer. If you have one you are lucky. But still if you ask to much questions to him, you are actually costing a precious resource to the group which is a bad news for you.  Below are some general advices.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Use slack general channel. If you send email to one person, the chance is low that  your busy and ignorant professor can help you. If you use slack to post your issue to the entire group, some competent students might help you.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Make environment simple.
90 Percent of these issues are package version collision.  Virtual env helps but not perfect. In old days I used to format frequently. That&amp;rsquo;s why I use one disk for system and one disk for home directory. Nowadays learning how to use docker will pay you back well in the long run.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Try to learn generalizable lesson and share it. Most of time, you just fix and forget. You might try stack overflow or Google solution until you fix it. The problem with this approach is that the time you spent on solving this issue does not produce any credit for your work.  While I also sometimes do that, the correct way to handle an issue is that &lt;strong&gt;&lt;em&gt;first understand the reason of the issue&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;create a technical note or blogs&lt;/em&gt;&lt;/strong&gt; that explains the issue and the solution.  Many people in the lab can benefit your contribution and your technical blog will help building your professional reputation. You need to be accustomed to solve these kinds of issues. It is like growing your muscles.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;how-to-use-your-advisor&#34;&gt;How to use your advisor&lt;/h3&gt;

&lt;p&gt;If your advisor cannot help you solve your technical issues, where can I use him? One area is when you have a research question. As a graduate student, you will always think the research question or the topic for the next paper. There can be two major pitfalls for setting the research topic.  An academic work is about finding a knowledge that none has found before. There can be two reasons why nobody has done it before.&lt;/p&gt;

&lt;p&gt;First, it can be too difficult to do or trivial but not meaningful.  When we think a new idea, I can bet there will be more than 10 people who have thought the same thing. Still the finding the solution might be too difficult.
Time machine, teleportation, or thinking machines are those areas. Those are technologies that people wish but it is very hard to make a progress in those area.  Or more commonly, your topic is slightly general and there can be many approaches to it. However, the topic might be well-known in the community and almost all low hanging fruits are taken already and what remains might be too challenging.&lt;/p&gt;

&lt;p&gt;Second, your problem might be too narrow or trivial or already solved before.
Your advisor is like a guide to the Mt. Everest or a chaperone to the party. He has an experience and background knowledge about the research community.&lt;br /&gt;
Therefore getting a cross check of your idea can be a good use of your advisor.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The HDILab culture</title>
      <link>http://crystal.uta.edu/~park/post/hdilab-culture/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/hdilab-culture/</guid>
      <description>

&lt;p&gt;Below is HDILab culture. A culture is a principle about how we do everyday things. I hope that our culture shape our group in a productive way.&lt;/p&gt;

&lt;h3 id=&#34;we-learn-by-teaching&#34;&gt;We learn by teaching.&lt;/h3&gt;

&lt;p&gt;Every week we will have a paper reading seminar where one student will teach a paper to other lab members. A pizza and a diet coke will be provided. You will have a chance to announce what you are working on nowadays in a friendly environment 30 minutes before the seminar. Currently the seminar starts on Wednesday 12:30pm.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;After you have done lab seminar, add the slides and all materials into the Google drive here. The goal here is to make it easier for a new lab member to follow what we have done so far.&lt;/li&gt;
&lt;li&gt;Also write one paragraph abstract for the seminar to summarize what you teach.&lt;/li&gt;
&lt;li&gt;Add your call sign so that we can know who did the seminar.  Students should answer the questions from colleagues.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;team-play&#34;&gt;Team play&lt;/h3&gt;

&lt;p&gt;There are focused hours in the lab where students are supposed to be at the same space and time. The main idea is to have an informal chat, update, questions and answers. The focused hours are currently held Mon, Tue, Wed 10am-2pm at ERB 205.
Don’t be late.
If you think you will be late, report it to the slack.&lt;/p&gt;

&lt;h3 id=&#34;sharable-output&#34;&gt;Sharable output&lt;/h3&gt;

&lt;p&gt;Students are required to maintain a lab journal and project journal
Lab journal is for the general purpose work and project journal is for the project related progress. For example,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I set up the new server or hardware for the-&amp;gt; hdilab journal&lt;/li&gt;
&lt;li&gt;I organized the inventory -&amp;gt; hdilab journal&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;I replicated the world model -&amp;gt; daivid journal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Every work should be recorded and reproducible.
Basically journal is for yourself. But write it well when others have to find something you did. When you accumulate enough work and progress, make them shareable and transferable chunk into three places:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;journal how-to technical note
When you create a new technical note leave a author call sign such as #deokgun so that I can find who wrote what.
If you need to update it, add a call sign and date after the original author.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;Example 
Created: #deokgun 01/08/2019
Updated: #sanjay 01/09/2019 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Personal homepage blog article&lt;/li&gt;
&lt;li&gt;Github readme.md&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One common mistake for the new member is writing a technical note about a topic that is already covered in previous technical note from other members. This is problematic in the two sense. First, it means that you did not search or read other&amp;rsquo;s technical note. A value of the technical note is how many times it is read by others. If no one reads others&amp;rsquo; technical note, the value of our journal will be nothing. Second, you are creating an additional burden for the future readers looking for a solution for the topic. In that sense, you are creating a noise if you are creating a redundant article. So what we should do when we found that the topic that we would like to wrtie is available.  Check the original post and if you have an additional content, just update the original post.  If you are sure that you can write a better one by rewriting, replace the original post. The original post should be archived to the old technical note and referenced by the new article.&lt;/p&gt;

&lt;p&gt;We share the open source code and how-to manual as a final output.
We use GitHub as the main archive
As a rule of thumb, I expect 50% of everyone’s time will be spent writing what you have done.&lt;/p&gt;

&lt;h4 id=&#34;how-to-write-a-journal&#34;&gt;How to write a journal&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Make the outline neat&lt;/li&gt;
&lt;li&gt;If you click the View-&amp;gt; Show Document Outline button, it will show you the document outline. Make sure your writing follows the header rule.
There is a shortcut key for selecting the paragraph level.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;cmd + alt + 1 makes the top level heading
cmd + alt + 2 makes the second level heading
cmd + alt + 0 makes the content paragraph, which is not shown in outline. 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;Things to do next part&lt;/strong&gt; is important. Your professor reads it often.  Keep it tidy. When something is done, remove. &lt;strong&gt;Update it everyday&lt;/strong&gt;. When you are given new goal, write it there.  Make the thing you are working on now, the first item. Order them in the priority.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;communication-is-half-of-your-job&#34;&gt;Communication is half of your job.&lt;/h3&gt;

&lt;p&gt;Your impact will be the multiplication of research and communication of the result.
Try to report the progress whenever there is a progress
Don&amp;rsquo;t wait until your boss ask your progress. Tell him what you are working on now.
 If you meet a barrier or decide to change direction, report it.
When I ask you to do something, I usually expect to hear the progress report in a one or two days.&lt;/p&gt;

&lt;h3 id=&#34;being-true-to-ourselves&#34;&gt;Being true to ourselves&lt;/h3&gt;

&lt;p&gt;You cannot deceive yourself. Being true to yourself is, in my opinion, a very good long-term strategy. For example, if you don’t know during the seminar, acknowledge that you don’t know and ask questions until you understand. Don’t be embarrassed or give up by social pressure. Academy is a few places where being true to yourself is tolerated.&lt;/p&gt;

&lt;p&gt;Other good question to ask yourself is whether you are enjoying the research. Actually according to my experience, research is not for everyone. Probably about 5 persons out of 100 suit the academic life. Because of this, it is perfectly okay if you feel that the graduate study is not what you want to do. I recommend to get a SW engineering job in that case, which actually pays you better and provides better work-life balance. You might feel like a failure to quit the research at first, but if you are true to yourself, you may find it as one of the best decisions of your life later.&lt;/p&gt;

&lt;p&gt;Similarly I will release you out of the lab if I think that you are not a good fit for the lab as early as possible. How I make that decision? First, I have to acknowledge that it is very difficult decision for me, too. It is not only emotionally difficult but intellectually difficult. Because nobody knows the future, one day the student I fired may get a Nobel prize.&lt;/p&gt;

&lt;p&gt;I have to follow the lab culture which is my principle. For me, there are three characteristics for the academic career.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First is &lt;strong&gt;curiosity&lt;/strong&gt;. The desire to know or find the truth is our strongest motivation and rewards.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Second is the &lt;strong&gt;self-starting&lt;/strong&gt;. This one is related to curiosity. Because you want to know something, you start researching about it. This is usually observed when the student comes to me and ask an advice for something. It is the opposite of waiting for the order from me.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Third is the persistence. The journey is long and the rewards are sparse. If you are not persistent, chances are you give up. &lt;strong&gt;Persistence is measured by the shareable output.&lt;/strong&gt; According to my experience, quantity is more important than the quality for measuring persistence. It means if you are producing lots of so-so blog article or technical note and low quality draft of academic papers, you have the persistence. Think about growing academic muscle by writing everyday.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Rewards for AGI</title>
      <link>http://crystal.uta.edu/~park/post/rewards/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/rewards/</guid>
      <description>

&lt;h2 id=&#34;contents&#34;&gt;Contents&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Introduce  the role of the rewards in reinforcement learning

&lt;ol&gt;
&lt;li&gt;Use the example of dog training&lt;/li&gt;
&lt;li&gt;Explain the dopamine&lt;/li&gt;
&lt;li&gt;Explain the&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Introduce an extrinsic rewards

&lt;ol&gt;
&lt;li&gt;Classic rewards&lt;/li&gt;
&lt;li&gt;Used in reinforcement learning examples

&lt;ol&gt;
&lt;li&gt;Atari&lt;/li&gt;
&lt;li&gt;Alpha Go&lt;/li&gt;
&lt;li&gt;World model paper&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Introduce an intrinsic rewards&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Explain the limitation of the extrinsic rewards

&lt;ol&gt;
&lt;li&gt;Montezuma&amp;rsquo;s revenge&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Explain the mechanism of the intrinsic rewards

&lt;ol&gt;
&lt;li&gt;How the curious or explorative behavior relates to the intrinsic rewards&lt;/li&gt;
&lt;li&gt;How to formulate the intrinsic rewards mathematically?&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Model-free vs model-based reinforcement learning&lt;/li&gt;
&lt;li&gt;Intrinsic rewards examples

&lt;ol&gt;
&lt;li&gt;Introduce paper by Stanford&lt;/li&gt;
&lt;li&gt;World Discovery Model paper&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Introduce the limitation of the intrinsic rewards&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The search space is too vast for a single agent learn by exploration&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Example: Radnom permutation of alphabet to generate a meaningful sequenc.&lt;/li&gt;
&lt;li&gt;Example: Musical note&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Explain the higher order Markov chains&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Introduce the social rewards&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Introduce the imprint&lt;/li&gt;
&lt;li&gt;Introduce how the baby learns

&lt;ol&gt;
&lt;li&gt;Learn by imitation&lt;/li&gt;
&lt;li&gt;Joint attention&lt;/li&gt;
&lt;li&gt;Gated learning&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Theory based mathematically driven algorithm vs quick dirty rule based system&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Future research direction&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Models that take into account the innate mechanisms&lt;/li&gt;
&lt;li&gt;Environments that can test the models with social rewards&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Reward plays a key role in the reinforcement learning.&lt;/p&gt;

&lt;p&gt;In this post, I will explain three types of the rewards that can shape the intelligent behavior.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Extrinsic rewards&lt;/strong&gt;: A reward triggered by the external entity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intrinsic rewards&lt;/strong&gt;: A reward that can be generated by the agent himself.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Social rewards&lt;/strong&gt;: A rewards that can be generated by the social activities&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;extrinsic-rewards&#34;&gt;Extrinsic rewards&lt;/h3&gt;

&lt;p&gt;Extrinsic rewards means the positive or negative reward triggered by the external entity. A concrete example is the
Previously rewards meant mostly extrinsic rewards.&lt;/p&gt;

&lt;h3 id=&#34;intrinsic-rewards&#34;&gt;Intrinsic rewards&lt;/h3&gt;

&lt;h3 id=&#34;social-rewards&#34;&gt;Social rewards&lt;/h3&gt;

&lt;p&gt;A search space to generate a meaningful space is very vast and only very few are meaningful. But we can learn from others the meaningful sequence which reduces the search space&lt;/p&gt;

&lt;p&gt;This can be expressed with music note.&lt;/p&gt;

&lt;p&gt;Should we use reward mechanism or reflex mechanism?&lt;/p&gt;

&lt;p&gt;Imprint is an example of reflex mechanism. Because we have the freedom to follow or not, I think reward mechanism makes more sense.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Jones, Susan S. (2012-12-10). &amp;ldquo;Human Toddlers&amp;rsquo; Attempts to Match Two Simple Behaviors Provide No Evidence for an Inherited, Dedicated Imitation Mechanism&amp;rdquo;. PLOS ONE. 7 (12): e51326. Bibcode:2012PLoSO&amp;hellip;751326J. doi:10.1371/journal.pone.0051326. ISSN 1932-6203. PMC 3519587. PMID 23251500&lt;/li&gt;
&lt;li&gt;Jones, Susan S. (2009-08-27). &amp;ldquo;The development of imitation in infancy&amp;rdquo;. Philosophical Transactions of the Royal Society B: Biological Sciences. 364 (1528): 2325–2335. doi:10.1098/rstb.2009.0045. ISSN 0962-8436. PMC 2865075. PMID 19620104.&lt;/li&gt;
&lt;li&gt;Rowland, D.C., Yanovich, Y. and Kentros, C.G. (2011). A stable hippocampal representation of a space requires its direct experience. Proceedings of the National Academy of Sciences. 108(35). 14654-14658.  -&amp;gt; An evidence for Gated language&lt;/li&gt;
&lt;li&gt;CONSPEC and CONLERN: a two-process theory of infant face recognition.
J Morton, MH Johnson - Psychological review, 1991 - psycnet.apa.org
Evidence from newborns leads to the conclusion that infants are born with some information
about the structure of faces. This structural information, termed CONSPEC, guides the
preference for facelike patterns found in newborn infants. CONSPEC is contrasted with a&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Newborns&amp;rsquo; preferential tracking of face-like stimuli and its subsequent decline
MH Johnson, S Dziurawiec, H Ellis, J Morton - Cognition, 1991 - Elsevier
Abstract Goren, Sarty, and Wu (1975) claimed that newborn infants will follow a slowly
moving schematic face stimulus with their head and eyes further than they will folow
scrambled faces or blank stimuli. Despite the far-reaching theoretical importance of this …&lt;/li&gt;
&lt;li&gt;How the brain processes social information: searching for the social brain
TR Insel, RD Fernald - Annu. Rev. Neurosci., 2004 - annualreviews.org
▪ Abstract Because information about gender, kin, and social status are essential for
reproduction and survival, it seems likely that specialized neural mechanisms have evolved
to process social information. This review describes recent studies of four aspects of social&lt;/li&gt;
&lt;li&gt;Eye contact detection in humans from birth
T Farroni, G Csibra, F Simion… - Proceedings of the …, 2002 - National Acad Sciences
Making eye contact is the most powerful mode of establishing a communicative link between
humans. During their first year of life, infants learn rapidly that the looking behaviors of
others conveys significant information. Two experiments were carried out to demonstrate …&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Soft Evolution</title>
      <link>http://crystal.uta.edu/~park/post/soft-evolution/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/soft-evolution/</guid>
      <description>

&lt;p&gt;Life evolves. The speed of evolution depends on the mechanism of the evolution. The first evolution was based on the random mutation of genes. It is basically trial and error. But the diversity of the life forms it generated is awesome. I would call it &lt;strong&gt;hard evolution&lt;/strong&gt;. We, humans, are one of the successful life forms with mosquitoes and cockroaches.&lt;/p&gt;

&lt;p&gt;Human adopted a new strategy. It was building a more flexible general purpose brain to adapt to the environment. Other life forms also have the brain. But its function was more rigid or hard encoded. You can think how the pocket calculator compares with the smartphone. Both have a similar electronic components namely CPU, memory and I/O devices.&lt;/p&gt;

&lt;p&gt;Using the general brain, we can do many things that was not possible. But the essential function is learning. In hard evolution, the special variation that worked well leaves the genes. However, in &lt;strong&gt;soft evolution&lt;/strong&gt;, we can learn from others. It basically allows exponential trial and errors. Nobody can experience all the diverse experience in the world given limited time and energy. Still we can learn from others first using verbal language. This allowed us to transfer knowledge from nearby people. The written language allowed it to go beyond the limitation of the space and time of the verbal language. Now what is beautiful about the soft evolution is that the time it takes to evolve has reduced dramatically. The soft evolution happens in the brain circuitry during the life time of the agent while in the hard evolution, the life time of the agent was a single unit of progress.&lt;/p&gt;

&lt;p&gt;Because of this general flexible brain, we are born with a rather blank state compared to other animals such as cats and dogs. (Of course there are still many innate circuitry which I will talk later about.) And it takes relatively long time to have a reasonably working program. Interestingly as the amount of the information to function well in the society increases the time it takes to be independent is also increasing. Now it is common in the first world that it takes about 20 to 30 years before one can be independent from their parents.&lt;/p&gt;

&lt;p&gt;I said the brain is born as a basically blank state. But still there are innate mechanism to help learn from the parents. Think of the truly blank state agent. We got a continuous stream of image and sound. How we can make sense of the these images? For example, parents talking to the baby might look like a skin colored chunk with a few holes that are constantly moving. One hole continuously changes shape and make a sound (hint: mouth). How can we learn this chunk of image is a mom and the sound is the language which is different from random noise from the street? Epistemology is an old branch of philosophy devoted to this problem.&lt;/p&gt;

&lt;p&gt;I think the innate mechanism is essential for the new born baby to make sense of the world. Let me give you an example. &lt;a href=&#34;https://science.sciencemag.org/content/198/4312/75&#34; target=&#34;_blank&#34;&gt;Andrew Meltzoff and Keith Moore found that a baby who was about 7 hours since the birth can still mimic the tongue movements&lt;/a&gt;. It is quite surprising when we think about all the skills to do this. First, the baby has to recognize the human face. Then he has to map the human face he never seen to his face that he never seen himself. Finally the baby has to control the tongue to imitate the expression.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/imitation-in-baby.png&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;New born baby can imitate the random facial expression. This capabilities an innate mechanism to help learn from others. We should learn from relevant objects such as people and care givers and not from irrelevant objects such as cars or doors.  &lt;a href=&#34;https://science.sciencemag.org/content/sci/198/4312/75.full.pdf&#34; target=&#34;_blank&#34;&gt;Image from Science 1977&lt;/a&gt;&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;I believe this imitation capability is essential to learn from others. Given blank state, we should not fill this blank with random noise but relevant contents. What will be the relevant contents for the new born baby. Most likely it will be from the parents and caregivers. The imitation mechanism has already filtered irrelevant objects in the world and focused on the human facial expression and followed its motion. This limits the vast space of the exploration to meaningful trajectory that was suggested by human.&lt;/p&gt;

&lt;h3 id=&#34;lessons-for-the-agi&#34;&gt;Lessons for the AGI&lt;/h3&gt;

&lt;p&gt;In the famous &lt;a href=&#34;https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf&#34; target=&#34;_blank&#34;&gt;DQN paper&lt;/a&gt;, there are experiments for the Atari games. Among many games that showed superhuman performance by the artificial agent, there was one game that showed very poor performance called &lt;strong&gt;Montezuma&amp;rsquo;s revenge&lt;/strong&gt;.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/0yI2wJ6F8r0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;This &lt;a href=&#34;https://www.theverge.com/2016/6/9/11893002/google-ai-deepmind-atari-montezumas-revenge&#34; target=&#34;_blank&#34;&gt;blog explains why the Montezuma&amp;rsquo;s revenge game is particularly challenging&lt;/a&gt;. In a summary, there are too many things that have to be done sequentially such as getting the key, avoid the monster, and go back to the door. The random behavior by the agent cannot explore the vast exploration space in a limited time. In 100 Million iterations, the agent can access only the second stage. This shows the limitation of the random trial and error. I said other animals cannot learn. But I was wrong. They can learn. For example, dogs can learn new trick. They learn by trial and error. They associate behaviors with positive rewards or treats. But things you can learn from this approach is limited.&lt;/p&gt;

&lt;p&gt;I think there are three components for the artificial general intelligence. The first is a model. For example, in my &lt;strong&gt;HPM&lt;/strong&gt; theory, the agent predicts the next sensory input with the help from the hierarchy to do the higher-order prediction (chunking). The second is an environment. It provides a source of information. The problem is there are vast space for exploration. Finally there will be many smart tricks such as imitation or &lt;a href=&#34;http://ilabs.washington.edu/kuhl/pdf/Kuhl_2007.pdf&#34; target=&#34;_blank&#34;&gt;social mechanism to focus on the human interaction during language acquisition&lt;/a&gt; to reduce this search space effectively by social learning. Our lab tries to build an &lt;a href=&#34;http://crystal.uta.edu/~park/post/research-in-hdilab/&#34; target=&#34;_blank&#34;&gt;environment that can provide a testbed for such social mechanism&lt;/a&gt; and study the models.&lt;/p&gt;

&lt;p&gt;Finally, what will be the next step for the evolution? I think it will be how we can limit the limitation of the brain cell. The brain cell is relatively small and degradable. If we can use our electronic components as a device, it will achieve a step-up in the evolution speed. But more importantly, I think the true power of the next evolution is when the artificial intelligence agent upgrades its own structure. This upgrades will be beyond the human&amp;rsquo;s ability to follow which is called &lt;strong&gt;technical singularity&lt;/strong&gt;. Some would call it &lt;a href=&#34;https://www.nature.com/articles/nrg1921&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;computational evolution&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/evolution.svg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;The evolution of the intelligence&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Atom: A Grammar for Unit Visualizations</title>
      <link>http://crystal.uta.edu/~park/publication/atom/</link>
      <pubDate>Wed, 26 Sep 2018 21:53:11 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/atom/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./img/atom.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Sequence of layout operations to generate a unit column chart for survivors of the Titanic by passenger class.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>http://crystal.uta.edu/~park/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ConceptVector: Text Visual Analytics via Interactive Lexicon Building Using Word Embedding</title>
      <link>http://crystal.uta.edu/~park/publication/conceptvector/</link>
      <pubDate>Sun, 28 Jan 2018 22:17:58 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/conceptvector/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./img/conceptvector.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The CommentIQ UI showing toggleable visualizations such as scatterplot, map, and timeline (left) that enable overview and filtering of comments, as well as an adjustable ranking based on various weighted quality criteria (right).ConceptVector supports interactive construction of lexicon-based concepts. Here the user creates a new unipolar concept (1) by adding initial keywords related to &lt;em&gt;tidal flooding&lt;/em&gt; (2). The system recommends related words along with their semantic groupings (3), also shown in a scatterplot (4), revealing word- and cluster-level relationships. Irrelevant words can be specified to improve recommendation quality (5). Concepts (9) can then be used to rank document corpora (10). Document scores can be visualized in a scatterplot based on concepts such as &lt;em&gt;tidal flooding&lt;/em&gt; and &lt;em&gt;money&lt;/em&gt; (7). Users can further refine concepts based on results (8).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Visual Analytics for Comment Analysis (in Korean)</title>
      <link>http://crystal.uta.edu/~park/talk/naver/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0600</pubDate>
      
      <guid>http://crystal.uta.edu/~park/talk/naver/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Supporting comment moderators in identifying high quality online news comments</title>
      <link>http://crystal.uta.edu/~park/publication/commentiq/</link>
      <pubDate>Mon, 26 Sep 2016 23:26:53 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/commentiq/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./img/commentiq.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The CommentIQ UI showing toggleable visualizations such as scatterplot, map, and timeline (left) that enable overview and filtering of comments, as well as an adjustable ranking based on various weighted quality criteria (right).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://crystal.uta.edu/~park/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>http://crystal.uta.edu/~park/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/project/example-external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AGI Research in HDILab</title>
      <link>http://crystal.uta.edu/~park/post/research-in-hdilab/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/post/research-in-hdilab/</guid>
      <description>

&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;My name is Deokgun Park and I lead Human Data Interaction Lab (HDILab) in the &lt;a href=&#34;https://cse.uta.edu/&#34; target=&#34;_blank&#34;&gt;Department of Computer Science &amp;amp; Engineering at the University of Texas at Arlington&lt;/a&gt;.
In this article, I will explain the problems we are solving at HDILab. In Human Data Interaction Lab, we are studying &lt;strong&gt;artificial general intelligence (AGI)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Many students already have an idea about artificial intelligence (AI). But artificial general intelligence or AGI might be a new term. So let&amp;rsquo;s start with what AGI is.&lt;/p&gt;

&lt;h3 id=&#34;clarifying-ai-and-agi&#34;&gt;Clarifying AI and AGI&lt;/h3&gt;

&lt;p&gt;Since Marvin Minsky and other researchers gathered at &lt;a href=&#34;https://en.wikipedia.org/wiki/Dartmouth_workshop&#34; target=&#34;_blank&#34;&gt;Dartmouth College in Hanover in 1956&lt;/a&gt;, the goal of AI was to build a machine that can do many tasks like humans. But after experiencing a few AI winters, the academic focus shifted to building models to perform a single application because it was more tractable. This approach has been frequently called machine learning (ML). It is said that one of the reason ML has been coined was to &lt;a href=&#34;https://en.wikipedia.org/wiki/AI_winter&#34; target=&#34;_blank&#34;&gt;avoid mentioning AI in the proposal during the AI winters&lt;/a&gt;. It was successful, and we achieved many advances in specific applications such as image classification, machine translation, self-driving car, or playing Go game. And the term AI became hot again.&lt;/p&gt;

&lt;p&gt;But we still lack an idea about how we can build a general-purpose AI which appears in Hollywood movies or general public associates with. Because most of the current AI research is application-specific, we need another term for the original general purpose agent. It has been rephrased many times, including&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;strong AI&lt;/li&gt;
&lt;li&gt;true AI&lt;/li&gt;
&lt;li&gt;human-like AI&lt;/li&gt;
&lt;li&gt;movie-like AI&lt;/li&gt;
&lt;li&gt;lifelong learning&lt;/li&gt;
&lt;li&gt;continual learning&lt;/li&gt;
&lt;li&gt;meta learning or learning to learn&lt;/li&gt;
&lt;li&gt;artificial general intelligence (AGI)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will use AGI to refer this original AI because it tells the fundamental difference between the current mainstream AI research, which is application-specific.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/AI-vs-AGI.svg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;AI vs AGI. AI started as a general purpose model, but later changed its meaning to mostly application specific models. We will use artificial general intelligence (AGI) to mean the original general purpose model.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;how-to-test-agi&#34;&gt;How to test AGI&lt;/h3&gt;

&lt;p&gt;Before we discuss how we can build AGI, let&amp;rsquo;s start with how we can test if we built AGI.  Because according to Peter Drucker or Lord Kelvin,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you can&amp;rsquo;t measure it, you can&amp;rsquo;t improve it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Alan Turing suggested &lt;a href=&#34;https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence&#34; target=&#34;_blank&#34;&gt;a test to verify AGI&lt;/a&gt;. According to the &lt;strong&gt;Turing test&lt;/strong&gt;, also known as &lt;strong&gt;Imitation Game&lt;/strong&gt;, a human participant asks an agent hidden behind the wall to perform many tasks. If the human cannot discern whether the agent is truly a human or an artificial agent, then the artificial agent is assumed to achieve a human-level intelligence.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/exmachina.jpg&#34; width=&#34;30%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;In the movie Ex Machina, you can see how Turing test is conducted.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;While theoretically valid, it poses several problems in its practical application. First, it is too difficult for the current status of research. The human tester can use all the knowledge about the world to test the agent, yet it would be very costly and impossible to teach all the knowledge about the world to the artificial agent, while researchers struggle to discover how we can mimic human-like learning.  It is like asking a 1st grader to take SAT test.&lt;/p&gt;

&lt;p&gt;Second, the test does not provide any idea about where the model can learn those knowledges required to take test. It is like testing students without giving them any textbooks or lectures.&lt;/p&gt;

&lt;p&gt;Third, even for the same model and the same evaluator, the feedback will be different from today to tomorrow. The test is subjective and not reproducible.&lt;/p&gt;

&lt;p&gt;Finally, it is prohibitively expensive to hire people to conduct a test. Humans may participate in annual Turing test competition, but during the hyperparameter tuning or iterative model refinement, it is difficult to get access to human testers.  For these reasons, it is not practically applicable in the current renaissance of the AI.&lt;/p&gt;

&lt;p&gt;We propose an alternative test method for AGI. This method is based on the observation that even if we raise cats and dogs, treating them like human babies, they cannot learn to speak. The animals are capability-limited, and the human baby cannot learn to speak if it is separated from people speaking to it. It is environment-limited. Therefore we can think that the language acquisition is the function of the environment and the capability of the learning agent. In other words, if an agent can learn how to speak in a proper environment, we can say that it has the capability to do artificial general intelligence. We call it the Language Acquisition Test for AGI or &lt;strong&gt;Park&amp;rsquo;s test&lt;/strong&gt;.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/parktest.png&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;In Park&amp;rsquo;s test, the agent is said to have a human-level intelligence if it can learn language given the proper environment&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;To pass a Park&amp;rsquo;s test, we needs a capable model and a proper environment. Let&amp;rsquo;s look at environment first.&lt;/p&gt;

&lt;h3 id=&#34;the-environment-for-the-language-acquisition&#34;&gt;The Environment for the Language Acquisition&lt;/h3&gt;

&lt;p&gt;To conduct the Park&amp;rsquo;s AGI Test, an agent requires an interaction with the world to learn how to speak. One factor that enabled the recent advances in reinforcement learning was the use of the simulated environments such as Atari games or 3D first person shooting games such as VizDoom. Those environments can be used to build and test an agent that can optimize its behavior with little instructions while maximizing the reward signal as a goal to train an agent. However, environments and reward signals adopted in those studies are primitive and more suitable for the development of low-level intelligence which can be found in fish or bugs.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;video autoplay loop=&#34;loop&#34; width=&#34;200px&#34;&gt;&lt;source src=&#34;https://gym.openai.com/videos/2019-05-31--eRh4Fbp8G5/Breakout-v0/original.mp4&#34; type=&#34;video/mp4&#34; &gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;video autoplay loop=&#34;loop&#34; style=&#34;&#34;&gt;&lt;source src=&#34;https://gym.openai.com/videos/2019-05-31--eRh4Fbp8G5/CarRacing-v0/original.mp4&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;video autoplay loop=&#34;loop&#34; style=&#34;&#34;&gt;&lt;source src=&#34;https://gym.openai.com/videos/2019-05-31--eRh4Fbp8G5/roboschool:RoboschoolAtlasForwardWalk-v1/original.mp4&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Atari Environment&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Car Racing Environment&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RoboSchool Environment&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If we want to build an agent with human-level of intelligence, we need to use an environment that can provide a reasonable sensory input and feedback that can teach an agent how to speak. One naive way to provide such an environment is using real people to provide the required responses or trainings. However, using real people has similar limitations with the Turing test. We will have to explore many models in a trial and error before we can finally build an AGI. In addition to the prohibitive cost of using human participants, human experimenters will become quickly tired of providing the same feedback again and again or providing different feedback to the same situation which does not lead to reproducible research.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Advanced Discussion: What is language?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Some would claim that the poor baby abandoned in jungle will still develop a language to communicate with other animal. Similarly there is an emergent communication pattern among collaborative robots. While true, we are interested in human language in this project especially for human robot interaction. The rationale is that we want the robot to learn human language not vice versa.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;There are a few prior researches in language acquisition. &lt;a href=&#34;https://arxiv.org/abs/1706.07230&#34; target=&#34;_blank&#34;&gt;Devendra Singh Chaplot and other researchers in the Carnegie Melon University&lt;/a&gt; used VizDoom environment to demonstrate how agent can learn semantic concepts using reinforcement learning. In their experiments, agents get rewards when they go to objects  according to the verbal direction such as &amp;ldquo;Go to short blue torch&amp;rdquo;. What is interesting is that during the training the agents experience verbal direction such as &amp;ldquo;Go to blue torch&amp;rdquo;, &amp;ldquo;Go to torch&amp;rdquo;, &amp;ldquo;Got to short red torch&amp;rdquo; and so on but never experience &amp;ldquo;short blue torch&amp;rdquo;. Even then during the test time, they can follow the direction to go to &amp;ldquo;short blue torch&amp;rdquo;. This implies that the agent can map the words such as &amp;ldquo;short&amp;rdquo;, &amp;ldquo;blue&amp;rdquo;, &amp;ldquo;torch&amp;rdquo; with the visual features in the objects. This is a step forward to solve &lt;a href=&#34;https://en.wikipedia.org/wiki/Symbol_grounding_problem&#34; target=&#34;_blank&#34;&gt;the symbol grounding problem&lt;/a&gt;.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/groundedlanguage.gif&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Agents learns  language using reinforcement learning. Image by &lt;a href=&#34;https://github.com/devendrachaplot/DeepRL-Grounding&#34; target=&#34;_blank&#34;&gt;Devendra Singh Chaplot et al&lt;/a&gt;&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;But the concepts that can be learned in this way is limited. There are limitations due to the environments. We don&amp;rsquo;t learn by fetching objects according to the parent directions. It will take too long to learn all concepts this way. We need a better environments that can teach the language&lt;/p&gt;

&lt;p&gt;When the transistor was first invented, people were excited to use it as an amplifier to build radio and radars. But the true power of the transistor was when it was arranged in a specific structure, it could build a logic gate. By arranging logic gates in a specific way, we could build a CPU, the true ultimate power of transistor.&lt;/p&gt;

&lt;p&gt;The same goes with the connectionism. We know how one or two neural cell behaves exactly and we can simulate them. But most advancement came with the arrangement of this device in a specific ways, such as multi-layer perceptron (MLP), convolutional neural net (CNN), recurrent neural net (RNN), and generative adversarial network (GAN). In this sense, we are experimental computer scientist who seek the right structure mostly by trial and errors. Because of this nature, it is helpful to have an environment that can provide an easy, low-cost, and reproducible way to experiment.&lt;/p&gt;

&lt;p&gt;In our lab, we would like to develop an environment for Park&amp;rsquo;s test. The key idea is that we will focus on the critical stage of the human development when humans learn how to speak as infants. This environment will contain a 3D replication of a room in the home with a few toys. There will be a mother character and a baby character. The mother character will be programmed manually using traditional game AI technology to take care of the baby and lead a conversation with the baby character which is often called a baby talk, child-directed speech (CDS), motherese or infant directed speech (IDS). IDS is a communication pattern, when a mother tries to teach language to an infant. The baby character will be the learning agent. The success of the test will be decided by whether the learning agents can acquire language and develop reasonable behavior comparable to the human developmental progress.&lt;/p&gt;




&lt;figure&gt;

&lt;img src=&#34;./img/env.svg&#34; width=&#34;100%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
  &lt;h4&gt;Previous environments have led the advancements of the reinforcement learning. We propose a novel environment for the language learning.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;hierarchical-prediction-memory-hpm&#34;&gt;Hierarchical Prediction Memory (HPM)&lt;/h3&gt;

&lt;p&gt;HDILab also studies the model that can learn the language in the environment described above.  Let&amp;rsquo;s start our discussion from the function and the mechanism.&lt;/p&gt;

&lt;h4 id=&#34;function-and-mechanism&#34;&gt;Function and Mechanism&lt;/h4&gt;

&lt;p&gt;The most difficult way to fly is to imitate the biological &lt;strong&gt;mechanism&lt;/strong&gt; of flying such as in birds or flies. The biological mechanism is highly evolved due to the long history of adaptation. And many of the complex mechanism is due to the biological limitation which does not apply to us. What we need to figure out is what those mechanism are actually doing or &lt;strong&gt;function&lt;/strong&gt;. The way human or horses run is &lt;em&gt;pushing the ground backward&lt;/em&gt;. The way birds fly is &lt;em&gt;pushing the air downward&lt;/em&gt;. This applies to the intelligence. The biological mechanism is very complex. It has been very optimized. It has to use biological lossy devices. So the mechanism is very complex. But we need to learn what is the function of the mechanism. It is in my opinion &lt;em&gt;prediction of vector sequence&lt;/em&gt;. Hierarchy helps to overcome the temporal limit by chunking. The essence of intelligence is &lt;em&gt;hierarchical prediction of vector sequence&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We conjecture that the essence of the intelligence is a hierarchical prediction.&lt;/p&gt;

&lt;p&gt;Where the original connectivist has missed? The original connectivist thought the decision or pattern recognition as the core activity. However, this lead to the wrong formalization of the problem? In my opinion, prediction should be the core activity. Prediction includes the decision or pattern recognition, but the main difference is that it has the streaming input and streaming output.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parallelspaces: Simultaneous Exploration of Feature and Data for Hypothesis Generation</title>
      <link>http://crystal.uta.edu/~park/publication/parallelspace/</link>
      <pubDate>Tue, 29 Mar 2016 10:40:11 -0500</pubDate>
      
      <guid>http://crystal.uta.edu/~park/publication/parallelspace/</guid>
      <description>


&lt;figure&gt;

&lt;img src=&#34;./files/parallelspaces/parallelspaces_screen.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The MovieVis tool. Two groups in the movie space have been selected to compare corresponding user distribution. Two movies selected in the upper-center region—One flew Over the Cuckoos Nest (1975) and Amadeus (1984)–and are shown in blue color. Another two movies selected in a lower-center region—Phenomenon (1996) and Twister (1996)—are shown in orange. The highlighted users are those who liked all both pairs of movies (because the group mode is set to common). Based on the user space axes—gender for the horizontal and age for the vertical—we can see that while the movie One Flew Over the Cuckoo’s Nest and Amadeus were favored by male reviewers of all ages, the Phenomenon and Twister were liked by relatively younger male audiences.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;




&lt;figure&gt;

&lt;img src=&#34;./files/parallelspaces/parallelspaces_teaser.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;On the left, we compare two movies, Toy Story (1995), in blue, and Scream (1996), in orange, according to the age, location and similarity criteria for users. Some notable observations are while the former is liked all around the U.S. by any age groups the latter is mostly popular in the eastern part and within a younger generation. On the right, we compare two users, a 19-year-old male student, in blue, and a 51-year-old male educator, in orange according to the average, release date, and similarity criteria for movies. We observe that the older user tends to rate older films highly. In addition, his average review tends to conform to the average ratings patterns of all users while the younger user seems to deviate from it.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
</description>
    </item>
    
  </channel>
</rss>
